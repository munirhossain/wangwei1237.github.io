[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "",
    "text": "欢迎阅读\nIntroduction to Probability and Statistics for Engineers and Scientists (Sixth Edition) 是一本为工程师和科学家而作的有关概率论和数理统计方面的书籍。\n本书的第六版继续展示了如何应用概率论来洞察现实生活中的统计问题。与之前的版本一样，本书精心设计的概率论相关的内容将真实现象的概率模型和其统计程序关联起来，以便读者能够更直观的理解实践工程师和科学家最常用的统计程序和策略。\n本书是为工程学、计算机科学、数学、统计学和自然科学专业的学生编写的统计学和概率统计入门课程。当然，科学家、工程师和其他专业人员也可以从本书中找到灵感。",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "index.html#翻译进度",
    "href": "index.html#翻译进度",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "翻译进度",
    "text": "翻译进度\n3/16..............",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "index.html#版权声明",
    "href": "index.html#版权声明",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "版权声明",
    "text": "版权声明\n本翻译稿是笔者在阅读原书过程中的笔记，采用“保持署名—非商用”创意共享 4.0 许可证。只要保持署名和非商用，您可以自由地阅读、分享本书。\n您可以：\n\n下载、保存以及打印本翻译稿\n网络链接、转载本翻译稿的部分或者全部内容，但是必须在明显处提供读者访问本翻译稿发布网站的链接\n\n您不可以：\n\n以任何形式出售本翻译稿的电子版或者打印版\n擅自印刷、出版本翻译稿\n以纸媒出版为目的，改写、改编以及摘抄本翻译稿的内容",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "preface_17.html",
    "href": "preface_17.html",
    "title": "译者序",
    "section": "",
    "text": "翻译稿中的样式惯例\n在翻译稿中，遵循以下的排版约定：",
    "crumbs": [
      "译者序"
    ]
  },
  {
    "objectID": "preface_17.html#翻译稿中的样式惯例",
    "href": "preface_17.html#翻译稿中的样式惯例",
    "title": "译者序",
    "section": "",
    "text": "斜体：表示英文术语、URL、电子邮件地址、文件名、文件扩展名。\n固定宽度：用于程序列表、段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。\n粗体：突出显示重要文本和中文术语。\n\n\n\n\n\n\n笔记\n\n\n\n该部分内容是原书中没有的内容，是笔者在阅读过程中补充的相关资料和笔者的个人理解。",
    "crumbs": [
      "译者序"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "序言",
    "section": "",
    "text": "本书的组织结构和内容范围\n1  统计学简介 对 统计学 进行了简要介绍，介绍了 统计学 的两大分支：描述统计、推论统计，然后介绍了 统计学 的一小段历史和为当今统计学的发展奠定基础的先驱人物。\n2  描述统计 的主要内容是 描述统计。本章介绍了描述数据集的图表，以及用于总结数据集某些关键属性的统计量（quantities）。\n3  概率论基础 的内容主要是概率实验，事件概率的基本概念，概率的相关公理。我们必须了解数据的来源，以从数据中得出结论。例如，我们通常假设，数据是从某个群体中抽取的 “随机样本”。为了准确理解这样的假设意味着什么，也为了准确理解将样本数据的属性与总体的属性联系起来会产生什么结果，我们有必要了解一些概率知识。\n4  随机变量和期望 将继续研究概率，本章会进一步介绍随机变量（random variables）和期望（expectation）等重要概念。\n5  Special random variables 会介绍应用中经常出现的一些特殊类型的随机变量，包括：二项分布、泊松分布、超几何分布、正态分布、均匀分布、伽马分布、卡方分布、\\(t\\) 分布和 \\(F\\) 分布……\n6  Distributions of sampling statistics 会研究样本均值（mean）和样本方差（variance）等抽样统计数据的概率分布。本章将介绍如何使用显著概率理论结果（中心极限定理）来近似样本均值的概率分布。此外，在某些重要的特殊场景下，当抽样的数据来自符合正态分布的总体时，本章也给出了样本均值和样本方差的联合概率分布。\n7  Parameter estimation 介绍了如何使用数据来估计感兴趣的参数。例如，科学家可能想要确定受到酸雨影响的中西部湖泊的比例。本章会研究两种参数估计方法。第一种估计方法用一个数字来估计感兴趣的统计量（例如，中西部湖泊中有 47% 的湖泊受到了酸雨的影响）。第二种则是以一个数值区间的形式来估计总体参数的范围（例如，中西部湖泊中有 45% ~ 49% 的湖泊受到了酸雨的影响）。第二种估计方法还告诉我们对其估计结果的 “置信水平”（level of confidence）。例如，尽管我们并不能肯定 47% 就是受影响的湖泊的确切比例，但我们很可能有 95% 的信心认为实际受影响的湖泊比例在 45% ~ 49% 之间。\n8  Hypothesis testing 介绍了统计假设检验这一重要内容，该部分关注的是利用数据来检验特定假设的合理性。例如，假设检验可能会拒绝 “中西部受酸雨影响的湖泊少于 44%” 这样的假设。本章引入了 \\(p\\) 值的概念来衡量在观察到数据后假设的合理性程度。本章还会介绍关于一个和两个正态总体参数的各种假设检验方法，以及关于伯努利分布和泊松分布的参数的假设检验。\n9  Regression 会涉及 回归（regression） 这个重要的课题。简单线性回归（包括平均数回归、残差分析、加权最小二乘法等）和多元线性回归的内容都将在本章中进行介绍。\n10  Analysis of variance 介绍了方差分析。本章具体介绍了一维方差分析（one-way analysis of variance）和二维方差分析（two-way analysis of variance）。\n11  Goodness of fit tests and categorical data analysis 关注的是拟合优度检验（goodness of fit tests）。拟合优度检验可以用来检验所提出的模型是否与观察到的数据一致。在本章中，我们介绍了经典的卡方拟合优度检验（Chi-squared goodness of fit test），并将其应用于检验列联表（contingency tables）中变量的独立性。本章的最后一节介绍了可用于检验数据是否来自特定连续概率分布的 Kolmogorov-Smirnov 检验方法。\n12  Nonparametric hypothesis tests 涉及到非参数假设检验，当我们无法假设潜在的数据分布具有某种特定的参数形式（如正态分布）时，可以使用非参数假设检验。\n13  Quality control 主要考虑质量控制（quality control）这一主题。质量控制是制造和生产过程中的一项关键统计技术。本章会介绍多种控制图，不仅包括 Shewhart 控制图，还包括基于 移动平均（Moving Averages） 和 累积和（Cumulative Sums）的更复杂的控制图。\n14  Life testing 介绍了与寿命测试相关的问题。在寿命测试中，起关键作用的不是正态分布，而是指数分布。\n15  Simulation, bootstrap statistical methods, and permutation tests 介绍了 bootstrap 统计方法和排列检验（permutation tests）的统计推断技术。本章首先介绍了如何通过模拟（simulation）获得概率，然后介绍了如何在这些统计推断方法中使用模拟。\n16  Machine learning and big data 是本书第 6 版中新增的内容，本章介绍了机器学习和大数据的相关技术。当拥有较大的数据量时，我们可以使用机器学习和大数据技术在无需假设任何特定概率模型下来估计概率。例如，我们想要估计一个由向量 \\((x_1, ..., x_n)\\) 表示的实验成功的概率。当该特征向量是对自然属性（qualitative in nature）（例如，动物的分类）的描述时，可以使用朴素贝叶斯方法和最近邻规则等技术。当特征向量的是量化数据（quantitative）（例如身高、体重）时，我们还研究了逻辑回归模型。\n本书的第六版不但新增了 16  Machine learning and big data ，最重要的变化是引入了统计软件 R。我们会在书中介绍 R 的使用方法，因此没有 R 使用经验的读者也无需担心。除此之外，我们还新增了 2.7 洛伦兹曲线和基尼系数 来讨论 洛伦兹曲线（Lorenz Curves）和 基尼指数（Gini Index）。第六版还增加了很多新的示例和问题。为了进一步提高本书文本表述和论证的清晰度，该版本对书中很多内容作了些许调整。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "preface.html#补充材料",
    "href": "preface.html#补充材料",
    "title": "序言",
    "section": "补充材料",
    "text": "补充材料\n可以从 https://educate.elsevier.com/book/details/9780128243466 处获取教师解答手册。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "preface.html#致谢",
    "href": "preface.html#致谢",
    "title": "序言",
    "section": "致谢",
    "text": "致谢\n感谢对第六版的内容提出有益意见的人们：\n\nGideon Weiss, University of Haifa\nN. Balakrishnan, McMaster University\nMark Brown, Columbia University\nRohitha Goonatilake, Texas A and M University\nSteve From, University of Nebraska at Omaha\nSubhash Kochar, Portland State University\nSumona Mondal, Mathematics, Clarkson University\nKamel Belbahri, Mathematics and Statistics, Université de Montréal\nAnil Aswani, Industrial Engineering and Operations Research, University of California, Berkeley\n\n对于希望保持匿名的所有审稿人，也在此表示感谢。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "chapter_1/1.html",
    "href": "chapter_1/1.html",
    "title": "1  统计学简介",
    "section": "",
    "text": "1.1 引言\n如今，人们普遍接受了这样的事实：为了了解某个事物，我们必须首先收集和该事物相关的数据。统计学（Statistics）是一门从数据中学习的艺术，它包括数据的收集，也包括通过后续的数据描述和数据分析来获得结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_2",
    "href": "chapter_1/1.html#sec-1_2",
    "title": "1  统计学简介",
    "section": "1.2 数据收集和描述统计",
    "text": "1.2 数据收集和描述统计\n\n\n\n\n\n\n描述统计\n\n\n\n描述统计（descriptive statistics）是统计学的一个重要分支，另一个重要的分支是 章节 1.3 中介绍的 推断统计（Inferential statistics）。\n描述统计 主要关注于数据的收集、处理、汇总、图表描述、概括与分析，包括统计数据的收集方法、数据的加工处理方法、数据的显示方法、数据的分布特征与分析方法等。描述统计 的目的是将数据转化为有意义的信息，并帮助我们理解数据的特征和规律。常见的 描述统计 包括直方图、平均数、中位数、众数等。\n推断统计 主要关注如何利用样本数据来推断总体特征，包括参数估计（例如平均数、标准差的估计）和假设检验两种类型。推断统计 允许我们根据部分数据来推断总体特征，从而提高研究的效率和准确性。常用的 推断统计 包括置信区间、t 检验、方差分析等。\n描述统计 是统计学的基础，其主要处理样本数据；而 推断统计 则是描述统计的升华，其利用样本数据来推测总体特征。\n\n\n有时候，我们会从一个给定的数据集合为起点来启动统计分析：例如，政府会定期收集和公布相关年份的降水量、地震发生次数、失业率、国内生产总值以及通货膨胀率。我们可以使用 统计学 来描述、总结并分析如上的数据。\n在有些场景下，我们可能还没有可用于分析的数据，此时需要利用统计理论来设计合适的实验以生成分析所需的数据。实验方案的选择取决于我们如何使用这些数据。\n\n\n教学方式的实验\n\n对于计算机编程课而言，假设一名老师想要确定哪种教学方法对初学者更好。\n\n为了研究这个问题，该老师可以把学生分成两组，然后针对不同组的学生采用不同的教学方法。在课程结束时，对学生的学习效果进行测试，并比较不同分组的学生成绩。如果其中一组学生的成绩明显高于另一组，那么我们假定该组使用的教学方法更优越的想法就更为合理。\n\n然而，为了从数据中得出有效的结论，对学生进行分组的方式至关重要，分组时应确保两组学生的编程资质是一致的。这一点，我们我们需要特别关注。我们不应该将男生分为一组，而把女生分为另一组。如果按照性别分组，即使女生组的测试成绩明显高于男生组，我们也无法确定成绩差异是源自教学方法的不同，还是因为女性在学习编程技能方面可能更具天赋。为了避免这个陷阱，我们可以 随机 把学生分成两组。“随机” 这个词意味着分组的方式应确保每个学生有同等的机会被分配到不同的组。\n在实验的最后，我们应该对数据进行描述（例如，两个分组的测试成绩）。此外，我们还应呈现数据的汇总指标（例如，不同分组的平均成绩）。在 统计学 中，涉及数据描述和数据汇总的部分称之为 描述统计。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_3",
    "href": "chapter_1/1.html#sec-1_3",
    "title": "1  统计学简介",
    "section": "1.3 推断统计和概率模型",
    "text": "1.3 推断统计和概率模型\n当我们完成了 章节 1.2 中所述的、教学方式的实验，并对实验数据进行了描述和汇总后，我们希望可以得出哪种教学方法更好的结论。在 统计学 中，涉及到得出结论的这一部分称之为 推断统计。\n为了能够从数据中得出结论，我们必须考虑偶然事件发生的可能性。例如，对于 章节 1.2 中提到的教学方式的实验，假设第一组学生的平均成绩稍高于第二组，我们能断定成绩的增加是因为教学方法吗？或者是否存在这种可能：教学方法并不是成绩增加的原因，第一组学生的成绩较高只是偶然发生的？例如，抛 10 次硬币，其中有 7 次正面朝上，这并不意味着在以后的实验中，这枚硬币正面朝上的概率会高于反面朝上。实际上，这枚硬币可能只是一枚普通的硬币，只是碰巧在10 次抛掷中出现了 7 次正面朝上。（另一方面，如果在 50 次抛掷中出现了 47 次正面朝上，那么我们就可以非常确定这不是一枚普通硬币。）\n为了从数据中得到正确的结论，我们通常会对可以获取到的、不同数据的可能性（或概率）做某些假设。这些假设的总和称之为数据的 概率模型。\n有时，数据的性质（nature）暗含了我们所假设的 概率模型 的形式。例如，假设一名工程师想要了解使用新的生产方式生产的计算机芯片的缺陷率。该工程师可能会从新生产方式生产的芯片中选择一组芯片，然后可以得到所抽取的这组芯片中的缺陷芯片数量。只要这组芯片是 “随机” 选择而产生的，那么假设这组芯片中的每一个芯片存在缺陷的概率为 \\(p\\) 就是合理的，其中 \\(p\\) 是使用新方法生产的所有芯片的缺陷率。因为我们无法抽查所有芯片以获得 \\(p\\)，因此 \\(p\\) 是未知的，我们可以用“随机”抽取的芯片所得到的数据来推断 \\(p\\)。\n在其他情况下，概率模型 在给定数据集上的表现并不明显。然而，对数据的仔细描述和呈现有时能帮助我们推断出合理的 概率模型，然后我们可以使用其它的数据来验证推断的 概率模型。\n统计推断 的基础是通过构建 概率模型 来描述数据，因此需要具备一定的概率论基础才能理解 统计推断。换句话说，统计推断 源自这样的假设：我们可以用概率来描述研究对象，然后我们可以基于该假设通过数据来推断这些概率，从而得出结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_4",
    "href": "chapter_1/1.html#sec-1_4",
    "title": "1  统计学简介",
    "section": "1.4 总体与样本",
    "text": "1.4 总体与样本\n在 统计学 中，我们对获取研究对象中的所有个体的集合的信息感兴趣。研究对象中所有个体的集合我们称之为 总体。总体 的规模往往太大，所以我们无法检查 总体 中的每个成员。例如，我们可能有某个州的所有居民数据，或者某个制造商去年生产的所有电视机数据，亦或者某个社区的所有家庭数据。在这些情况下，我们试图通过选择总体元素的一个子分组并对该子分组进行检查来了解 总体，这个子分组我们称其为 样本。\n如果 样本 需要提供有关 总体 的信息，那么，在某种意义上而言，样本 必须具有代表性。\n\n\n市民的平均年龄\n\n假设我们对某市居民的年龄分布感兴趣，并且我们获得了进入城镇图书馆（town library）的前 100 个市民的年龄。如果这 100 人的平均年龄为 46.2 岁，我们是否可以依次为依据得出结论：该市居民的平均年龄为 46.2 岁？\n\n可能并非如此。当然，我们可以认为，在这种情况下选择的 样本 可能并不能代表 总体，因为通常而言，年轻学生和老年市民去图书馆的可能性要大于上班族。\n\n\n\n\n\n\ntown library\n\n\n\n在美国，“town library” 是指位于城镇内的公共图书馆。这些图书馆由城镇或地方政府资助，为当地社区提供各种书籍、资料和服务。城镇图书馆通常提供免费的借阅服务，包括书籍、期刊、报纸、音像资料等，并提供学习空间、研究帮助、电脑和互联网接入等资源。它们也可能举办各种活动和课程，以满足社区居民的教育、文化和娱乐需求。\n\n\n在某些情况下，我们得到了一个 样本，然后我们必须判断该 样本 是否能够代表 总体，例如如上的市民平均年龄的示例。在实践中，如果样本不是以“随机“的方式进行选择，那么通常不能假定给定的 样本 可以代表 总体。任何特定的、非随机的抽样规则往往会导致 样本 对某些数据存在固有的偏好，这也意味着会天然的反对另外的数据。\n因此，对于待选择的个体而言，在没有任何先验知识的情况下，通过完全”随机“的方式来选择 样本，我们更有可能获得有代表性的 样本。尽管这听起来可能有些矛盾，但这确实如此。换句话说，我们不需要刻意选择样本，以便 样本 中的人的性别比例和职业比例与 总体 是一致的。相反，我们应该把 样本 的特性留给 “可能性” 或者 ”概率“，以获得大致正确的百分比。一旦选好了随机样本，我们就可以通过研究 样本 并使用 统计推断 来得出和 总体 有关的结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#统计学简史",
    "href": "chapter_1/1.html#统计学简史",
    "title": "1  统计学简介",
    "section": "1.5 统计学简史",
    "text": "1.5 统计学简史\n在文艺复兴时期，意大利的威尼斯和佛罗伦萨开始对人口和经济方面的数据进行系统化的收集。统计学（statistics） 一词来源于国家（state）这个单词，通常用来描述和国家有关的数据收集。这种收集数据的想法不断从意大利传播到西欧的其他国家。事实上，在 16 世纪上半叶，欧洲国家的政府普遍要求教区居民登记出生、婚姻和死亡情况。由于公共卫生条件差，政府尤其关注居民登记的死亡信息统计。\n\n\n\n\n\n\nstatistics 一词的来源\n\n\n\n在 Statistics, History of 这篇论文中，作者提到了 statistics 一词的来源。\n\nIt is widely believed that the term statistics originated from the Latin Status (situation, condition) of population and economics; in late Latin, the same term meant State. Another root of the term comes from the Italian word stato (state), and a statista (a person who deals with affairs of state).\nAccording to Kendall (1960:447) the first use of the word statistics “occurs in a work by an Italian historian Girolamo Ghilini, who in 1589 refers to an account of civile, politica, statistica e militare scienza.”\n\n\n\n19 世纪之前，欧洲的高死亡率主要源自流行病、战争和饥荒。对于流行病而言，最严重的是瘟疫。从 1348 年的黑死病开始，瘟疫在近 400 年的时间里频繁在欧洲发生。1562 年，为了让英国的王室成员意识到需要搬迁到乡下，伦敦市开始每周公布死亡人数。最初，这些死亡人数的清单中会列出死亡地点以及是否因瘟疫而死亡。从 1625 年开始，该清单中的信息扩展到所有的死亡原因。\n1662 年，英国商人 John Graunt 出版了一本名为 Natural and Political Observations Made upon the Bills of Mortality 的书。表格 1.1 摘录了该书中所列出的英格兰五个不同瘟疫年份的总死亡人数和因瘟疫死亡的人数。\n\n\n\n表格 1.1: 不同年份的英格兰死亡人数表\n\n\n\n\n\n年份\n死亡人数\n瘟疫致死人数\n\n\n\n\n1592\n25,886\n11,503\n\n\n1593\n17,844\n10,662\n\n\n1603\n37,294\n30,561\n\n\n1625\n51,758\n35,417\n\n\n1636\n23,359\n10,400\n\n\n\n\n\n\nGraunt 利用伦敦的死亡人数来估算该市的人口总数。例如，为了估算 1660 年伦敦的人口，Graunt 对伦敦某些教区 (或社区) 家庭进行了调查，并发现平均每 88 人中大约有 3 人死亡。这意味着平均每 88/3 个人就会有 1 个人死亡。伦敦的死亡人数清单显示 1660 年伦敦有 13200 人死亡，所以 Graunt 估计当年伦敦的人口大约为：\n\\[\n13200 × 88/3 = 387200\n\\]\nGraunt 利用这种估计方法来预测整个英格兰的人口数量。他在书中指出，政府会对这些数据感兴趣，因为这些数据可以作为应征入伍人数和应纳税人数的指标。\nGraunt 还利用伦敦的死亡人数清单，以及关于何种疾病会导致何人、在什么年龄死亡的一些合理猜测，来推断死亡年龄。(回想一下，前面提到的死亡人数清单只列出了死亡原因和地点，其并没有列出死者的年龄。) 然后，格兰特利用这些信息计算出不同年龄段的死亡人口比例。表格 1.2 是 Graunt 计算的死亡率表之一。例如，表格 1.2 指出，在 100 名新生儿中，有 36 人将在 6 岁之前死亡，24 人将在 6~15 岁之间死亡，……\n\n\n\n表格 1.2: John Graunt 的死亡率表\n\n\n\n\n\n死亡年龄\n每 100 新生儿中的死亡人数\n\n\n\n\n0-6\n36\n\n\n6-16\n24\n\n\n16-26\n15\n\n\n26-36\n9\n\n\n36-46\n6\n\n\n46-56\n4\n\n\n56-66\n3\n\n\n66-76\n2\n\n\n&gt;=76\n1\n\n\n\n\n\n\n从事 年金 行业的人对 Graunt 的死亡年龄表非常感兴趣。年金 与人寿保险不同，人们会一次性支付一笔款项作为投资，然后在有生之年定期从 年金 中获得收益。\n\n\n\n\n\n\n年金\n\n\n\n年金（annuity）是一种金融产品，通常由保险公司或金融机构提供。年金是一种长期投资工具，旨在为购买者提供一定期间内的收入。购买者通常向保险公司或金融机构支付一笔或多笔资金，而作为回报，购买者将在未来的一段时间内获得一定的收益。\n\n\n受到 Graunt 死亡率表的启发，1693 年，Edmund Halley 又做了更进一步的工作。Halley 是哈雷彗星的发现者（同时，Halley 也是对《自然哲学的数学原理》一书的出版贡献最大的人，他不但鼓励牛顿把自己的发现编写成书，更是为该书的出版提供了资金支持），他利用死亡率表来计算任何年龄段的人活到任何特定年龄的概率。Halley 说服了当时的保险公司，让他们相信年度人寿保险保费应该取决于被保险人的年龄。\n继 Graunt 和 Halley 之后，从 17 世纪末到 18 世纪，对数据的收集呈现稳步增长的趋势。例如，1667年，巴黎开始收集死亡人数清单；到 1730 年时，在欧洲，记录死亡年龄已成为一件非常普遍的事情。\n18 世纪之前，“statistics” 这个词被用作对国家或地区进行描述性分析的科学方法的简称。从 1800 年左右开始，西欧国家和美国政府开始系统地收集和公布类似的人口普查数据，这积累了大量的、可用的人口普查记录和相关的表格数据，这也导致了 “statistics” 一词在含义上发生了变化。19 世纪时，“statistics” 越来越多地与数字联系在一起，到 19 世纪 30 年代，在英国和法国，人们普遍将 “statistics” 一词与社会“数字科学”（numerical science）视为同等含义。\n贯穿整个 19 世纪，在 Jacob Bernoulli、Karl Friedrich Gauss 和 Pierre Simon Laplace 等数学家的推动下，尽管 概率论 已经发展起来，但在研究统计结果方面，概率论 几乎没有任何应用。此中的原因在于，当时的大多数社会统计学家都满足于让数据自己说话。特别是，当时的统计学家对个体推断并不感兴趣，他们更关心整个社会。因此，在当时，统计学家并不关心抽样，而是试图获得全部的人口普查数据。因此，在 19 世纪的社会统计学中，通过样本来推断总体概率的事情几乎没有发生过。\n直到 19 世纪末，统计学才开始关注如何从数值数据中推断结论。推断统计 这一运动始于 Francis Galton 关于 遗传天才 的分析工作，在这项分析中， Francis Galton 使用了我们现在所说的回归分析和相关性分析（章节 9）。Francis Galton 的工作极大的推动了 Karl Pearson 为统计学所做的贡献。Karl Pearson 是卡方检验（章节 11）的发明者，也是由 Francis Galton 于1904 年资助建立的高尔顿实验室的第一任负责人。在高尔顿实验室，Karl Pearson 发起了一个旨在发明一种用统计数据进行推断的新方法的研究项目。Pearson 邀请科学和工业领域的高年级学生到实验室来学习统计方法，然后将对应的方法应用于各自的领域。化学家 W.S. Gosset 是高尔顿实验室最早的访问学者之一，他以 “Student” 的名义出版了自己的研究发现，并以此表达了对皮尔逊的敬意。（有一个比较有名的故事是说，Gosset 害怕他所在的吉尼斯酿酒厂的老板在发现他们的一位化学家正在做统计学研究时会不高兴，因此不敢以自己的名义出版著作）。Gosset 因为他所发明的 t 检验而名声大振（章节 8）。\n20 世纪初，群体生物学（population biology）和农业是应用统计学的两个最重要的领域。统计学这这些领域的应用主要源自 Pearson 和他的实验室的其他人的研究，也源自英国科学家 Ronald A. Fisher 在统计学中的显著成就。在如上所介绍的先驱者以及其他研究者（例如， Karl Pearson 的儿子 Egon 和出生于波兰的数理统计学家 Jerzy Neyman 等）的推动下，他们所发明的推理理论已经通用到可以处理广泛的量化问题和实践问题。因此，在 20 世纪初之后的几年里，越来越多的科学家、商人和政界人士开始将统计学视为能够为科学问题和实践问题提供定量解决方案的工具（见 表格 1.3）。\n\n\n\n表格 1.3: Statistics 定义的变化\n\n\n\n\n\n\n\n\n\n时间\n定义\n\n\n\n\nQuetelet, 1849\nStatistics has then for its object that of presenting a faithful representation of a state at a determined epoch.\n\n\nGalton, 1889\nStatistics are the only tools by which an opening can be cut through the formidable thicket of difficulties that bars the path of those who pursue the Science of man.\n\n\nFisher, 1925\nStatistics may be regarded (i) as the study of populations, (ii) as the study of variation, and (iii) as the study of methods of the reduction of data.\n\n\nE. Pearson, 1936\nStatistics is a scientific discipline concerned with collection, analysis, and interpretation of data obtained from observation or experiment. The subject has a coherent structure based on the theory of Probability and includes many different procedures which contribute to research and development throughout the whole of Science and Technology.\n\n\nWeaver, 1952\nStatistics is the name for that science and art which deals with uncertain inferences — which uses numbers to find out something about nature and experience.\n\n\nPorter, 1986\nStatistics has become known in the 20th century as the mathematical tool for analyzing experimental and observational data.\n\n\nthis book, 2020\nStatistics is the art of learning from data.\n\n\n\n\n\n\n如今，统计学的思想无处不在。在每一份报纸和杂志上，描述统计学 的特点都有所体现。在公共卫生、医学研究、工程研究、科学研究、市场营销、质量控制、教育、会计、经济、气象预报、投票和调查、体育、保险、赌博以及所有声称是科学的研究领域，统计推断 都是不可或缺的。的确，统计学已经深深植根于人类的知识遗产（intellectual heritage）之中。\n\n\n\n\n\n\n知识遗产\n\n\n\n知识遗产（intellectual heritage）是指社会所拥有的知识、思想、传统、技能和价值观的集合，这些资源被传承下来并世代相传。知识遗产包括各种形式的人类智慧，如文学作品、艺术品、哲学理论、科学发现、宗教信仰、法律体系、技术创新等。知识遗产不仅仅是一种资产，更是一种社会、文化和历史的遗产，它反映了人类的智慧、经验和创造力，对于塑造社会的认同感、价值观和意识形态具有重要意义。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#问题",
    "href": "chapter_1/1.html#问题",
    "title": "1  统计学简介",
    "section": "问题",
    "text": "问题\n\n下周将举行选举，我们试图通过对总体选民进行抽样来预测共和党候选人或民主党候选人谁会获胜。以下哪种抽样方法可能产生有代表性的样本？\n\n\n对参加大学篮球比赛的所有达到投票年龄的人进行民意调查。\n\n\n对去市中心一家高档餐厅用餐的所有达到投票年龄的人进行民意调查。\n\n\n获取一份选民登记名单，随机选择100个名字，并对他们进行提问。\n\n\n使用电视台的电话投票民意调查结果，电视台会要求听众打电话进来并说出他们的选择。\n\n\n从电话簿中选择名字，并给这些人打电话。\n\n\n在1936年的美国总统竞选中，第 1 题的 (e) 选项使用的方法导致了及其糟糕的预测结果。在那次竞选中，富兰克林·罗斯福以压倒性优势击败了阿尔弗雷德·兰登。该杂志从汽车用户和电话用户名单中抽取选民样本，基于对这些选民的调研，Literary Digest 杂志预测兰登会获胜。\n\n\n你认为 Literary Digest 杂志的预测为何如此离谱？\n\n\n从 1936 年到现在，有没有什么变化让你相信 Literary Digest 杂志使用的方法在今天会更有效？\n\n\n一位研究人员正试图发现当今美国人死亡时的平均年龄。为了获得数据，研究人员阅读了 30 期的《纽约时报》的讣告专栏，并记录了美国人的死亡年龄。你认为这种方法会得到一个有代表性的样本吗？\n为了确定镇上吸烟者的比例，现决定在当地的以下地点之一进行民意调查。这些民意调查地点中，哪一个最有可能得出合理的结果？为什么？\n\n\n台球厅\n\n\n保龄球馆\n\n\n购物中心\n\n\n图书馆\n\n\n一所大学计划对其近期毕业的学生进行调查，以确定他们的年薪信息。该学校随机选择了 200 名近期要毕业的学生，并向他们发送了和他们目前工作有关的调查问卷。然而，在这 200 人中，只有 86 人返回了问卷。假设这返回的 86 份问卷显示的平均年薪为 75000 美元。\n\n\n该学校认为 75000 美元是所有毕业生平均工资水平的比较好的近似值，这种想法对吗？解释你的回答背后的理由。\n\n\n如果你对 (a) 的回答是否定的，你能想到，在什么条件下，返回的问卷所显示的工资水平将会是一个不错的毕业生平均工资水平的近似值？\n\n\n一篇文章报道称，对夜间交通事故中丧生的行人所穿衣服的调查显示，约 80% 的受害者穿着深色衣服，20% 的受害者穿着浅色衣服。文章得出的结论是，晚上穿浅色衣服更安全。\n\n\n这个结论合理吗？请解释下你的回答。\n\n\n如果你对 (a) 的回答是否定的，那么在得出最终结论之前，还需要什么其他信息？\n\n\n如何评判 Graunt 估算伦敦人口的方法？他的方法是有什么隐含的假设？\n1658 年，伦敦的死亡率清单记录了 12246 人死亡。假设对伦敦教区的调查显示，该年的人口死亡率大约为 2%，使用 Graunt 的方法来估算 1658 年伦敦的人口总数。\n1662 年，当 Graunt 的书出版时，假设你是一名年金销售员。解释一下，你将如何利用 Graunt 给出的关于人们死亡年龄的数据。\n基于 Graunt 的死亡率表（表格 1.2）：\n\n\n活到 6 岁的人的占比是多少？\n\n\n活到 46 岁的人的占比是多少？\n\n\n死于 6 岁到 36 岁之间的人的占比是多少？",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html",
    "href": "chapter_2/2.html",
    "title": "2  描述统计",
    "section": "",
    "text": "2.1 引言\n本章将介绍 描述统计 的相关内容，在介绍 描述统计 的过程中，我们将学习如何描述和总结数据。\n章节 2.2 会讨论如何描述数据集。如果一个数据集中的数据差异相对较小，章节 2.2.1 和 章节 2.2.2 介绍了如何使用 频率表（frequency tables）来描述这样的数据集，章节 2.2.3 则介绍如何将数据集划分到不同的分组。\n章节 2.3 讨论了如何使用统计指标来总结数据集，统计指标往往是由数据集确定的量化数值。章节 2.3.1 介绍了用于描述数据集中心（center）的三个统计指标：样本均值（sample mean）、样本中位数（sample median）和样本众数（sample mode）。章节 2.3.2 会介绍样本方差（sample variance）及样本标准差（sample standard deviation）。样本均值、样本中位数、样本众数、样本方差和标准差这些统计数据用于描述数据集中数值的分布。章节 2.3.3 会介绍样本的百分位数（sample percentiles），样本百分位数这个统计指标可以告诉我们数据集中哪个值大于所有数据的 95%。\n章节 2.4 节介绍了数据样本集中的切比雪夫不等式（Chebyshev’s inequality），切比雪夫不等式给出了与样本均值相差超过 \\(k\\) 倍样本标准差的数据比例的上限。虽然切比雪夫不等式适用于所有数据集，但在某些情况下（例如 章节 2.5 中讨论的正态分布数据集），我们可以获得更精准的数据比例。\n在 章节 2.5 中，我们注意到，当数据分布符合钟形（bell-shaped）时，我们认为该数据集是近似正态的，此时，位于样本均值 \\(k\\) 个样本标准差内的数据比例可以根据所谓的经验法则（empirical rule）给出更精确的估计。\n章节 2.6 中关注的是成对数据（paired data），并介绍了如何使用散点图（scatter diagram）来描述成对数据以及样本相关系数（sample correlation coefficient）。样本相关系数是一个统计量，该值表示成对数据中第一个值与第二个值之间相关联的程度。\n章节 2.7 介绍了国民收入分配，洛伦兹曲线（Lorenz curve）（ L(p)）和基尼系数（Gini index）。洛伦兹曲线给出了收入较低的百分之 \\(p\\) 的居民收入占总收入的比例，基尼系数则是用于衡量收入分配不平等程度的指标。\n章节 2.8 介绍了如何使用 R 来分析数据集。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_2",
    "href": "chapter_2/2.html#sec-2_2",
    "title": "2  描述统计",
    "section": "2.2 描述数据集",
    "text": "2.2 描述数据集\n应当用数据清晰、简洁的显示研究结果，以便研究者可以迅速把握数据的关键特征。多年来，人们发现，对于展示数据而言，表格和图是特别有用的方式。图表常常可以揭示数据的重要特征，如数据的范围、集中程度和对称性。本节将介绍一些常见的数据图表展示方式。\n\n2.2.1 频率表和图\n如果一个数据集中的数据差异较小，我们便可以以频率表（frequency table）的形式来方便的展现该数据集。例如，表格 2.1 就是一个数据集的频率表，该数据集由 42 名最近毕业的电子工程专业的大学生的起始年薪（以千美元为单位，四舍五入）构成。表格 2.1 告诉我们，最低起薪为 57000 美元，并且有四名毕业生的起薪为 57000 美元；最高起薪为 70000 美元，并且有一名学生的起薪为 70000 美元；最为普遍的起薪为 62000 美元，并且有 10 名学生拿到了 62000 美元的起薪。\n\n\n代码\nlibrary(knitr)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ndf &lt;- data.frame(\"Starting Salary\" = ss, \"Frequency\" = f)\nkable(df, align = \"l\")\n\n\n\n\n表格 2.1: 起薪分布\n\n\n\n\n\n\nStarting.Salary\nFrequency\n\n\n\n\n57\n4\n\n\n58\n1\n\n\n59\n3\n\n\n60\n5\n\n\n61\n8\n\n\n62\n10\n\n\n63\n0\n\n\n64\n5\n\n\n66\n2\n\n\n67\n3\n\n\n70\n1\n\n\n\n\n\n\n\n\n可以用线图（line graph）来直观地显示频率表中的数据。如 图 2.1，在线图中，水平坐标轴用于绘制不同的数据值，而垂直直线的高度用于表示对应数据值出现的频率。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value_end = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1),  \n  value_start = rep(0, 11) \n)  \n\n# 将类别转换为因子，以确保正确的顺序  \ndf$salary &lt;- factor(df$salary, levels = df$salary, ordered = TRUE)  \n \nggplot(df, aes(x = salary, y = value_start, yend = value_end, color = salary)) +  \n  geom_segment(size = 2) +                    # 绘制水平线表示每个“条形”  \n  geom_point(aes(y = value_end), size = 3) +  # 在每个“条形”的末端添加点  \n  theme_minimal() +  \n  labs(x = \"Starting Salary\", y = \"Frequency\") +  \n  scale_y_continuous(breaks = seq(1, 10, by = 1)) +  \n  theme(legend.position = \"none\")           # 调整图例位置\n\n\n\n\n\n\n\n\n图 2.1: 起薪线图\n\n\n\n\n\n当为 图 2.1 中的线条增加厚度时，图 2.1 就变成了 图 2.2 所示的条形图（bar graph）。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\n)  \n\n# 将类别转换为因子，以确保正确的顺序  \ndf$salary &lt;- factor(df$salary, levels = df$salary, ordered = TRUE)  \n \nggplot(df, aes(x = salary, y = value)) +  \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +  \n  theme_minimal() +  \n  xlab(\"Starting Salary\") +  \n  ylab(\"Frequency\") +\n  scale_y_continuous(breaks = seq(1, 10, by = 2))\n\n\n\n\n\n\n\n\n图 2.2: 起薪条形图\n\n\n\n\n\n另一种用于表示频数表的图形是折线图（frequency polygon），在折线图中，对于在数据集中出现的不同的数据值，其出现的次数为纵坐标，以此画出对应的点，然后用直线将这些点依次连接起来。图 2.3 给出了 表格 2.1 对应的折线图。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\n)  \n\nggplot(df, aes(x=salary, y=value)) +   \n  geom_line() +  \n  labs(x=\"Starting Salary\", y=\"Frequency\") + \n  scale_y_continuous(breaks = seq(1, 10, by = 2)) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n图 2.3: 起薪折线图\n\n\n\n\n\n\n\n2.2.2 相对频率表和图\n一个数据集中有 \\(n\\) 个值，如果 \\(f\\) 是某个特定值的频率，那么\\(\\frac{f}{n}\\) 为该特定值的相对频率（relative frequency）。也就是说，一个值的相对频率是数据集中具有该值的数据所占的比例。可以用线图、条形图、折线图来表示相对频率。事实上，在相对频率图中，除了纵坐标的值是绝对频率图中的值除以数据点总数外，相对频率图看起来和绝对频率图没什么不同。\n\n例子 2.1 表格 2.2 是 表格 2.1 的相对频率表。将 表格 2.1 中相应的频率除以数据集的大小（42） 得到其对应的相对频率表。\n\n\n\n代码\nlibrary(knitr)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ncnt = sum(f)\nf &lt;- f / cnt\n\ndf &lt;- data.frame(\"Starting Salary\" = ss, \"Relative Frequency\" = f)\nkable(df, align = \"l\")\n\n\n\n\n表格 2.2: 起薪分布相对频率表\n\n\n\n\n\n\nStarting.Salary\nRelative.Frequency\n\n\n\n\n57\n0.0952381\n\n\n58\n0.0238095\n\n\n59\n0.0714286\n\n\n60\n0.1190476\n\n\n61\n0.1904762\n\n\n62\n0.2380952\n\n\n63\n0.0000000\n\n\n64\n0.1190476\n\n\n66\n0.0476190\n\n\n67\n0.0714286\n\n\n70\n0.0238095\n\n\n\n\n\n\n\n\n当数据集中的数据不是数值型数据时，通常使用饼图（pie chart）来表示相对频率。首先画一个圆，然后将其切分成不同的扇形区域，每一个扇区对应数据集中的一种数据类型。在饼图中，扇区的面积表示数据值的相对频率，其面积等于圆的总面积乘以数据值的相对频率。\n\n例子 2.2 根据一家肿瘤专科诊所登记的最近 200 名患者的数据，得到了一个关于不同类型肿瘤患者数的数据集。图 2.4 使用饼图的形式来显示如上的数据集。\n\n\n代码\nlibrary(knitr)\n\ntype &lt;- c(\"Melanoma\", \"Bladder\", \"Colon\", \"Lung\", \"Breast\", \"Prostate\")\nnum &lt;- c(9, 12, 32, 42, 50, 55)  \nvalue &lt;- num / sum(num)\n\ndf &lt;- data.frame(\"Type of Cancer\" = type, \"Number of New Cases\" = num, \"Relative Frequency\" = value)\n\nkable(df, align = \"l\")\n\n\n\n\n\nType.of.Cancer\nNumber.of.New.Cases\nRelative.Frequency\n\n\n\n\nMelanoma\n9\n0.045\n\n\nBladder\n12\n0.060\n\n\nColon\n32\n0.160\n\n\nLung\n42\n0.210\n\n\nBreast\n50\n0.250\n\n\nProstate\n55\n0.275\n\n\n\n\n\n\n\n\n代码\nlibrary(ggplot2)\n  \n# 提供的数据  \ntype &lt;- c(\"Melanoma\", \"Bladder\", \"Colon\", \"Lung\", \"Breast\", \"Prostate\")\nnum &lt;- c(9, 12, 32, 42, 50, 55)  \nvalue &lt;- num / sum(num)\n\ndf &lt;- data.frame(type = type, num = num, value = value)\ndf$label &lt;- paste(df$type, \"\\n\", round(df$value * 100, 1), \"%\", sep=\"\") \n\n# 绘制饼图  \nggplot(df, aes(x = \"\", y = value, fill = type)) +  \n  geom_bar(width = 1, stat = \"identity\") +  \n  coord_polar(\"y\", start = 0) +  \n  theme_void() +  \n  theme(legend.title = element_blank()) +  \n  scale_fill_brewer(palette = \"Pastel1\") +  \n  labs(fill = \"type\") +  \n  geom_text(aes(label = label),   \n            position = position_stack(vjust = 0.5)) + # 添加百分比标签\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n图 2.4: 诊所数据饼图\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n虽然我们经常使用饼图，尤其是在商业分析中，饼图更是得到了广泛的使用，但是统计学家则一直很排斥使用饼图。因为人们对长度的判断比面积更为精确，因此统计学家更倾向于使用条形图。在 R 中，对饼图的支持要比其他的工具差很多。\n\n\n\n\n2.2.3 分组数据，直方图，肩形图和茎叶图\n如 章节 2.2.2 所述，使用线图或条形图绘制数据值的频率通常是描述数据集的有效方法。然而，对于那些不同数值数量太多的数据集而言，就无法使用线图或条形图的方法来对数据进行描述。在这种情况下，我们可以先将数值分组或按类别进行分类，然后绘制落在每个分组中的数据值的数量。分组数量的选取需要在以下两者之间进行取舍：\n\n较少的分组，但是将会丢失实际数据值中的很多信息；\n较多多的分组，但是将导致每个分组中的数值频率太小，以至于无法从图中辨别出数据模型。\n\n尽管典型的分组数为 5 ~ 10 个，但是适当的分组数量来自主观选择。当然，我们可以尝试不同的分组数，并对比看看哪张图表的效果最好。尽管不是必须的，但是在选择分组数时，通常会让不同分组之间的间隔长度保持一致。\n分组的端点（endpoint）称之为分组边界（class boundaries）。我们将会采用左端包含原则，该原则规定分组中的数据包含其左端点，但不包含其右端。因此，例如，20–30 这个分组包含所有 \\(\\ge\\) 20 且 \\(&lt;\\) 30 的值。\n表格 2.3 给出了 200 只白炽灯的使用寿命。表格 2.4 为 表格 2.3 数据的分组频率表，其分组的间隔长度为 100，第一个分组从 500 开始。\n\n\n代码\nlibrary(knitr)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\nkable(matrix(data, nrow = 20, ncol = 10, byrow = TRUE))\n\n\n\n\n表格 2.3: 200 个 白炽灯的寿命（Hour）\n\n\n\n\n\n\n1067\n919\n855\n1092\n1157\n1195\n1022\n978\n923\n1333\n\n\n521\n933\n930\n807\n999\n932\n901\n1324\n996\n780\n\n\n1187\n1067\n824\n653\n844\n814\n1037\n1151\n1026\n1147\n\n\n1039\n1083\n1023\n984\n1134\n932\n998\n996\n610\n916\n\n\n1196\n785\n1162\n1170\n1195\n1340\n832\n1009\n811\n1217\n\n\n928\n1153\n954\n1063\n1035\n944\n818\n1250\n900\n1106\n\n\n1118\n1037\n980\n935\n1103\n1000\n863\n990\n883\n867\n\n\n1040\n1289\n856\n924\n938\n1078\n1133\n765\n1001\n895\n\n\n1126\n936\n929\n950\n1122\n938\n1157\n1151\n1085\n896\n\n\n946\n858\n1002\n909\n1049\n940\n1203\n1078\n704\n621\n\n\n958\n760\n878\n934\n788\n1143\n1035\n1112\n990\n1258\n\n\n699\n1083\n801\n1122\n1180\n1106\n775\n1105\n709\n860\n\n\n918\n1156\n920\n948\n905\n972\n1035\n1045\n970\n1237\n\n\n956\n1102\n1009\n765\n958\n902\n958\n1311\n1037\n702\n\n\n1071\n1069\n830\n1063\n1077\n1021\n1062\n1157\n1122\n1115\n\n\n833\n1320\n890\n1303\n1011\n1102\n854\n1178\n1138\n951\n\n\n1101\n949\n992\n966\n910\n1058\n730\n980\n935\n1069\n\n\n1170\n1067\n931\n970\n932\n904\n1192\n922\n1150\n1091\n\n\n880\n1029\n658\n912\n1292\n1116\n880\n1173\n1184\n954\n\n\n824\n529\n1081\n1171\n705\n1425\n1110\n1149\n972\n1002\n\n\n\n\n\n\n\n\n\n\n代码\nlibrary(knitr)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\nintervals &lt;- seq(500, 1500, by = 100)\ngroup &lt;- cut(data, intervals, right=FALSE)\nkable(table(\"Class Interval\" = group))\n\n\n\n\n表格 2.4: 200 个 白炽灯的寿命（Hour）分布表\n\n\n\n\n\n\nClass.Interval\nFreq\n\n\n\n\n[500,600)\n2\n\n\n[600,700)\n5\n\n\n[700,800)\n12\n\n\n[800,900)\n25\n\n\n[900,1e+03)\n58\n\n\n[1e+03,1.1e+03)\n41\n\n\n[1.1e+03,1.2e+03)\n43\n\n\n[1.2e+03,1.3e+03)\n7\n\n\n[1.3e+03,1.4e+03)\n6\n\n\n[1.4e+03,1.5e+03)\n1\n\n\n\n\n\n\n\n\n分组数据的条形图中，其不同的分组彼此相邻，我们称之为直方图（histogram）。直方图的纵坐标可以表示分组的频率或相对频率，当表示分组频率时该图为频率直方图，当表示分组相对频率时为相对频率直方图。图 2.5 给出了 表格 2.4 中数据的频率直方图。\n\n\n代码\nlibrary(ggplot2)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\ndf &lt;- data.frame(value = data)\nbreaks_vector &lt;- seq(from = 500, to = 1500, by = 100)\n\nggplot(df, aes(x = value)) +  \n  geom_histogram(breaks = breaks_vector, fill = \"lightblue\", color = \"black\") +  \n  xlab(\"incandescent lamps lifetime(Hour)\") +  \n  ylab(\"Frequency\")\n\n\n\n\n\n\n\n\n图 2.5: 200 个 白炽灯的寿命（Hour）分布直方图\n\n\n\n\n\n很多时候，我们需要绘制累积频率图（cumulative frequency graph）或者累积相对频率图（cumulative relative frequency graph）。在累积频率（相对频率）图的横坐标上，一个点代表一个可能的数据值，其对应的纵坐标为值小于或等于该数据值的数据数量（或比例）。图 2.6 给出了 表格 2.3 中所示数据的累积相对频率图。从这个图中我们可以发现，使用寿命小于 1500（小时） 的白炽灯占比为 100%，使用寿命 \\(\\le\\) 900 的占比大约为 40% ，使用寿命 \\(\\le\\) 1100 的占比大约为 80%，……我们通常又把累积频率图称为肩形图（ogive）。\n\n\n代码\nlibrary(ggplot2)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\ndf &lt;- data.frame(value = data)\ndf$value &lt;- df$value[order(df$value)]\ndf$cumulative_freq &lt;- cumsum(rep(1/nrow(df), nrow(df))) \n\nggplot(df, aes(x = value, y = cumulative_freq)) +  \n  geom_step(direction = \"vh\", color = \"blue\") +  \n  xlab(\"incandescent lamps lifetime\") +  \n  ylab(\"Cumulative Relative Frequency\") +   \n  theme_minimal()\n\n\n\n\n\n\n\n\n图 2.6: 200 个 白炽灯的寿命（Hour）累积频率图\n\n\n\n\n\n对于中小型数据集而言，茎叶图（stem-leaf plot）是一种有效的数据组织方式。可以把每个数据值分为茎和叶两部分来获得茎叶图。例如，如果数据都是两位整数值，那么我们可以把十位数作为茎，个位数作为叶。例如，值 62 的茎叶图表示为：\n\n\n62 的茎叶图\n\nStem Leaf\n  6   2\n\n62，67 两个数据的茎叶图表示为：\n\n\n62，67 的茎叶图\n\nStem Leaf\n  6  2,7\n\n\n例子 2.3 表格 2.5 给出了美国 35 个城市的每日最低气温的月平均值和年平均值。表格 2.5 中的每日最低温度的年平均值可以用下面的茎叶图表示。\n\n\n代码\ndf &lt;- read.table(\"../misc/US_minimum_temperature.csv\", header=TRUE, sep=\",\")\nstem(df$Annual.avg.)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  2 | 9\n  3 | 034\n  3 | 56699\n  4 | 0001244\n  4 | 55567899\n  5 | 112\n  5 | 677899\n  6 | \n  6 | 9\n  7 | 0\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n由于 R 中的 stem() 并不支持小数，因此对于 表格 2.5 中所示的年平均值会先进行四舍五入转成整数，然后再画茎叶图。因此，这里给的茎叶图和原书中的不一致。\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_minimum_temperature.csv\", header=TRUE, sep=\",\")\nkable(df)\n\n\n\n\n表格 2.5: 1961年~1990年，美国指定城市的每日最低气温表。数据来源：Source: U.S. National Oceanic and Atmospheric Administration, Climatography of the United States, No. 81。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState\nStation\nJan.\nFeb.\nMar.\nApr.\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nAnnual.avg.\n\n\n\n\nAL\nMobile\n40.0\n42.7\n50.1\n57.1\n64.4\n70.7\n73.2\n72.9\n68.7\n57.3\n49.1\n43.1\n57.4\n\n\nAK\nJuneau\n19.0\n22.7\n26.7\n32.1\n38.9\n45.0\n48.1\n47.3\n42.9\n37.2\n27.2\n22.6\n34.1\n\n\nAZ\nPhoenix\n41.2\n44.7\n48.8\n55.3\n63.9\n72.9\n81.0\n79.2\n72.8\n60.8\n48.9\n41.8\n59.3\n\n\nAR\nLittle Rock\n29.1\n33.2\n42.2\n50.7\n59.0\n67.4\n71.5\n69.8\n63.5\n50.9\n41.5\n33.1\n51.0\n\n\nCA\nLos Angeles\n47.8\n49.3\n50.5\n52.8\n56.3\n59.5\n62.8\n64.2\n63.2\n59.2\n52.8\n47.9\n55.5\n\n\nCA\nSacramento\n37.7\n41.4\n43.2\n45.5\n50.3\n55.3\n58.1\n58.0\n55.7\n50.4\n43.4\n37.8\n48.1\n\n\nCA\nSan Diego\n48.9\n50.7\n52.8\n55.6\n59.1\n61.9\n65.7\n67.3\n65.6\n60.9\n53.9\n48.8\n57.6\n\n\nCA\nSan Francisco\n41.8\n45.0\n45.8\n47.2\n49.7\n52.6\n53.9\n55.0\n55.2\n51.8\n47.1\n42.7\n49.0\n\n\nCO\nDenver\n16.1\n20.2\n25.8\n34.5\n43.6\n52.4\n58.6\n56.9\n47.6\n36.4\n25.4\n17.4\n36.2\n\n\nCT\nHartford\n15.8\n18.6\n28.1\n37.5\n47.6\n56.9\n62.2\n60.4\n51.8\n40.7\n32.8\n21.3\n39.5\n\n\nDE\nWilmington\n22.4\n24.8\n33.1\n41.8\n52.2\n61.6\n67.1\n65.9\n58.2\n45.7\n37.0\n27.6\n44.8\n\n\nDC\nWashington\n26.8\n29.1\n37.7\n46.4\n56.6\n66.5\n71.4\n70.0\n62.5\n50.3\n41.1\n31.7\n49.2\n\n\nFL\nJacksonville\n40.5\n43.3\n49.2\n54.9\n62.1\n69.1\n71.9\n71.8\n69.0\n59.3\n50.2\n43.4\n57.1\n\n\nFL\nMiami\n59.2\n60.4\n64.2\n67.8\n72.1\n75.1\n76.2\n76.7\n75.9\n72.1\n66.7\n61.5\n69.0\n\n\nGA\nAtlanta\n31.5\n34.5\n42.5\n50.2\n58.7\n66.2\n69.5\n69.0\n63.5\n51.9\n42.8\n35.0\n51.3\n\n\nHI\nHonolulu\n65.6\n65.4\n67.2\n68.7\n70.3\n72.2\n73.5\n74.2\n73.5\n72.3\n70.3\n67.0\n70.0\n\n\nID\nBoise\n21.6\n27.5\n31.9\n36.7\n43.9\n52.1\n57.7\n56.8\n48.2\n39.0\n31.1\n22.5\n39.1\n\n\nIL\nChicago\n12.9\n17.2\n28.5\n38.6\n47.7\n57.5\n62.6\n61.6\n53.9\n42.2\n31.6\n19.1\n39.5\n\n\nIL\nPeoria\n13.2\n17.7\n29.8\n40.8\n50.9\n60.7\n65.4\n63.1\n55.2\n43.1\n32.5\n19.3\n41.0\n\n\nIN\nIndianapolis\n17.2\n20.9\n31.9\n41.5\n51.7\n61.0\n65.2\n62.8\n55.6\n43.5\n34.1\n23.2\n42.4\n\n\nIA\nDes Moines\n10.7\n15.6\n27.6\n40.0\n51.5\n61.2\n66.5\n63.6\n54.5\n42.7\n29.9\n16.1\n40.0\n\n\nKS\nWichita\n19.2\n23.7\n33.6\n44.5\n54.3\n64.6\n69.9\n67.9\n59.2\n46.6\n33.9\n23.0\n45.0\n\n\nKY\nLouisville\n23.2\n26.5\n36.2\n45.4\n54.7\n62.9\n67.3\n65.8\n58.7\n45.8\n37.3\n28.6\n46.0\n\n\nLA\nNew Orleans\n41.8\n44.4\n51.6\n58.4\n65.2\n70.8\n73.1\n72.8\n69.5\n58.7\n51.0\n44.8\n58.5\n\n\nME\nPortland\n11.4\n13.5\n24.5\n34.1\n43.4\n52.1\n58.3\n57.1\n48.9\n38.3\n30.4\n17.8\n35.8\n\n\nMD\nBaltimore\n23.4\n25.9\n34.1\n42.5\n52.6\n61.8\n66.8\n65.7\n58.4\n45.9\n37.1\n28.2\n45.2\n\n\nMA\nBoston\n21.6\n23.0\n31.3\n40.2\n49.8\n59.1\n65.1\n64.0\n56.8\n46.9\n38.3\n26.7\n43.6\n\n\nMI\nDetroit\n15.6\n17.6\n27.0\n36.8\n47.1\n56.3\n61.3\n59.6\n52.5\n40.9\n32.2\n21.4\n39.0\n\n\nMI\nSault Ste. Marie\n4.6\n4.8\n15.3\n28.4\n38.4\n45.5\n51.3\n51.3\n44.3\n36.2\n25.9\n11.8\n29.8\n\n\nMN\nDuluth\n-2.2\n2.8\n15.7\n28.9\n39.6\n48.5\n55.1\n53.3\n44.5\n35.1\n21.5\n4.9\n29.0\n\n\nMN\nMinneapolis-St. Paul\n2.8\n9.2\n22.7\n36.2\n47.6\n57.6\n63.1\n60.3\n50.3\n38.8\n25.2\n10.2\n35.3\n\n\nMS\nJackson\n32.7\n35.7\n44.1\n51.9\n60.0\n67.1\n70.5\n69.7\n63.7\n50.3\n42.3\n36.1\n52.0\n\n\nMO\nKansas City\n16.7\n21.8\n32.6\n43.8\n53.9\n63.1\n68.2\n65.7\n56.9\n45.7\n33.6\n21.9\n43.7\n\n\nMO\nSt. Louis\n20.8\n25.1\n35.5\n46.4\n56.0\n65.7\n70.4\n67.9\n60.5\n48.3\n37.7\n26.0\n46.7\n\n\nMT\nGreat Falls\n11.6\n17.2\n22.8\n31.9\n40.9\n48.6\n53.2\n52.2\n43.5\n35.8\n24.3\n14.6\n33.1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_3",
    "href": "chapter_2/2.html#sec-2_3",
    "title": "2  描述统计",
    "section": "2.3 对数据集进行汇总",
    "text": "2.3 对数据集进行汇总\n如今的实验涉及到的数据规模通常比较大。例如，为了了解某些行为习惯对健康的影响，1951 年，医学统计学家 R. Doll 和 A. B. Hill 向英国的所有医生发起了一项调查问卷，并且回收到了大约 40,000 份问卷。问卷的问题涉及年龄、饮食习惯和吸烟习惯。随后，Doll 和 Hill 对问卷回复者进行了为期 10 年的跟踪调查，并对其中的死亡人员的死因进行了监测。为了感知如此大量的数据，需要选择适当的方法对数据进行总结。在本节中，我们将介绍一些汇总数据的统计指标，其中统计指标是一个数值，数据集决定了其统计指标的具体数值。\n\n\n\n\n\n\nThe British Doctors’ Study (1951–2001)\n\n\n\n1951 年，R. Doll 和 A. B. Hill 向英国的 6 万名医生发出调查问卷，并跟踪他们的吸烟情况和健康情况。根据跟踪情况，Doll 和 Hill 提交了两份报告（统称为英国医生研究）：1954 年提交的 The Mortality of Doctors in Relation to Their Smoking Habits 和 1956 年提交的 Lung Cancer and Other Causes of Death in Relation to Smoking。报告中公布了吸烟与疾病发病率的确凿科学证据，报告一经发布就震惊了世界，就连 Doll 本人也吓得戒掉了自己的重度烟瘾。\n针对英国医生的跟踪调查一直持续到 2001 年，当时参与问卷的大多数参与者已经故去，并且还在世的最年轻的参与者也已经七十多岁了。在近 50 年的研究中，研究人员公布了多项报告，这些报告强化了公众对吸烟会导致呼吸道疾病和心血管疾病的认知。\n关于这项研究的内容可以参阅：The British Doctors’ Study (1951–2001)。\n\n\n\n2.3.1 样本均值，样本中位数和样本众数\n在这一节中，我们将介绍一些用于描述数据集中心（center）的统计指标。首先，假设我们有一个由 \\(n\\) 个数据构成的数据集：\\(x_1，x_2，...，x_n\\) 。这 \\(n\\) 个数的算术平均数（arithmetic average）就是样本均值（sample mean）。\n\n定义 2.1 样本均值（sample mean） \\(\\overline{x}\\) 的定义如下：\n\\[\n\\overline{x} = \\frac{\\sum_{i=1}^{n}{x_i}}{n}\n\\tag{2.1}\\]\n\n如果 \\(a\\)，\\(b\\) 为常数，并且\n\\(y_i = ax_i+b, i\\in[1,n]\\)\n那么，数据集 \\(y_1,...,y_n\\) 的样本均值为：\n\\[\n\\begin{align}\n\\overline{y}&=\\frac{\\sum_{i=1}^{n}{ax_i+b}}{n} \\\\\n&= \\frac{\\sum_{i=1}^{n}{ax_i}}{n} + \\frac{\\sum_{i=1}^{n}{b}}{n} \\\\\n&= a\\overline{x}+b\n\\end{align}\n\\tag{2.2}\\]\n\n练习 2.1 2004 年至 2013 年，美国高尔夫球大师赛的获胜分数如下：\n\\(280, 278, 272, 276, 281, 279, 276, 281, 289, 280\\)\n请计算如上分数的 样本均值。\n\n\n答案 2.1. 比起直接将这些分数相加，对于每个分数而言，先减去 280 以获得新值 \\(y_i = x_i - 280\\) 会更容易计算其样本均值：\n\\(0, −2, −8, −4, 1, −1, −4, 1, 9, 0\\)\n\n\\(y_i\\) 的算术平均数为 \\(-\\frac{8}{10}\\)，因此 \\(\\overline{y}=-\\frac{8}{10}\\)，所以 \\(\\overline{x}=\\overline{y}+280=279.2\\)。\n有时，我们想要确定一个用频率表来描述的数据集的样本均值，在频率表中存在 \\(k\\) 个不同的值 \\(v_1,...,v_k\\)，以及它们对应的频率 \\(f_1,...,f_k\\)。该数据集由 \\(n=\\sum_{i=1}^{k}{f_i}\\) 个值组成，其中值 \\(v_i\\) 出现 \\(f_i\\) 次，因此这 \\(n\\) 个数据的样本均值为：\n\\[\n\\overline{x}=\\sum_{i=1}^{k}{\\frac{v_if_i}{n}}\n\\tag{2.3}\\]\n对上述计算进行展开，得到：\n\\(\\overline{x}=\\frac{f_1}{n}{v_1} + \\frac{f_2}{n}{v_2} + ... + \\frac{f_k}{n}{v_k}\\)\n因此，样本均值是数据集中不同值的加权平均数，其中 \\(v_i\\) 的权重等于 \\(n\\) 个数据中值等于 \\(v_i\\) 的数据的占比。\n\n练习 2.2 如下的频率表给出了青少年交响乐团的成员年龄分布。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;-data.frame(\n  Age = c(15, 16, 17, 18, 19, 20),\n  Frequency = c(2, 5, 11, 9, 14, 13)\n)\n\nkable(df, align = \"l\")\n\n\n\n\n\nAge\nFrequency\n\n\n\n\n15\n2\n\n\n16\n5\n\n\n17\n11\n\n\n18\n9\n\n\n19\n14\n\n\n20\n13\n\n\n\n\n\n计算该交响乐团中 54 位成员的年龄的样本均值。\n\n\n答案 2.2. \\(\\overline{x} = (15·2 + 16·5 + 17·11 + 18·9 + 19·14 + 20·13) / 54 ≈ 18.24\\)\n\n另一个用于表示数据集中心的统计指标是样本中位数（sample median），简单来说，中位数就是当数据集中的数据按递增顺序排列后，位于数据集中间的数。\n\n定义 2.2 把大小为 \\(n\\) 的数据集中的数据从小到大排序。如果 \\(n\\) 是奇数，则 样本中位数 就是第 \\(\\frac{(n + 1)}{2}\\) 个数；如果 \\(n\\) 是偶数，则 样本中位数 就是第 \\(\\frac{n}{2}\\) 个数和第 \\(\\frac{n}{2} + 1\\) 个数的平均值。\n\n因此，3 个数的样本中位数是其第 2 小的数；4 个数的样本中位数是第 2 小和第 3 小的数的平均值。\n\n练习 2.3 找出 练习 2.2 中的样本中位数。\n\n\n答案 2.3. 由于有 54 个数，因此当数据按递增顺序排列后，样本中位数是第 27 个数和第 28 个数的平均值。因此，样本中位数是 18.5。\n\n样本均值和样本中位数都是描述数据集中心趋势的、非常有用的统计指标。样本均值的计算会用到数据集中的所有数据，并且容易受到数据集中极端值（远远大于或小于数据集中大多数数据的数据）的影响。样本中位数的计算只会到数据集中的一个或两个数据，因此样本中位数不受数据集中的极端值的影响。样本均值更好还是样本中位数更好，取决于我们试图从数据中学习什么。\n\n如果政府有统一的个人所得税税率，并试图估计税收总额，那么可以使用居民收入的样本均值作为统计量指标。\n如果政府正在考虑建造保障房，并希望确定能够负担得起这种住房的居民人口比例，那么更好的方式则是使用样本中位数。\n\n\n练习 2.4 1972 年，Hoel, D. G. 发表了一篇论文 A representation of mor- tality data by competing risks。在这篇论文中，Hoel 首先让一组 5 周大的小白鼠接受 300rad 的辐射剂量，然后把这些小白鼠分成两组：第一组置于无菌环境中，第二组则置于常规的实验室环境。随后，Hoel 观察并记录这些小白鼠的生存天数。以下的茎叶图（茎以百天为单位）记录了因胸腺淋巴瘤死亡的小白鼠的数据：第一张图是生活在无菌条件下的小白鼠，第二张图是生活在普通实验室条件下的小白鼠。\n\n\n\n表格 2.6: 不同环境下的小白鼠实验\n\n\n\n\n\n无菌环境下的小白鼠\n\n\nStem\nLeaf\n\n\n\n\n1\n58, 92, 93, 94, 95\n\n\n2\n02, 12, 15, 29, 30, 37, 40, 44, 47, 59\n\n\n3\n01, 01, 21, 37\n\n\n4\n15, 34, 44, 85, 96\n\n\n5\n29,37\n\n\n6\n24\n\n\n7\n07\n\n\n8\n00\n\n\n\n\n\n\n正常实验室环境下的小白鼠\n\n\nStem\nLeaf\n\n\n\n\n1\n59, 89, 91, 98\n\n\n2\n35, 45, 50, 56, 61, 65, 66, 80\n\n\n3\n43, 56, 83\n\n\n4\n03, 14, 28, 32\n\n\n\n\n\n\n\n\n计算两组小白鼠的生存时间的样本均值和样本中位数。\n\n\n答案 2.4. 从茎叶图中可以清晰地看出，无菌环境下小白鼠的样本均值（344.07）大于常规实验室环境下小白鼠的样本均值（292.32）。另一方面，由于无菌环境下的小白鼠有 29 个数据值，所以其样本中位数是第 15-最大 的数据值，即 259。另一组小白鼠的样本中位数是第 10-最大 的数据值，即 265。因此，尽管第一组数据的样本均值大于第二组，但这两组数据的样本中位数却大致基本一致。其中的原因在于，第一组数据中大于 500 的 5 个数据对其样本均值的影响较大，但对其样本中位数的影响要小得多。事实上，如果把大于 500 的 5 个数据替换为任何其他五个大于或等于 259 的数据，其样本中位数将保持不变。从茎叶图来看，无菌环境可能延长了五只寿命最长的小白鼠的寿命，但无法确定无菌环境是否对其他小白鼠的寿命产生了什么别的影响。\n\n另一个用于表示数据集中心趋势的统计指标是 样本众数（sample mode）。在数据集中，出现频率最高的值为 样本众数。如果出现频率最高的值有多个，那么所有出现频率最高的这些数值都是 样本众数。\n\n练习 2.5 以下的频率表为抛 40 次骰子获得的结果。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;- data.frame(\n    Value = c(1, 2, 3, 4, 5, 6),\n    Frequency = c(9, 8, 5, 5, 6, 7)\n)\nkable(df, align = \"l\")\n\n\n\n\n\nValue\nFrequency\n\n\n\n\n1\n9\n\n\n2\n8\n\n\n3\n5\n\n\n4\n5\n\n\n5\n6\n\n\n6\n7\n\n\n\n\n\n\n计算其样本均值\n计算其样本中位数\n计算器样本众数\n\n\n\n答案 2.5. \n\n样本均值为 \\(\\overline{x}=(9 + 16 + 15 + 20 + 30 + 42) / 40 = 3.05\\)\n样本中位数为 第 20-最小 和 第 21-最小 的平均数 3\n样本众数为 1\n\n\n\n\n2.3.2 样本方差和样本标准差\n虽然我们已经介绍了用于描述数据集中心趋势的统计指标，但我们也对描述数据波动的统计量感兴趣。可以通过计算数据值与样本均值之间距离的平方的平均值来描述数据集中数据的波动，这就是样本方差（sample variance）。出于技术原因，在计算样本方差时，需要除以 \\(n-1\\) 而不是 \\(n\\)（\\(n\\) 是数据集的大小）。\n\n定义 2.3 对于数据集 \\({x_1,...,x_n}\\)，其 样本方差 \\(s^2\\) 的定义如下：\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}{n - 1}\n\\tag{2.4}\\]\n\n\n练习 2.6 计算如下两个数据集的样本方差：\n\nA: 3, 4, 6, 7, 10\nB: -20, 5, 15, 24\n\n\n\n答案 2.6. 对于 A 而言，其样本均值 \\(\\overline{x} = (3 + 4 + 6 + 7 + 10) / 5 = 6\\)，因此，其样本方差为： \\(s^2 = [(−3)^2 + (−2)^2 + 0^2 + 1^2 + 4^2] / 4 = 7.5\\)\n对于 B 而言，其样本均值也是 6，因此，其样本方差为： \\(s^2 = [(−26)^2 + (−1)^2 + 9^2 + (18)^2] / 3 ≈ 360.67\\)\n\n通过 Solution 2.6 可发现，虽然 A 和 B 的样本均值是一样的，但是 B 的样本方差远大于 A。\n在计算样本方差时，会经常用到如下的数学等式：\n\\[\n\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} = \\sum_{i=1}^{n}{x_i^2} - n\\overline{x}^2\n\\tag{2.5}\\]\n方程式 2.5 的证明过程如下：\n\\[\n\\begin{align}  \n\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} &= \\sum_{i=1}^{n}{(x_i^2 - 2x_i\\overline{x} + \\overline{x}^2)} \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - 2\\overline{x}\\sum_{i=1}^{n}{x_i} + \\sum_{i=1}^{n}{\\overline{x}^2} \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - 2n\\overline{x}^2 + n\\overline{x}^2 \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - n\\overline{x}^2\n\\end{align}\n\\]\n如果 \\(y_i = ax_i + b\\)，\\(i = 1,...,n\\)，则 \\(\\overline{y} = a\\overline{x} + b\\)，因此：\n\\(\\sum_{i=1}^{n}{(y_i - \\overline{y})^2} = a^2\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}\\)\n所以：\n\\[\ns_y^2 = a^2s_x^2\n\\tag{2.6}\\]\n换句话说，为数据集中的每个数据增加一个常数不会改变其样本方差；而让数据集中的每个数据乘以一个常数则会得到一个新的样本方差，新的样本方差等于原来的样本方差乘以该常数的平方。\n\n练习 2.7 下表给出了 1997 年至 2005 年间全球商业航空运输中导致人员死亡的事故数量。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;- data.frame(\n    Year=seq(1997, 2005, by=1),\n    Accidents = c(25, 20, 21, 18, 13, 13, 7, 9, 18))\n\nkable(df, align=\"l\")\n\n\n\n\n\nYear\nAccidents\n\n\n\n\n1997\n25\n\n\n1998\n20\n\n\n1999\n21\n\n\n2000\n18\n\n\n2001\n13\n\n\n2002\n13\n\n\n2003\n7\n\n\n2004\n9\n\n\n2005\n18\n\n\n\n\n\n根据如上的数据，计算航工事故的样本方差。\n\n\n答案 2.7. 将数据集中的数据都减去 18，我们得到一个新的数据集：\n\\(y = \\{7,2,3,0,−5,−5,−11,−9,0\\}\\)\n\\(\\overline{y} = \\sum_{i=1}^{9}{y_i} / 9 = -2\\)\n\\(\\sum_{i=1}^{9}{y_i^2} = 49 + 4 + 9 + 25 + 25 + 121 + 81 = 314\\)\n因为新的数据集的方差和原数据集是一样的，因此根据 方程式 2.5：\n\\(s^2 = \\frac{\\sum_{i=1}^{9}{y_i^2} - n\\overline{x}^2}{n - 1} = \\frac{314 - 9·4}{8} = 34.75\\)\n\n\n\n\n\n\n\n注释\n\n\n\n因为 \\(y_i = x_i - 20\\)，因此，根据 方程式 2.6， \\(y\\) 和 \\(x\\) 的方差是一样的。\n\n\n样本方差的平方根称之为 样本标准差（sample standard deviation）。\n\n定义 2.4 样本标准差 \\(s\\)的定义如下所示：\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}{n - 1}}\n\\tag{2.7}\\]\n\n\n\n2.3.3 样本百分位数和箱线图\n简单来说，数据集的 样本\\(100p\\)-百分位数 是指小于或等于数据集中 \\(100p\\%\\) 的数据所对应的数据值，其中 \\(0 \\le p \\le 1\\)。\n\n定义 2.5 样本\\(100p\\)-百分位数 是数据集中的一个数据值，这个值满足至少 \\(100p\\%\\) 的数据小于或等于它，并且至少 \\(100(1-p)\\%\\) 的数据大于或等于它。如果存在两个数据值满足这个条件，那么该数据集的 样本\\(100p\\)-百分位数 是这两个值的算术平均数。\n\n为了确定大小为 \\(n\\) 的数据集的样本\\(100p\\)-百分位数，我们需要确定这样的数据值，以使得该值满足如下的条件：\n\n至少有 \\(np\\) 个数据小于或等于该值\n至少有 \\(n(1-p)\\) 个数据大于或等于该值\n\n为了计算样本\\(100p\\)-百分位数，首先要对数据集进行升序排列。\n\n如果 \\(np\\) 不是整数，那么唯一满足前述条件的数据值是数据从小到大排序后，位置大于 \\(np\\) 的最小整数所对应的值。例如，如果 \\(n=22\\)，\\(p=0.8\\)，那么我们需要一个数据值，使得至少有 17.6 个数据小于或等于它，并且至少有 4.4 个数据大于或等于它。显然，只有第 18 小的值同时满足这两个条件，这就是 样本80-百分位数。\n如果 \\(np\\) 是整数，那么很容易发现 \\(np\\) 和 \\(np+1\\) 这两个位置的数据都满足前述条件，因此样本 \\(100p\\)-百分位数就是这两个数据值的算术平均数。例如，如果我们想计算大小为 20 的数据集的 90-百分位数，那么第 18-小 和第 19-小 的值都会使得至少有 90% 的数据小于或等于它们，并且至少有 10% 的数据大于或等于它们。因此，90-百分位数是这两个值的平均数。\n\n\n练习 2.8 表格 2.7 列出了 2006 年美国人口最多的 25 个城市的人口数。对于这组数据，找出：\n\n样本10-百分位数\n样本80-百分位数。\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_population.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.7: 2006 年 7 月，美国 25 个最大城市的人口数据\n\n\n\n\n\n\nRank\nCity\nPopulation\n\n\n\n\n1\nNew York, NY\n8250567\n\n\n2\nLos Angeles, CA\n3849378\n\n\n3\nChicago, IL\n2833321\n\n\n4\nHouston, TX\n2144491\n\n\n5\nPhoenix, AR\n1512986\n\n\n6\nPhiladelphia, PA\n1448394\n\n\n7\nSan Antonio, TX\n1296682\n\n\n8\nSan Diego, CA\n1256951\n\n\n9\nDallas, TX\n1232940\n\n\n10\nSan Jose, CA\n929936\n\n\n11\nDetroit, MI\n918849\n\n\n12\nJacksonville, FL\n794555\n\n\n13\nIndianapolis, IN\n785597\n\n\n14\nSan Francisco, CA\n744041\n\n\n15\nColumbus, OH\n733203\n\n\n16\nAustin, TX\n709893\n\n\n17\nMemphis, TN\n670902\n\n\n18\nFort Worth, TX\n653320\n\n\n19\nBaltimore, MD\n640961\n\n\n20\nCharlotte, NC\n630478\n\n\n21\nEl Paso, TX\n609415\n\n\n22\nMilwaukee, WI\n602782\n\n\n23\nBoston, MA\n590763\n\n\n24\nSeattle, WA\n582454\n\n\n25\nWashington, DC\n581530\n\n\n\n\n\n\n\n\n\n答案 2.8. \n\n因为样本的大小是 25，25·0.1 = 2.5，因此，样本10-百分位数就是样本第 3-小的数据，也就是 590763。\n因为 25·0.8 = 20，因此，样本80-百分位数是第 20-小和第 21-小的算术平均数，\\(\\frac{1512986 + 1448394}{2}\\)，也就是 1480690。\n\n\n样本50-百分位数，就是样本中位数。样本25-百分位数、样本50-百分位数、样本75-百分位数一起构成了样本四分位数（sample quartiles）。\n\n定义 2.6 样本25-百分位数称之为 第一四分位数（the first quartile），样本50-百分位数称之为 样本中位数 或 第二四分位数（the second quartile），样本75-百分位数称之为 第三四分位数（the third quartile）\n\n\n\n\n\n\n\n注释\n\n\n\n有时，也会把样本四分位数称为下四分位数和上四分位数：下四分位数（25-百分位数），中位数（50-百分位数），上四分位数（75-百分位数）。\n\n\n四分位数把数据集分为四个部分，大约 25% 的数据小于第一四分位数，25% 的数据位于第一四分位数和第二四分位数之间，25% 的数据位于第二四分位数和第三四分位数之间，剩余的 25% 的数据大于第三四分位数。\n\n练习 2.9 我们使用分贝（dB）来测量噪音。听力正常的人在安静环境下能听到的最弱的声音大约是 1dB，窃窃私语时的声音大约是 30dB，人们正常交谈时的声音大约是 70dB，收音机的音量大约是 100dB。当声音超过 120 dB 时，耳朵就开始感知到不适了。\n曼哈顿中央车站外测量到的 36 个不同时间点的噪音水平如下所示：\n\n\n曼哈顿中央车站噪音水平\n\n82, 89, 94, 110, 74, 122, 112, 95, 100, 78, 65, 60, 90, 83, 87, 75, 114, 85 69, 94, 124, 115, 107, 88, 97, 74, 72, 68, 83, 91, 90, 102, 77, 125, 108, 65\n\n计算如上数据的四分位数。\n\n\n答案 2.9. 因为 \\(n = 36\\)，所以四分位数对应的 \\(np\\) 均为整数，因此其对应的四分位数值为第 \\(np\\)-小和第 \\((np+1)\\)-小的平均数。\n\n第一四分位数（\\(p=0.25\\)）：第 9-小和第 10-小的平均值，也就是 74.5。\n第二四分位数（\\(p=0.5\\)）：第 18-小和第 19-小的平均值，也就是 89.5。\n第三四分位数（\\(p=0.75\\)）：第 27-小和第 28-小的平均值，也就是 104.5。\n\n\n我们经常用箱线图（box plot）绘制数据集的汇总统计指标。\n\n在横坐标轴上绘制一条从最小值到最大值的直线段。\n在这条直线上叠加一个 “箱子”，该箱子从第一四分位数开始一直延伸到第三四分位数，并用垂直线表示第二四分位数。\n\n例如，表格 2.1 中给出的 42 个起薪数据覆盖了从最低值 57000$ 到最高值 70000$ 之间的数。第一四分位数（第 11-小的值）是 60000\\(，第二四分位数（第 21-小和第 22-小的平均值）是 61500\\)，第三四分位数（第 32-小的值）是 64000$。该数据集的箱线图如 图 2.7 所示。\n\n\n代码\nlibrary(ggplot2)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ndf &lt;- data.frame(value=rep(ss, f))\nggplot(df, aes(x=value, y=\"\")) +\n  geom_boxplot() + \n  labs(x=\"Starting Salary\", y=\"\")\n\n\n\n\n\n\n\n\n图 2.7: 起薪线图\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n图 2.7 中的箱线图和文中对各四分位数的计算并不一致，这主要是因为该图使用 R 的 ggplot2 包绘制，对于该包而言，在绘制箱线图时，会剔除数据中可能的离群点（\\(\\pm 1.5IQR\\)），离群点在图中显示为一个点。\n\n\n箱线图上直线的长度等于数据集中的最大值减去数据集中的最小值，称为数据范围。箱线图中箱子的长度等于第三四分位数减去第一四分位数，称为四分位距（IQR: inter quaritle range）。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_4",
    "href": "chapter_2/2.html#sec-2_4",
    "title": "2  描述统计",
    "section": "2.4 切比雪夫不等式",
    "text": "2.4 切比雪夫不等式\n设 \\(\\overline {x}\\) 和 \\(s\\) 分别是数据集的样本均值和样本标准差。假设 \\(s &gt; 0\\)，切比雪夫不等式表明，对于 \\(\\forall k \\ge 1\\) ，至少有 \\((100 \\cdot (1−\\frac {1}{k^2})) \\%\\) 的数据位于 \\([ \\overline {x} − ks, \\overline {x} + ks]\\) 的区间内。\n\n令 \\(k = \\frac {3}{2}\\)，根据切比雪夫不等式，至少有 \\(55.56\\%\\) 的数据会位于 \\(\\overline {x} \\pm 1.5s\\) 的范围内。\n令 \\(k=2\\)，则至少有 \\(75\\%\\) 的数据位于 \\(\\overline {x} \\pm 2s\\) 的范围内。\n令 \\(k=3\\)，则至少有 \\(88.9\\%\\) 的数据位于 \\(\\overline {x} \\pm 3s\\) 的范围内。\n\n\n2.4.1 切比雪夫不等式\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。\n令 \\(S_k=\\{|x_i - \\overline{x}| \\lt ks, i \\in [1, n]\\}\\)，即 \\(S_k\\) 为距离 \\(\\overline{x}\\) \\(k\\) 个标准差以内的数据构成的集合。\n令 \\(|S_k|\\) 为集合 \\(S_k\\) 中的元素个数。\n则有：\n\\[\n\\frac{|S_k|}{n} \\ge {1 - \\frac{n-1}{nk^2}} \\gt {1 - \\frac{1}{k^2}}, \\ \\ \\forall k \\ge 1\n\\tag{2.8}\\]\n方程式 2.8 就是切比雪夫不等式，其证明过程如下：\n\\[\n\\begin{align}\n(n-1)s^2 &= \\sum_{i=1}^{n}{(x_i-\\overline{x})^2} \\\\\n&= \\sum_{i \\in S_k}{{(x_i-\\overline{x})^2}} + \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}} \\\\\n& \\ge \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}}\n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\because \\forall i \\in S_k, \\ \\ |x_i - \\overline{x}| \\lt ks, \\\\\n&\\therefore \\forall i \\notin S_k, \\ \\ |x_i - \\overline{x}| \\ge ks, \\\\\n&\\therefore \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}} \\ge \\sum_{i \\notin S_k}{k^2s^2} \\\\\n&=k^2s^2(n-|S_k|)\n\\end{align}\n\\]\n\\[\n\\therefore (n-1)s^2 \\ge k^2s^2(n-|S_k|)\n\\tag{2.9}\\]\n当 \\(s^2 \\ne 0\\) 时，对于 方程式 2.9 的等式两边都除以 \\(nk^2s^2\\)，得到：\n\\[\n\\begin{align}\n&\\frac{n-1}{nk^2} \\ge \\frac{n-|S_k|}{n}, \\\\\n&\\therefore \\frac{n-1}{nk^2} \\ge 1-\\frac{|S_k|}{n} \\\\\n&\\therefore \\frac{|S_k|}{n} \\ge 1-\\frac{n}{nk^2}+\\frac{1}{nk^2} \\\\\n&\\therefore \\frac{|S_k|}{n} \\ge 1-\\frac{1}{k^2}\n\\end{align}\n\\]\n由于切比雪夫不等式的通用性，对于给定的数据集，实际位于 \\([\\overline{x}-ks, \\overline{x}+ks]\\) 区间内的数据的百分比可能比切比雪夫不等式给出的下限要大一点。\n\n例子 2.4 表格 2.8 给出了 2013 年 6 月美国最畅销的 10 款汽车。根据数据可知：\\(\\overline{x}=35.33\\)，\\(s=11.86\\)，当 \\(k=\\frac{3}{2}\\) 时，至少有 55.55%（\\(100(1-\\frac{1}{k^2})\\%\\)）的数据位于 [17.54, 53.12]（\\([\\overline{x}-ks, \\overline{x}+ks]\\)）区间内。而实际上，对于表中的数据而言，有 \\(90\\%\\) 的数据落在了这个区间。\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_cars.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.8: 2013 年 6 月美国最畅销的 10 款汽车\n\n\n\n\n\n\nRank\nModel\nSales.Volume.in.thousands.of.vehicles.\n\n\n\n\n1\nFord F Series\n68.0\n\n\n2\nChevrolet Silverado\n43.3\n\n\n3\nToyota Camry\n35.9\n\n\n4\nChevrolet Cruze\n32.9\n\n\n5\nHonda Accord\n31.7\n\n\n6\nHonda Civic\n29.7\n\n\n7\nDodge Ram\n29.6\n\n\n8\nFord Escape\n28.7\n\n\n9\nNissan Altima\n26.9\n\n\n10\nHonda CR-V\n26.6\n\n\n\n\n\n\n\n\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。那么，\\(\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\) 的数据占比是多少呢？\n假设令 \\(N_k=\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\)，我们是否可以计算出 \\(\\frac{|N_k|}{n}\\)？\n当然！！！\n根据 方程式 2.8，我们可以得到：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{k^2}\n\\tag{2.10}\\]\n不过，利用接下来要介绍的单边切比雪夫不等式，我们可以得到一个更为精准的数据。\n\n\n2.4.2 单边切比雪夫不等式\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。\n令 \\(N_k=\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\)， \\(|N_k|\\) 为集合 \\(N_k\\) 中的元素个数，则有：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{1+k^2}\n\\tag{2.11}\\]\n我们称 方程式 2.11 为单边切比雪夫不等式（one-sided Chebyshev inequality），其证明过程如下：\n令 \\(y_i=x_i-\\overline{x}\\)，\\(i \\in [1,n]\\)，对于 \\(\\forall b \\gt 0\\)，有：\n\\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &\\ge \\sum_{i:y_i \\ge ks}{(y_i+b)^2} \\\\\n& \\ge \\sum_{i:y_i \\ge ks}{(ks+b)^2} \\\\\n& = |N_k| \\cdot (ks+b)^2\n\\end{align}\n\\tag{2.12}\\]\n因为 \\(|N_k|\\) 为 \\(y_i \\ge ks\\) 的元素个数，\\(ks\\) 和 \\(b\\) 都是正数，因此有： \\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &= \\sum_{i=1}^{n}{(y_i^2 + 2by_i + b^2)} \\\\\n&= \\sum_{i=1}^{n}{y_i^2} + 2b\\sum_{i=1}^{n}{y_i} + nb^2\n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\because y_i = x_i - \\overline{x} \\\\\n&\\therefore \\sum_{i=1}^{n}{y_i} = \\sum_{i=1}^{n}{(x_i - \\overline{x})} = \\sum_{i=1}^{n}{x_i} - n\\overline{x} = 0\n\\end{align}\n\\]\n所以有：\n\\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &= \\sum_{i=1}^{n}{y_i^2} + nb^2 \\\\\n&=(n-1)s^2 + nb^2\n\\end{align}\n\\tag{2.13}\\]\n根据 方程式 2.12 和 方程式 2.13，有：\n\\[\n(n-1)s^2 + nb^2 \\ge |N_k| \\cdot (ks+b)^2\n\\]\n进而得到：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{s^2 + b^2}{(ks + b)^2}\n\\tag{2.14}\\]\n因为 \\(b\\) 是任意大于 0 的数，因此我们可以令：\n\\[\nb=\\frac{s}{k}\n\\tag{2.15}\\]\n把 方程式 2.15 代入 方程式 2.14 得到 方程式 2.11：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{k^2 + 1}\n\\]\n根据 方程式 2.10，我们可以发现，在一个数据集中，超过样本均值的 2 倍标准差的数据最多占比 25%。但是利用 方程式 2.11 所示的单边切比雪夫不等式，我们可以将这个比例精确到最多占比 20%。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_5",
    "href": "chapter_2/2.html#sec-2_5",
    "title": "2  描述统计",
    "section": "2.5 正态分布数据集",
    "text": "2.5 正态分布数据集\n我们在实践中观察到的许多大数据集都具有形状相似的直方图。通常，这些直方图在样本中位数处达到峰值，然后在中位数的两侧以钟形对称的形式下降。我们称这样的数据集为正态数据集，称其直方图为正态直方图。图 2.8 (a) 展示了一个正态数据集的直方图。\n如果一个数据集的直方图接近正态直方图，我们说该数据集近似正态分布。例如，我们会说图 图 2.8 (b) 给出的直方图来自一个近似正态的数据集，而图 图 2.8 (c) 和图 图 2.8 (d) 给出的直方图则不是近似正态的数据集（因为每个直方图都太不对称）。与样本中位数不是近似对称的任何数据集都是偏态（skewed）分布。如果数据集的长尾在中位数右侧，则称为 “右偏”；如果数据集的长尾在中位数左侧，则称为 “左偏”。因此，图 图 2.8 (c) 中的数据集为左偏分布，而 图 2.8 (d) 中的数据集为右偏分布。\n\n代码\nlibrary(ggplot2)\n\nx &lt;- seq(1, 19)\ny &lt;- 100 - 10 * abs(x - mean(x))\ndf &lt;- data.frame(value=rep(x, y))\n\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\n\nx &lt;- seq(1, 19)\ny &lt;- 100 - 10 * abs(x - mean(x))\nvalue &lt;- rep(x, y)\nvalue &lt;- value[value != 17]\ndf &lt;- data.frame(value=value)\n\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\ndf &lt;- data.frame(value=rbeta(10000, 5, 2))\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\ndf &lt;- data.frame(value=rbeta(10000, 1, 5))\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 正态分布\n\n\n\n\n\n\n\n\n\n\n\n(b) 近似正态分布\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) 左偏分布\n\n\n\n\n\n\n\n\n\n\n\n(d) 右偏分布\n\n\n\n\n\n\n\n图 2.8: 不同数据集的直方图\n\n\n\n从正态直方图的对称性可以看出，一个近似正态分布的数据集，其样本均值和样本中位数大致相等。\n假设 \\(\\overline{x}\\) 和 \\(s\\) 分别是近似正态分布数据集的样本均值和样本标准差。经验法则（empirical rule）指定了观察到的数据位于 \\(s\\)、\\(2s\\)、\\(3s\\) 个样本均值 \\(x\\overline{x}\\) 内的大致比例。\n\n2.5.1 经验法则\n如果一个数据集是一个近似正态分布的数据集，其样本均值和样本标准差分别是 \\(\\overline{x}\\) 和 \\(s\\)，那么有如下的正确结论：\n\n大约有 68% 的观察数据会位于 \\(\\overline{x} \\pm s\\) 区间内\n大约有 95% 的观察数据会位于 \\(\\overline{x} \\pm 2s\\) 区间内\n大约有 99% 的观察数据会位于 \\(\\overline{x} \\pm 3s\\) 区间内\n\n\n如下的数据是工业工程专业的学生在统计学考试中的分数：\n43, 46, 52, 55, 55, 56, 58, 60, 62, 63, 64, 66, 66, 72, 74, 74, 75, 77, 77, 78, 83, 85, 85, 87, 88, 90, 91, 94\n通过其茎叶图，我们会发现如上数据的直方图近似正态分布。接下来我们用这份数据来评估一下经验法则。\n\n\n代码\nscores &lt;- c(43, 46, 52, 55, 55, 56, 58, 60, 62, 63, 64, 66, 66, 72, 74, 74, 75, 77, 77, 78, 83, 85, 85, 87, 88, 90, 91, 94)\nstem(scores)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  4 | 36\n  5 | 25568\n  6 | 023466\n  7 | 2445778\n  8 | 35578\n  9 | 014\n\n\n\n\n答案 2.10. 计算得到数据集的样本均值和样本方差：\\(\\overline{x} \\thickapprox 70.571\\)，\\(s \\thickapprox 14.354\\)。因此，根据经验法则：\n\n有 68% 的数据会位于 56.2~84.9 之间，但是实际上，数据集中只有 \\(\\frac{15}{28} \\%\\) 也就是 53.6% 的数据位于56.2~84.9 之间。\n有 95% 的数据会位于 41.68~99.28 之间，但是实际上，数据集中所有的数据都位于 41.68~99.28 之间。\n\n\n如果一个总体是由多个不同类型的子总体而构成，那么从这个总体中抽样得到的数据集通常不是正态分布。这种数据集的直方图通常看起来像是多个正态直方图的组合或叠加，因此在这种直方图上通常会有多个局部峰值。由于这些局部峰值处的直方图比其邻近值更高，因此这些峰值类似于众数。如 图 2.9 所示，在直方图中，具有两个局部峰值的数据集称之为双峰分布。\n\n\n代码\nsamples1 &lt;- rnorm(10000, mean=1, sd=1)  \nsamples2 &lt;- rnorm(10000, mean=5, sd=1)\ndf &lt;- data.frame(value=c(samples1, samples2))\n\nggplot(df, aes(x=value)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n图 2.9: 双峰分布直方图",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_6",
    "href": "chapter_2/2.html#sec-2_6",
    "title": "2  描述统计",
    "section": "2.6 成对数据集和样本相关系数",
    "text": "2.6 成对数据集和样本相关系数\n我们经常关注由成对数据值构成的数据集，这些数据集中的成对数据之间存在着某种关系。在这样的数据集中，如果每个成对数据都有一个 \\(x\\) 值和一个 \\(y\\) 值，那么我们就用 \\((x_i, y_i)\\) 表示第 \\(i\\) 个数据。例如，为了确定每天中午的温度（以摄氏度为单位）与当天生产的不合格零件数量之间的关系，一家公司记录了 表格 2.9 中的数据。对于这个数据集，\\(x_i\\) 代表第 \\(i\\) 天中午的摄氏温度，\\(y_i\\) 代表第 \\(i\\) 天生产的不合格零件数量。\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.9: 天气温度和产品缺陷量数据\n\n\n\n\n\n\nDay\nTemperature\nNumber.of.Defects\n\n\n\n\n1\n24.2\n25\n\n\n2\n22.7\n31\n\n\n3\n30.5\n36\n\n\n4\n28.6\n33\n\n\n5\n25.5\n19\n\n\n6\n32.0\n24\n\n\n7\n28.6\n27\n\n\n8\n26.5\n25\n\n\n9\n25.3\n16\n\n\n10\n26.0\n14\n\n\n11\n24.4\n22\n\n\n12\n24.8\n23\n\n\n13\n20.6\n20\n\n\n14\n25.1\n25\n\n\n15\n21.4\n25\n\n\n16\n23.7\n23\n\n\n17\n23.9\n27\n\n\n18\n25.2\n30\n\n\n19\n27.4\n33\n\n\n20\n28.3\n32\n\n\n21\n28.8\n35\n\n\n22\n26.6\n24\n\n\n\n\n\n\n\n\n在二维图上绘制成对数据集中的数据是一种表示成对数据集的有效方法，其中 \\(x\\) 轴代表成对数据的 \\(x\\) 值，\\(y\\) 轴代表成对数据的 \\(y\\) 值，这样的图称之为散点图（scatter diagram）。图 2.10 为 表格 2.9 中数据的散点图。\n\n\n代码\nlibrary(ggplot2)\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nggplot(df, aes(x=Temperature, y=Number.of.Defects)) + \n    geom_point()\n\n\n\n\n\n\n\n\n图 2.10: 天气温度和产品缺陷量散点图\n\n\n\n\n\n对于成对数据集而言，一个有趣问题是，比较大的 \\(x\\) 值是否倾向于与比较大的 \\(y\\) 值配对，小的 \\(x\\) 值是否与小的 \\(y\\) 值配对？如果情况并非如此，那么我们可能会质疑其中一个变量的较大的值是否倾向于与另一个变量的较小的值配对。通常，可以通过散点图来大致回答这些问题。例如，图 2.10 表明，高温和缺陷产品数量高之间似乎存在某种联系。为了对成对数据之间的这种关系进行定量度量，我们需要开发一个新的统计指标，以衡量 \\(x\\) 值与 \\(y\\) 值之间的配对程度。\n假设数据集由 \\(\\{(x_i, y_i)\\}\\) 组成，其中 \\(i = 1,...,n\\)，\\(\\overline{x}\\) 和 \\(\\overline{y}\\) 分别是 \\(x\\) 和 \\(y\\) 的样本均值。对于第 \\(i\\) 对数据，使用 \\(x_i - \\overline{x}\\) 作为 \\(x_i\\) 与其样本均值的偏差，使用 \\(y_i - \\overline{y}\\) 作为 \\(y_i\\) 与其样本均值的偏差。如果 \\(x_i\\) 的值比较大，那么 \\(x_i \\gt \\overline{x}\\)，所以 \\(x_i - \\overline{x} \\gt 0\\)。类似地， 如果 \\(x_i\\) 的值比较小，那么 \\(x_i \\lt \\overline{x}\\)，所以 \\(x_i - \\overline{x} \\lt 0\\)。对于 \\(y_i\\) 而言，同样如此。于是，我们可以得出以下结论：\n\n\n\n\n\n\n重要\n\n\n\n当 \\(x\\) 的较大值趋向于和 \\(y\\) 的较大值相关联，\\(x\\) 的较小值趋向于和 \\(y\\) 的较小值相关联时，则 \\(x_i - \\overline{x}\\) 和 \\(y_i- \\overline{y}\\) 的符号（无论正负）都将趋于相同。\n\n\n如果 \\(x_i - \\overline{x}\\) 和 \\(y_i - \\overline{y}\\) 的符号相同（无论正负），那么它们的乘积 \\((x_i - \\overline{x})(\\)y_i - )$ 是正数。因此，当 \\(x\\) 的较大值趋向于和 \\(y\\) 的较大值相关联，\\(x\\) 的较小值趋向于和 \\(y\\) 的较小值相关联时，\\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将趋向于一个较大的正数。事实上，当较大（小）的 \\(x\\) 与较大（小）的 \\(y\\) 配对时，不但所有的 \\((x_i - \\overline{x})(y_i - \\overline{y})\\) 的符号都是正的，而且当 \\((x_i - \\overline{x})\\) 的最大值与 \\((y_i - \\overline{y})\\) 的最大值配对、其对应的次大值配对、依次类推对 \\((x_i - \\overline{x})\\) 和 \\((y_i - \\overline{y})\\) 配对时，\\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将获得最大值。同理，当 \\(x_i\\) 的较大值倾向于和 \\(y_i\\) 的较小值配对时，\\(x_i - \\overline{x}\\) 和 \\(y_i - \\overline{y}\\) 的符号相反，所以 \\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将是一个较大的负数。\n\n定义 2.7 对于成对数据集 \\(\\{(x_i, y_i), i = 1,...,n\\}\\)，\\(s_x\\) 和 \\(s_y\\) 分别表示 \\(x\\) 和 \\(y\\) 的样本标准差，则 \\((x_i, y_i)\\) 的样本相关系数（sample correlation coefficient）\\(r\\) 的定义如下：\n\\[\n\\begin{align}\nr&=\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(y_i-\\overline{y})}}{(n-1)s_xs_y} \\\\\n&=\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sqrt{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} \\cdot \\sum_{i=1}^{n}{(y_i-\\overline{y})^2}}}\n\\end{align}\n\\tag{2.16}\\]\n\n当 \\(r \\gt 0\\) 时，成对数据集中的样本成正相关（positively correlated），当 \\(r \\lt 0\\) 时，样本成负相关（negatively correlated）。\n成对数据集的样本相关系数 \\(r\\) 具备如下的特性：\n\n\\(-1 \\le r \\le 1\\)\n\\(\\forall a&gt;0\\)， 如果 \\(y_i = ax_i + b\\)，则 \\(r=1\\)\n\\(\\forall a&lt;0\\)， 如果 \\(y_i = ax_i + b\\)，则 \\(r=-1\\)\n\\(\\forall a\\) 和 \\(\\forall c\\)，且 \\(a \\cdot c \\gt 0\\)，如果 \\(r\\) 是 \\(\\{(x_i, y_i)\\}\\) 的相关系数，则 \\(r\\) 也是 \\(\\{(ax_i + b, cy_i + d)\\}\\) 的相关系数\n\n\n特性 1 说明样本相关系数 \\(r\\) 总是介于 -1 和 +1 之间。\n特性 2 说明当成对数据之间存在线性关系并且 \\(x\\) 的较大（小）值趋向于和 \\(y\\) 的较大（小）值相关联时，\\(r\\) 等于 +1。\n特性 3 说明当成对数据之间存在线性关系并且 \\(x\\) 的较大（小）值趋向于和 \\(y\\) 的较小（大）值相关联时，\\(r\\) 等于 -1。\n特性 4 指出，当给每个 \\(x\\)（或 \\(y\\)） 变量加上一个常数，或将每个 \\(x\\)（或 \\(y\\)） 变量都乘以一个正数时，\\(r\\) 的值保持不变。特性 4 意味着 \\(r\\) 不依赖于测量数据的单位。例如，无论身高数据的测量单位是英尺还是英寸，也无论体重数据的测量单位是磅还是千克，一个人的身高和体重之间的样本相关系数都是一致的。此外，如果成对数据中的一个值是温度，那么无论该值是华氏温度还是摄氏温度，样本相关系数都是相同的。\n\n样本相关系数 \\(r\\) 的绝对值 \\(|r|\\) 用于表示 \\(x\\) 和 \\(y\\) 之间线性关系的强度。\\(|r| = 1\\) 意味着完美的线性关系，也就是说，可以用一条直线穿过 \\(\\{(xi,yi), i = 1, ..., n\\}\\) 中的所有数据点 。\\(|r| \\thickapprox 0.8\\) 意味着相对较强的线性关系，此时虽然没有任何一条直线可以穿过所有的数据点，但存在一条直线 “接近” 穿过所有的数据点。\\(|r| \\thickapprox 0.3\\) 意味着成对数据之间的线性关系相对较弱。\n\\(r\\) 的符号给定了相关性的方向。当较小的 \\(y\\) 倾向于和较小的 \\(x\\) 配对，而较大的 \\(y\\) 倾向于和较大的 \\(x\\) 配对时，对于这样的线性关系，\\(r \\gt 0\\)。而当较小的 \\(y\\) 倾向于和较大的 \\(x\\) 配对，而较大的 \\(y\\) 倾向于和较小的 \\(x\\) 配对时，对于这样的线性关系，\\(r \\lt 0\\)。图 2.11 显示了具有不同 \\(r\\) 值的数据集的散点图。\n\n代码\nlibrary(MASS)  \nlibrary(ggplot2)\n\n# 设置你想要的相关系数  \nrho &lt;- -0.5  # 例如，我们想要的相关系数是0.5  \n\n# 创建一个协方差矩阵。假设两个变量的方差都是1（对于标准化数据）  \n# 协方差矩阵的对角线元素是方差，非对角线元素是协方差（与相关系数相关）  \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf1 &lt;- as.data.frame(data)\ncolnames(df1) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 0   \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf2 &lt;- as.data.frame(data)\ncolnames(df2) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 0.9   \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf3 &lt;- as.data.frame(data)\ncolnames(df3) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 1\nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf4 &lt;- as.data.frame(data)\ncolnames(df4) &lt;- c(\"X\", \"Y\")\n\nggplot(df1, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df2, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df3, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df4, aes(x=X, y=Y)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) r = -0.5\n\n\n\n\n\n\n\n\n\n\n\n(b) r = 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) r = 0.9\n\n\n\n\n\n\n\n\n\n\n\n(d) r = 1\n\n\n\n\n\n\n\n图 2.11: 不同样本相关系数的数据散点图\n\n\n\n\n练习 2.10 计算 表格 2.9 所示的样本相关系数。\n\n\n答案 2.11. \n\n\n代码\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nr &lt;- cor(df$Temperature, df$Number.of.Defects)\nprint(r)\n\n\n[1] 0.418944\n\n\n这意味着气温和当天的缺陷产品数量之间存在着弱正相关性。\n\n\n例子 2.5 以下数据表给出了 10 个学生的静息心率（每分钟心跳次数）和其对应的受教育年限。图 2.12 展现了这些数据的散点图。这些数据的样本相关系数 \\(r=−0.7638\\)。负相关系数表明，对于这个数据集来说，高静息心率与低受教育年限紧密相关，而低静息心率则与高受教育年限紧密相关。\n\n\n代码\nlibrary(knitr)\nperson &lt;- seq(1:10)\nYears &lt;- c(12, 16, 13, 18, 19, 12, 18, 19, 12, 14)\nBPM &lt;- c(73, 67, 74, 63, 73, 84, 60, 62, 76, 71)\ndf &lt;- data.frame(Person=person, Years.of.School=Years, BPM=BPM)\n\nkable(df, align=\"l\")\n\n\n\n\n\nPerson\nYears.of.School\nBPM\n\n\n\n\n1\n12\n73\n\n\n2\n16\n67\n\n\n3\n13\n74\n\n\n4\n18\n63\n\n\n5\n19\n73\n\n\n6\n12\n84\n\n\n7\n18\n60\n\n\n8\n19\n62\n\n\n9\n12\n76\n\n\n10\n14\n71\n\n\n\n\n\n\n\n代码\nlibrary(ggplot2)\nperson &lt;- seq(1:10)\nYears &lt;- c(12, 16, 13, 18, 19, 12, 18, 19, 12, 14)\nBPM &lt;- c(73, 67, 74, 63, 73, 84, 60, 62, 76, 71)\ndf &lt;- data.frame(Person=person, Years.of.School=Years, BPM=BPM)\n\nggplot(df, aes(x=Years.of.School, y=BPM)) +\n    geom_point()\n\n\n\n\n\n\n\n\n图 2.12: 不同数据集的直方图\n\n\n\n\n\n\n\n\n\n\n\n\n相关性衡量的是变量之间的关联关系，而不是因果关系\n\n\n\n例子 2.5 中的数据集仅考虑了 10 名学生，因此不足以让人对受教育年限和心率之间的关系得出任何确凿的结论。此外，即使有更大规模的数据集，并且受教育年限高低与其静息心率之间同样存在着较强的负相关性，我们也没有理由得出 多接受几年教育会直接降低一个人的心率 的结论。也就是说，尽管高受教育年限往往与较低的静息心率有关联，但这并不意味着多受几年教育是导致较低心率的直接原因。通常，对这种关联性的解释在于，存在一个与所考虑的这两个变量都有相关性的隐藏因素。\n在 例子 2.5 中，可能是受教育年限高的人更了解健康领域的最新发现，因此可能更了解锻炼和良好营养的重要性。亦或者，可能不是知识在起作用，而是受过更多教育的人所从事的工作会让他们有更多时间进行锻炼，同时也可以获取更多薪水以补充良好的营养。受教育年限和静息心率之间的强烈负相关性可能是由受教育年限以及其他潜在因素的综合结果。\n\n\n接下来，我们将证明样本相关系数 \\(r\\) 的第一个特性：\\(|r| \\le 1\\)，当且仅当所有的数据点都在一条直线上时，\\(=\\) 成立。\n\\[\n\\begin{align}\n\\because &\\sum{(\\frac{x_i - \\overline{x}}{s_x} - \\frac{y_i - \\overline{y}}{s_y})^2} \\ge 0 \\\\\n\\therefore & \\sum{\\frac{(x_i - \\overline{x})^2}{s_x}} + \\sum{\\frac{(x_i - \\overline{x})^2}{s_x}} - 2 \\sum{\\frac{(x_i - \\overline{x})(y_i - \\overline{y})}{s_xs_y}} \\\\\n\\therefore & (n - 1) + (n - 1) -2(n - 1)r \\ge 0 \\\\\n\\therefore & 2(n - 1)(1 - r) \\ge 0 \\\\\n\\therefore & r \\le 1\n\\end{align}\n\\tag{2.17}\\]\n假设所有的数据点 \\({(x_i, y_i), i=1,...,n}\\) 都位于直线 \\(y_i = ax_i + b;\\ i=1,...n \\ \\& \\ a&gt;0\\) 上，则：\n\\[\n\\begin{align}\n& s_y^2=a^2s_x^2 \\\\\n& \\overline{y}=a\\overline{x} + b \\\\\n\\therefore & a = \\frac{s_y}{s_x}, \\ b = \\overline{y} - \\frac{s_y}{s_x}\\overline{x}\n\\end{align}\n\\tag{2.18}\\]\n根据 方程式 2.17， 当且仅当 \\(r = 1\\) 时，\\(\\sum{(\\frac{x_i - \\overline{x}}{s_x} - \\frac{y_i - \\overline{y}}{s_y})^2} = 0\\)。\n也即当且仅当 \\(r = 1\\) 时，\\(\\frac{y_i - \\overline{y}}{s_y} = \\frac{x_i - \\overline{x}}{s_x}\\)。\n所以，当且仅当 \\(r = 1\\) 时，\\(y_i = \\overline{y} - \\frac{s_y}{s_x}\\overline{x} + \\frac{s_y}{s_x}x_i\\)，把 方程式 2.18 代入得到 \\(y_i=ax_i + b\\)。\n因此，当且仅当 \\(r = 1\\) 时，\\((x_i, y_i)\\) 的所有的点都位于直线 \\(y_i = ax_i + b, a&gt;0\\)。\n同理，我们可以证明，当且仅当 \\(r = -1\\) 时，\\((x_i, y_i)\\) 的所有的点都位于直线 \\(y_i = ax_i + b, a&lt;0\\)。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_7",
    "href": "chapter_2/2.html#sec-2_7",
    "title": "2  描述统计",
    "section": "2.7 洛伦兹曲线和基尼系数",
    "text": "2.7 洛伦兹曲线和基尼系数\n洛伦兹曲线（Lorenz Curve）\\(L(p), 0 \\le p \\le 1\\)，是与群体中成员的收入相关的图表。\\(L(p)\\) 表示群体中，收入最低的 \\(100p\\%\\) 的人的总收入在群体总收入中的收入占比。例如，\\(L(0.3)\\) 是收入最低的 30% 的人的总收入在群体中的收入占比。一般来说，假设群体中有 \\(n\\) 个人，其个体收入按升序排列为 \\(x_1 \\le x_2 \\le x_3 ... \\le x_n\\)。因为 \\(x_1 + ... + x_j\\) 是收入最低的 \\(j\\) 个人的总收入，而 \\(x_1 + ... + x_n\\) 是该群体所有人的总收入。因此，收入最低的 \\(100\\frac{j}{n}\\%\\) 的人的收入占比就是：\n\\[\nL(\\frac{j}{n}) = \\frac{x_1 + ... + x_j}{x_1 + ... + x_n},\\ j = 1, ..., n\n\\]\n一般而言，令 \\(L(0) = 0\\)，并通过直线连接 \\(\\frac{j}{n}\\) 和 \\(\\frac{j + 1}{n}\\) 来绘制洛伦兹曲线。\n\n例子 2.6 假设我们想绘制 \\(n=5\\) 的洛伦兹曲线，其中该群体的收入分别是：9，7，22，5，17。该群体的收入按照升序排序后是：5，7，9，17，22。因为群体的总收入是 60，因此：\n\nL(0.2) = 5 / 60\nL(0.4) = 12 / 60\nL(0.6) = 21 / 60\nL(0.8) = 38 / 60\nL(1) = 60 /60\n\n将如上的点用直线连接起来就形成了洛伦兹曲线，如 图 2.13。\n\n\n\n代码\nlibrary(ggplot2)\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.13: 例子 2.6 的洛伦兹曲线\n\n\n\n\n\n也可以用洛伦茨曲线来展现群体中的个体财富，其中 \\(L(p)\\) 代表最贫穷的 \\(100p%\\) 的人所拥有的全部财富的比例。例如，如果全部人口由 1000 人组成，那么 \\(L(0.22)\\) 就是 220 个最贫穷的人所拥有的财富比例。\n现在，当向集合中添加一个大于之前所有值的新值时，集合的平均值总是会增加。因此，如果群体成员的收入递增排序后是 \\(x_1 \\le x_2 \\le x_3... \\le x_n\\)，那么 \\(\\forall j = 1,...,n\\)，有：\n\\[\n\\begin{align}\n& \\frac{x_1 + ... + x_j}{j} \\le \\frac{x_1 + ... + x_{j+1}}{j + 1} \\le \\frac{x_1 + ... + x_n}{n} \\\\\n\\therefore & \\frac{x_1 + ... + x_j}{x_1 + ... + x_n} \\le \\frac{j}{n} \\\\\n\\therefore & L{(\\frac{j}{n}}) \\le \\frac{j}{n}\n\\end{align}\n\\]\n此外，可以验证，当且仅当所有人的收入都相等时，\\(L(\\frac{j}{n}) = \\frac{j}{n}, j=1,...,n\\)。因此，除非所有人的收入都相等，否则洛伦茨曲线总是位于 \\((0,0)\\) 和 \\((1,1)\\) 构成的直线之下。对于 例子 2.6，图 2.14 正说明了这一点。\n\n\n代码\nlibrary(ggplot2)\n\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.14: 例子 2.6 的包含直线的洛伦兹曲线\n\n\n\n\n\n因此，当所有人的收入都相等时，洛伦茨曲线与从 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线重合；而当群体中不同个体收入不相等时，洛伦茨曲线则位于该直线的下方。当群体成员的收入越不平等，\\((0, 0)\\) 到 \\((1, 1)\\) 的直线和洛伦茨曲线之间的区域则越大（如 图 2.15 中的阴影区域所示）。\n\n\n代码\nlibrary(ggplot2)\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  annotate(\"text\", x = 0.75, y = 0.25, label = \"B\", hjust = 1, vjust = 0, size = 6) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.15: 直线[(0, 0), (1, 1)]和洛伦兹曲线之间的面积\n\n\n\n\n\n可以用基尼系数（Gini Index）衡量 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线和洛伦茨曲线之间的区域大小，进而衡量群体中成员的收入不平等性。基尼系数等于 图 2.15 中阴影区域面积与直线下方区域的面积之比。由于三角形的面积是底乘以高的一半，所以从 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线下方的面积等于 \\(\\frac{1}{2}\\)。\n因此，基尼系数 \\(G\\) 的定义如下：\n\\[\nG = \\frac{L(p) 曲线和直线围成的区域面积}{\\frac{1}{2}}\n\\]\n令洛伦兹曲线下方的区域为 \\(B\\)，则洛伦兹曲线和直线围成的面积就是直线下方的面积减去洛伦兹曲线下方的面积。因此，基尼系数\n\\[\nG=\\frac{\\frac{1}{2} - B}{\\frac{1}{2}} = 1 - 2B\n\\tag{2.19}\\]\n\n练习 2.11 计算 例子 2.6 中的数据的基尼系数。\n\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[4], y=df$yf[4], xend=df$x[4], yend=0) +\n  geom_segment(x=df$x[5], y=df$yf[5], xend=df$x[5], yend=0) +\n  geom_segment(x=df$x[6], y=df$yf[6], xend=df$x[6], yend=0) +\n  annotate(\"text\", x = 0.15, y = 0.02, label = \"B1\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.3, y = 0.1, label = \"B2\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.5, y = 0.2, label = \"B3\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.7, y = 0.4, label = \"B4\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.9, y = 0.6, label = \"B5\", hjust = 1, vjust = 0, size = 3) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.16: 求解 B 的面积\n\n\n\n\n\n\n答案 2.12. 为了计算 \\(B\\) 的面积（即洛伦兹曲线下的面积），如 图 2.16 所示，我们令 \\(B = B1 + B2 + B3 + B4 + B5\\)，其中 \\(B1\\) 是0~0.2 的洛伦兹曲线下的区域面积，\\(B2\\) 是 0.2~0.4 之间的区域面积，\\(B3\\) 是 0.4~0.6 之间的区域面积，\\(B4\\) 是 0.6~0.8 之间的区域面积；\\(B5\\) 是 0.8~1 之间的区域面积。现在，\\(B1\\) 是一个三角形的面积，其底为 0.2，高为 5/60，因此：\n\\[\nB1 = \\frac{1}{2} \\cdot 0.2 \\cdot \\frac{5}{60} = \\frac{5}{600}\n\\]\n对于 \\(B2, B3, B4, B5\\) 而言，这些区域的面积由两部区域构成：顶部的三角形的面积和底部的矩形面积。如下图所示，以 \\(B2\\) 为例，其面积由 \\(B2-1\\) 和 \\(B2-2\\) 两部分构成：\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  scale_x_continuous(limits=c(0, 0.6), breaks=seq(0, 0.6, 0.2)) +\n  scale_y_continuous(limits=c(0, 0.25), breaks=seq(0, 0.25, 0.05)) +\n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[3], yend=df$yf[3]) + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[3], yend=df$yf[2], linetype=\"dashed\") +\n  annotate(\"text\", x = 0.3, y = 0.1, label = \"B2-1\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.3, y = 0.03, label = \"B2-2\", hjust = 1, vjust = 0, size = 3) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n\n因此，所有的三角形的底的长度都是 0.2，其对应的高分别为 \\(\\frac{5}{60}, \\frac{7}{60}, \\frac{9}{60}, \\frac{17}{60}, \\frac{22}{60}\\)。因此，所有的三角形的面积为：\n\\[\nS_\\triangle = \\frac{1}{2} \\cdot 0.2 \\cdot \\frac{5+7+9+17+22}{60} = 0.1\n\\]\n四个矩形的长均是 0.2，其对应的高分别是 \\(\\frac{5}{60}, \\frac{12}{60}, \\frac{21}{60}, \\frac{38}{60}\\)。因此，所有的矩形的面积为：\n\\[\nS_\\square = 0.2 \\cdot \\frac{5 + 12 + 21 + 38}{60} \\thickapprox 0.25333\n\\]\n所以 \\(B = S_\\triangle + S_\\square =\\) \\(0.1 + 0.25333 = 0.35333\\)，故而 \\(G = 1 - 2B =\\) \\(1 - 2 \\cdot 0.35333 =\\) \\(0.29334\\)。\n\n一般而言，收入数据以升序进行排列，\\(x_1 \\le x_2 \\le x_3 \\le ... \\le x_n\\)，令 \\(s_j = x_1 + ... + x_j, j=1,...,n\\)，则洛伦兹曲线下方的所有三角形的底均是 \\(\\frac{1}{n}\\)，且其对应的高分别为 \\(\\frac{x_1}{s_n}\\)，\\(\\frac{x_2}{s_n}\\)，……，\\(\\frac{x_n}{s_n}\\)。\n因此，所有三角形的面积为：\n\\[\nS_\\triangle=\\frac{1}{2n}\\frac{(x_1 + ... + x_n)}{s_n}=\\frac{1}{2n}\n\\]\n所有的矩形的长均为 \\(\\frac{1}{n}\\)，且其对应的高分别为 \\(\\frac{s_1}{s_n}\\)，\\(\\frac{s_2}{s_n}\\)，……，\\(\\frac{s_{n-1}}{s_n}\\)。\n因此，所有矩形的面积为：\n\\[\nS_\\square = \\frac{s_1 + s_2 + ... + s_{n-1}}{ns_n}\n\\]\n所以：\n\\[\nB = \\frac{1}{2n} +  \\frac{s_1 + s_2 + ... + s_{n-1}}{ns_n}\n\\tag{2.20}\\]\n当所有人的收入都相等时，基尼系数为 0，因此直线与洛伦兹曲线之间的面积为 0。另一个极端的情况就是，当群体的 \\(n\\) 个人中，只有一个人有收入，那么此时基尼系数达到最大值。对于第二种场景，洛伦兹曲线下的面积是一个三角形的面积，其底边长度为 \\(\\frac{1}{n}\\)，高度为 1（如 图 2.17）。此时 \\(B=\\frac{1}{2n}\\)，因此 \\(G=1-\\frac{1}{n}\\)。\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 0, 0, 0, 0, 60)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[4], y=df$yf[4], xend=df$x[4], yend=0) +\n  geom_segment(x=df$x[5], y=df$yf[5], xend=df$x[5], yend=0) +\n  geom_segment(x=df$x[6], y=df$yf[6], xend=df$x[6], yend=0) +\n  labs(x=\"people proportion\", y=\"incomes proportion\") +\n  theme(  \n    axis.text.x = element_blank(),   \n    axis.text.y = element_blank(), \n  ) + \n  annotate(\"text\", x = 0.9, y = 0.25, label = \"B\", hjust = 1, vjust = 0, size = 6) +\n  annotate(\"text\", x = 0.8, y = 0, label = \"1-(1/n)\", hjust = 1, vjust = 0, size = 3) + \n  annotate(\"text\", x = 1, y = 0, label = \"1\", hjust = 1, vjust = 0, size = 3) + \n  annotate(\"text\", x = 0, y = 1, label = \"1\", hjust = 1, vjust = 0, size = 3)\n\n\n\n\n\n\n\n\n图 2.17: 最大基尼系数",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_8",
    "href": "chapter_2/2.html#sec-2_8",
    "title": "2  描述统计",
    "section": "2.8 R",
    "text": "2.8 R\n如果我们要计算 \\(x_1,...,x_n\\) 的样本均值和样本方差，我们可以在 R 中输入：\nx &lt;- c(x_1,...,x_n)\n然后可以按下 回车 键，并输入 mean(x)，然后当再次按下 回车 时，就会打印出样本均值。当输入 var(x)，然后按下 回车 时，就会打印出样本方差。\n例如，我们要计算：4，6，12，9，21，14 的样本均值和样本方差，我们可以用 R 按照如下方式获取：\n&gt; x &lt;- c(4,6,12,9,21,14)\n&gt; mean(x)\n[1] 11\n&gt; var(x)\n[1] 37.6\n&gt; \n在 R 中，我们不需要输入行首的 &gt;，R 会自动为每一行补充提示符 &gt;，以提示我们输入代码。R 中的命令还有：\n\nsum(x)：返回向量 x 中所有数据的和。\nmedian(x)：返回向量 x 中的所有数据的中位数。\nsd(x)：返回向量 x 中所有数据的标准差。\n\n如果 \\(x=c(x_1,...,x_n)\\)，\\(y=c(y_1,...,y_n)\\)，则：\n\n\\(x+y=c(x_1+y_1,...,x_n+y_n)\\)\n\\(x-y=c(x_1-y_1,...,x_n-y_n)\\)\n\\(x^2=c(x_1^2,...,x_n^2)\\)\n\\(\\frac{x}{y}=c(\\frac{x_1}{y_1},...,\\frac{x_n}{y_n}), \\ \\forall y_i \\ne 0\\)\n\n如果 \\(a\\) 是一个实数，则：\n\n\\(a + x = c(a+x_1,...,a+x_n)\\)\n\\(ax = c(ax_1,...,ax_n)\\)\n\\(\\frac{x}{a}=c(\\frac{x_1}{a},...,\\frac{x_n}{a}), \\ \\forall a \\ne 0\\)\n\\(\\frac{a}{x}=c(\\frac{a}{x_1},...,\\frac{a}{x_n}), \\ \\forall x_i \\ne 0\\)\n\n对于成对数据 \\(\\{(x_i,y_i)\\}, \\ i=1,...,n\\)，我们可以使用如下命令获取其相关系数：\n&gt; x &lt;- c(x1,...,xn) \n&gt; y &lt;- c(y1,...,yn) \n&gt; cor(x, y)\n可以用 plot(x, y) 获取 \\(\\{(x_i,y_i)\\}\\) 的散点图：\n&gt; plot(x, y)\n假设我们有如下的数据：(4,10), (6,13), (12,22), (9,15), (21,30), (14,15)，我们可以使用如下的 R 命令获取其样本相关系数和散点图：\n\n\n代码\nx &lt;- c(4, 6, 12, 9, 21, 14)\ny &lt;- c(10, 13, 22, 15, 30, 15) \ncor(x, y)\n\n\n[1] 0.9041494\n\n\n代码\nplot(x, y)\n\n\n\n\n\n\n\n\n\nR 还可以用于数学计算，例如我们可以使用如下命令计算 \\(\\frac{18\\sqrt{177}}{677}\\)：\n\n\n代码\n18*sqrt(177)/677 \n\n\n[1] 0.3537288\n\n\n\n如果我们从向量 x &lt;- c(x1, ..., xn) 中选择第 \\(i\\) 个位置的元素 \\(x_i\\)，我们可以使用命令 x[i]。\n如果希望从向量 x 中选择 \\(i\\) 到 \\(j\\) 的元素并构成一个新的向量，我们可以使用命令 x[i:j]。\n\n\n\n代码\nx &lt;- c(3, 18, 9, 7, 22, 5, 17)\nx[3]\n\n\n[1] 9\n\n\n代码\nx[2:5]\n\n\n[1] 18  9  7 22\n\n\n我们可以使用 R 计算基尼系数。对于向量 x &lt;- c(x1, ..., xn)，先利用 sort(x) 得到 关于向量 x 中数据的递增排序。\n\n\n代码\nx &lt;- c(9, 7, 22, 5, 17)\nsort(x)\n\n\n[1]  5  7  9 17 22\n\n\n如果我们想使用 方程式 2.19 和 方程式 2.20 来计算 练习 2.11 中的基尼系数，我们可以使用如下的代码：\n\n\n代码\ny &lt;- c(9, 7, 22, 5, 17)\nx &lt;- sort(y)\ns &lt;- cumsum(x)[1:4]\nB &lt;- 1/10 + sum(s) / (5 * sum(x))\nG &lt;- 1 - 2 * B\nG \n\n\n[1] 0.2933333\n\n\n我们也可以在 R 中定义 函数。例如，我们想在 R 中定义函数 \\(f\\) 以实现 \\(f(x) = x^2\\)，可以使用如下的代码：\n\n\n代码\nf = function(x){x * x}\nf(4)\n\n\n[1] 16\n\n\n如果我们想实现 \\(f(x) = e^x\\)，可以使用如下的代码：\n\n\n代码\nf = function(x){exp(x)}\nf(1)\n\n\n[1] 2.718282\n\n\n使用 函数 的概念，我们可以使用如下的代码以获取 9, 7, 22, 5, 17 的基尼系数：\n\n\n代码\ns = function(x, j){sum(x[1:j])}\n\ny &lt;- c(9, 7, 22, 5, 17)\nx &lt;- sort(y)\nB &lt;- 1/10 + (s(x, 1) + s(x, 2) + s(x, 3) + s(x, 4)) / (5 * s(x, 5))\nG &lt;- 1 - 2 * B\nG \n\n\n[1] 0.2933333",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#问题",
    "href": "chapter_2/2.html#问题",
    "title": "2  描述统计",
    "section": "问题",
    "text": "问题\n\n以下是 1997 年 6 月，旧金山湾区每加仑标准无铅汽油的价格的样本数据。\n3.88, 3.90, 3.93, 3.90, 3.93, 3.96, 3.88, 3.94, 3.96, 3.88, 3.94, 3.99, 3.98\n使用如下的方式对数据进行描述：\n\n频率表\n相对频率的线图\n\n解释一下如何构建一个饼图。如果数据集中的某个数据值的相对频率为 r，那么在饼图中，该扇区将会位于什么角度？\n以下是西半球四个地区的石油储量估计数据（以十亿桶为单位）：\n\nUnited States 38.7\nSouth America 22.6\nCanada 8.8\nMexico 60.0\n\n请使用饼图来描述如上的数据。\n选择一本书或一篇文章，计算前 100 个句子中每个句子的单词数，并使用茎叶图来展现这些数据。现在选择另一本由不同作者撰写的书或文章，并做同样的操作。这两个茎叶图看起来是否相似？你认为这种方法能否有效地判断不同的文章是否由不同的作者所写？\n以下是每日上班通勤时间（以分钟为单位）的频率表：\n\n\n\nTravel time\nFrequency\n\n\n\n\n15\n6\n\n\n18\n5\n\n\n22\n4\n\n\n23\n3\n\n\n24\n4\n\n\n25\n2\n\n\n26\n4\n\n\n32\n3\n\n\n36\n1\n\n\n48\n1\n\n\n\n\n频率表中的数据包含了几天的数据？\n频率表中的总的通勤时间是多少？\n\n表格 2.10 列出了 1985 年至 2006 年间，美国商业航空事故的次数以及由此造成的死亡总人数。\n\n绘制事故数的频率表\n绘制事故数的折线图\n绘制事故数的累积相对频率图\n计算事故数的样本均值\n计算事故数的样本中位数\n找出事故数的样本众数\n计算事故数的样本标准差\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_airline.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.10: 美国商业航空公司 1985~2006 安全数据，数据来源： National Transportation Safety Board。\n\n\n\n\n\n\nYear\nDepartures..millions.\nAccidents\nFatalities\n\n\n\n\n1985\n6.1\n4\n197\n\n\n1986\n6.4\n2\n5\n\n\n1987\n6.6\n4\n231\n\n\n1988\n6.7\n3\n285\n\n\n1989\n6.6\n11\n278\n\n\n1990\n7.8\n6\n39\n\n\n1991\n7.5\n4\n62\n\n\n1992\n7.5\n4\n33\n\n\n1993\n7.7\n1\n1\n\n\n1994\n7.8\n4\n239\n\n\n1995\n8.1\n2\n166\n\n\n1996\n7.9\n3\n342\n\n\n1997\n9.9\n3\n3\n\n\n1998\n10.5\n1\n1\n\n\n1999\n10.9\n2\n12\n\n\n2000\n11.1\n2\n89\n\n\n2001\n10.6\n6\n531\n\n\n2002\n10.3\n0\n0\n\n\n2003\n10.2\n2\n22\n\n\n2004\n10.8\n1\n13\n\n\n2005\n10.9\n3\n22\n\n\n2006\n11.2\n2\n50\n\n\n\n\n\n\n\n\n\n根据 表格 2.10 的数据，\n\n绘制事故导致的死亡人数的直方图\n绘制事故导致的死亡人数的茎叶图\n计算事故导致的死亡人数的的样本均值\n计算事故导致的死亡人数的的样本中位数\n计算事故导致的死亡人数的的样本标准差\n\nA 镇成年女性的体重样本均值大于 B 镇成年女性的体重样本均值。此外，A 镇成年男性的体重样本均值也大于 B 镇成年男性的体重样本均值。我们是否可以得出结论：A 镇成年人的体重样本均值大于 B 镇成年人的体重样本均值？请给出你的解释。\n首位数定律（Benford’s law for first digits）指出：在许多现实生活中的数值数据集中，首位数字并不是以相等的比例出现，而是偏向于较小的数字。更具体地说，首位数定律指出，首位非零数字为 \\(i, i=1,...,9\\) 的数据比例大约为 \\(log_{10}{(i+1)}\\)。例如，\\(log_{10}{(2)}=0.301\\)，这表明大约 30.1% 的数据的首位数字是 1。表格 2.11 给出了首位数定律中以 1~9 作为首位数字的数据的比例。\n有趣的是，首位数定律已被证明可以适用于各种现实生活数据集，包括电费账单、街道地址、股票价格、人口数量、死亡率、河流长度、物理和数学常数，并且当数据值广泛分布时似乎最为准确。首位数定律最初是由美国天文学家西蒙・纽科姆（Simon Newcomb）在 1881 年发表的。1938 年，物理学家弗兰克・本福德（Frank Benford）在 20 个不同领域的数据集上测试了首位数定律，并表明在大多数情况下它都是一个很好的拟合。弗兰克・本福德测试的数据包括：河流的表面积、美国城市的人口规模、物理常数和分子量（molecular weights）等。\n物理考试中的一个多选题为：以下哪个是 20℃ 下，100% 过氧化氢溶液的密度（单位为 \\(g/{cm}^3\\)），(a) 7.3316、(b) 6.2421、(c) 1.4512、(d) 8.1818。如果你对过氧化氢一无所知，你会猜哪个答案是正确的？\n\n\n\n表格 2.11: 首位数定律\n\n\n\n\n\nFirst digit\nProportion of data having it as first digit\n\n\n\n\n1\n0.301\n\n\n2\n0.176\n\n\n3\n0.125\n\n\n4\n0.097\n\n\n5\n0.079\n\n\n6\n0.067\n\n\n7\n0.058\n\n\n8\n0.051\n\n\n9\n0.046\n\n\n\n\n\n\nA 公司总共有 100 名员工，而 B 公司总共有 110 名员工。假设 A 公司的所有员工的薪水总和比 B 公司高。\n\n对于 A 公司工资的中位数与 B 公司工资的中位数来说意味着什么？\n对于 A 公司工资的平均数与 B 公司工资的平均数来说意味着什么？\n\n一个包含 198 个数据的数据集中，前 99 个数据的样本均值等于 120，而后 99 个数据的样本均值等于 100。关于整个数据集的样本均值，你能得出什么结论？\n\n关于整个数据集的样本中位数，你能得出什么结论？\n关于整个数据集的样本众数，你能得出什么结论？\n\n下表给出了 1922 年英格兰的重大道路交通事故中，按照年龄、性别汇总的行人死亡人数数据。\n\n估算男性年龄的样本均值\n估算女性年龄的样本均值\n估算死亡男性的四分位数\n估算死亡女性的四分位数\n\n\n\n\nAge Range\nNumber of Males\nNumber of Females\n\n\n\n\n0-5\n120\n67\n\n\n5-10\n184\n120\n\n\n10-15\n44\n22\n\n\n15-20\n24\n15\n\n\n20-30\n23\n25\n\n\n30-40\n50\n22\n\n\n40-50\n60\n40\n\n\n50-60\n102\n76\n\n\n60-70\n167\n104\n\n\n70-80\n150\n90\n\n\n80-100\n49\n27\n\n\n\n以下是 12 个相邻位置发现的煤炭样本中的含灰量占比数据：\n9.2, 14.1, 9.8, 12.4, 16.0, 12.6, 22.7, 18.9, 21.0, 14.5, 20.4, 16.9\n\n计算如上数据的样本均值\n计算如上数据的样本标准差\n\n5 个数据的样本均值和样本方差分别是 \\(\\overline{x} = 104\\)，\\(s^2 = 16\\)，如果其中的 3 个数是 102， 100， 105，另外两个数是什么？\n假设你得到了美国 50 个州中每个州所有工人的平均工资。\n\n你认为这 50 个州的平均工资的样本均值会等于整个美国的工人平均工资吗？\n如果对（a）的回答是否定的，请解释除了这 50 个平均值之外，还需要什么其他信息来确定整个国家的样本平均薪资。同时，解释你将如何使用这些额外信息来计算这个整个美国的工人平均工资。\n\n如下是 40 个晶体管的使用寿命（单位为小时）：\n112, 121, 126, 108, 141, 104, 136, 134, \n121, 118, 143, 116, 108, 122, 127, 140,\n113, 117, 126, 130, 134, 120, 131, 133,\n118, 125, 151, 147, 137, 140, 132, 119,\n110, 124, 132, 152, 135, 130, 136, 128\n\n计算如上数据的样本均值、样本中位数、样本众数\n给出如上数据的累积相对频率图\n\n一个实验测量了 50 个粘土样本干燥后的收缩比率，并记录了以下数据：\n18.2 21.2 23.1 18.5 15.6 20.8 19.4 15.4 21.2 13.4 \n16.4 18.7 18.2 19.6 14.3 16.6 24.0 17.6 17.8 20.2 \n17.4 23.6 17.5 20.3 16.6 19.3 18.5 19.3 21.2 13.9 \n20.5 19.0 17.6 22.3 18.4 21.2 20.4 21.4 20.3 20.1 \n19.6 20.6 14.8 19.7 20.5 18.0 20.8 15.8 23.1 17.0\n\n\n画出如上数据的茎叶图\n\n\n计算样本均值，样本中位数，样本众数\n\n\n计算样本方差\n\n\n从 13% 开始，以 1% 为间隔将如上的数据进行分组，并绘制直方图\n\n\n对于分组数据而言，假设每个数据点实际上位于其所在区间的中点，计算样本均值和样本方差，并与 (b) 和 (c) 的结果进行比较。为什么它们会不同？\n\n\n如下是计算 \\(\\{x_i;\\ i=1,...,n\\}\\) 样本均值和样本方差的一种快速算法。首先计算前 \\(j(j \\ge 2)\\) 个数据的样本均值和方差：\\(\\overline{x}_j = \\frac{\\sum_{i=1}^{j}{x_i}}{j}\\)，\\(s_j^2=\\frac{\\sum_{i=1}^{j}{(x_i - \\overline{x})^2}}{j - 1}\\)。其中，\\(\\overline{x}_1 = x_1\\)，\\(s_1^2 = 0\\)。则：\n\\[\n\\begin{align}\n& \\overline{x}_{j+1} = \\overline{x}_j + \\frac{x_{j + 1} - \\overline{x}}{j + 1} \\\\\n& s_{j+1}^2 = (1 - \\frac{1}{j})s_j^2 + (j + 1)(\\overline{x}_{j+1} - \\overline{x}_j)^2\n\\end{align}\n\\]\n\n\n使用如上的算法计算 3, 4, 7, 2, 9, 6 的样本均值和样本方差\n\n\n使用普通的计算方式来校验 (a) 的结果\n\n\n验证如上算法中的 \\(\\overline{x}_{j+1}\\) 和 \\(\\overline{x}_{j}\\) 的关系\n\n\n对于 表格 2.5 的数据，\n\n计算 1 月的平均气温的 90-分位值\n计算 7 月的平均气温的 75-分位值\n\n根据 《纽约时报》在 2013 年 8 月 1 日两周前发布的讣告，找出如下的死亡年龄的四分位数。\n92, 90, 92, 74, 69, 80, 94, 98, 65, 96, \n84, 69, 86, 91, 88, 74, 97, 85, 88, 68, \n77, 94, 88, 65, 76, 75, 60, 69, 97, 92, \n85, 70, 80, 93, 91, 68, 82, 78, 89\n我们按照各个大学在谷歌上的月搜索量对大学进行月度排名，在截止到 2013 年 6 月的 114 个月中，获得过月榜单 TOP 10 的大学的上榜次数如下表所示。\n\n\n\n\n\n\n\nUniversity\nNumber of Months in Top 10\n\n\n\n\nHarvard University\n114\n\n\nUniversity of Texas, Austin\n114\n\n\nUniversity of Michigan\n114\n\n\nStanford University\n113\n\n\nUniversity of California Los Angeles (UCLA)\n111\n\n\nUniversity of California Berkeley\n97\n\n\nPenn State University\n94\n\n\nMassachusetts Institute of Technology (MIT)\n66\n\n\nUniversity of Southern California (USC)\n63\n\n\nOhio State University\n52\n\n\nYale University\n48\n\n\nUniversity of Washington\n33\n\n\n\n\n计算样本均值\n计算样本方差\n计算样本的四分位数\n\n填写缺失的单词或短语以完成以下句子：“如果向一组数字中增加一个新的数字，如果新的数字____，则该数组的样本均值将增加。”\n用箱线图表示第 20 题中的数据。\n在一个石油化工企业中，在 36 个随机选择的时间点测量了平均颗粒物浓度（单位为 \\(mg/m^3\\)），得到了如下的浓度数据：\n5, 18,  15, 7,  23, 220, 130, 85, 103, 25, \n80, 7,  24, 6,  13, 65,  37,  25, 24,  65, \n82, 95, 77, 15, 70, 110, 44,  28, 33,  81, \n29, 14, 45, 92, 17, 53\n\n使用直方图描述如上数据\n如上的直方图是近似正态直方图吗？\n\n一位化学工程师想要研究盐水蒸发池中水的蒸发率，他获得了 4 年中盐水蒸发池 7 月份每天蒸发英寸数的 55 个数据。这些数据以下面的茎叶图给出，其最小数据为 0.02 英寸，最大数据为 0.56 英寸。\n.0    2,6\n.1    1,4\n.2    1,1,1,3,3,4,5,5,5,6,9\n.3    0,0,2,2,2,3,3,3,3,4,4,5,5,5,6,6,7,8,9 \n.4    0,1,2,2,2,3,4,4,4,5,5,5,7,8,8,8,9,9 \n.5    2,5,6\n计算如上数据的：\n\n样本均值\n样本中位数\n样本标准差\n如上的数据看起来符合近似正态分布吗？\n位于样本均值 1 个标准差以内的数据占比是多少？\n\n以下是加利福尼亚大学伯克利分校工业工程与运筹学系录取的最近 30 名学生的 GPA（grade point averages）。\n3.46, 3.72, 3.95, 3.55, 3.62, 3.80, 3.86, 3.71, 3.56, 3.49, \n3.96, 3.90, 3.70, 3.61, 3.72, 3.65, 3.48, 3.87, 3.82, 3.91, \n3.69, 3.67, 3.72, 3.66, 3.79, 3.75, 3.93, 3.74, 3.50, 3.83\n\n\n使用茎叶图来绘制如上的数据\n\n\n计算样本均值 \\(\\overline{x}\\)\n\n\n计算样本标准差 \\(s\\)\n\n\n计算位于 \\([\\overline{x} - 1.5s, \\overline{x} + 1.5s]\\) 的数据比例，并和切比雪夫不等式给出的下限比例进行对比\n\n\n计算位于 \\([\\overline{x} - 2s, \\overline{x} + 2s]\\) 的数据比例，并和切比雪夫不等式给出的下限比例进行对比\n\n\n第 26 题中的数据是否近似于正态分布？对于第 26 题的 (d) 和 (e) ，请使用经验法则给出的近似占比与实际占比进行比较。\n你是否期望一个健身俱乐部所有会员的体重直方图会近似于正态分布？\n对于第 16 题中的数据：\n\n\n计算样本均值和样本中位数\n\n\n这些数据符合近似正态分布吗？\n\n\n计算样本标准差 \\(s\\)\n\n\n计算位于 \\([\\overline{x} - 1.5s, \\overline{x} + 1.5]\\) 区间的数据的占比\n\n\n对比 (d) 的结果和经验法则给出的结果\n\n\n对比 (d) 的结果和切比雪夫不等式给出的结果\n\n\n以下是 12 名考试成绩大致相同的法学院学生的身高和起薪数据：\n\n\n\nHeight (inches)\nSalary\n\n\n\n\n64\n91\n\n\n65\n94\n\n\n66\n88\n\n\n67\n103\n\n\n69\n77\n\n\n70\n96\n\n\n72\n105\n\n\n72\n88\n\n\n74\n122\n\n\n74\n102\n\n\n75\n90\n\n\n76\n114\n\n\n\n\n绘制数据的散点图\n计算样本相关系数\n\n根据人们的站立姿势数据形成一个随机样本。针对样本中的人，还额外记录了每个人在过去一年中经历背痛的天数。令研究人员惊讶的是，这些数据表明良好的站姿与背痛天数之间存在正相关关系。这是否意味着良好的站姿会导致背痛？\n如果我们把美国 50 个州中每个州的居民平均收入和居住在该州的外国出生的移民数量绘制为成对的数据图，那么这些成对数据将呈现正相关关系。我们能否得出结论，移民居民往往比土生土长的美国人的收入更高？如果不是，还能如何解释这个现象？\n随机抽取 12 名高中三年级学生，并要求他们估算自己每周平均学习的小时数。以下的数据给出了估算结果和学生的 GPA。\n\n\n\nHours\nGPA\n\n\n\n\n6\n2.8\n\n\n14\n3.2\n\n\n3\n3.1\n\n\n22\n3.6\n\n\n9\n3.0\n\n\n11\n3.3\n\n\n12\n3.4\n\n\n5\n2.7\n\n\n18\n3.1\n\n\n24\n3.8\n\n\n15\n3.0\n\n\n17\n3.9\n\n\n\n\n计算学习小时数和 GPA 之间的样本相关系数。\n\n验证样本相关系数的特性 3。\n验证样本相关系数的特性 4。\n在一项针对二至四年级的儿童研究中，研究人员针对每个学生都做了阅读测试。在研究结果数据时，研究人员注意到学生的阅读测试分数和身高之间存在正相关关系。研究人员得出结论，身高较高的孩子阅读能力更好，因为他们可以更容易地看到黑板。你认为呢？\n最近的一项研究发现，母乳喂养的婴儿与 6 岁时进行的词汇测试分数之间存在正相关关系。讨论在解释这项研究结果时可能遇到的困难。\n一个群体的收入分别为 25、32、60、40、38、50，绘制其洛伦茨曲线并计算其基尼系数。\n根据如下的年收入（以千美元为单位）频率表，绘制该群体的洛伦茨曲线并计算其基尼系数：\n\n\n\nValue\nFrequency\n\n\n\n\n30\n2\n\n\n50\n4\n\n\n60\n5\n\n\n90\n4\n\n\n100\n3\n\n\n120\n2\n\n\n\n如果样本中所有的数据都乘以一个大于 0 的常数 \\(c\\)，基尼系数将会发生什么变化？如果样本中所有的数据都加上一个大于 0 的常数 \\(c\\)，基尼系数又会发生什么变化？下降，保持不变，还是不好说？",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html",
    "href": "chapter_3/3.html",
    "title": "3  概率论基础",
    "section": "",
    "text": "3.1 引言\n对于一个实验中特定 事件（event）发生的概率（probability）而言，概率 这个概念具有多种含义或解释。例如，如果一位地质学家说 “某地区有 60% 的可能性存在石油”，对于地质学家的这一说法，我们可能都会有一些先入为主的观点。事实上，我们中的大多数人可能会用以下两种方式中的一种来解释地质学家的这一说法：\n对事件概率（the probability of an event ）的上述两种解释分别是：频率解释（frequency interpretation）和 主观解释（subjective interpretation）。\n然而，无论给予概率哪种解释，人们一致认为在这两种情况下概率的数学理论都是相同的。例如，如果你认为明天下雨的概率是 0.3，明天多云但不下雨的概率是 0.2，那么你会认为明天多云或下雨的概率就是 0.5。并且 0.5 的结果与我们对概率的主观解释无关。\n在本章中，我们会先研究如下的概念：样本空间（sample space）、实验中的 事件（events），然后介绍概率论中公认的规则（rules）和公理（axioms）。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_1",
    "href": "chapter_3/3.html#sec-3_1",
    "title": "3  概率论基础",
    "section": "",
    "text": "地质学家认为，从长远来看，在外部环境与所考虑地区非常相似的地区中，有 60% 的地区存在石油。\n地质学家认为该地区含有石油的可能性大于不含有石油的可能性，而且实际上，60% 是地质学家对该地区含有石油这一假设的信心度量。\n\n\n\n在 频率解释 中，我们把实验中一个给定结果的概率看作是该结果的一个 “属性”（property）。我们认为，可以通过不断的、重复实验来确定结果出现的”概率”——在实验中，观察到的、该结果出现的比例就是其概率。普遍情况下，科学家眼中的概率就是 频率解释。\n在 主观解释 中，我们并不把概率看作是给定实验结果的“属性”，而是看作引用该概率的人对结果发生的可能性的信念。因此，在 主观解释 中，概率成了一个主观概念，此时，概率除了表达个人的信心程度外并没有其他意义。哲学家和某些经济决策者往往对 主观解释 青睐有加。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_2",
    "href": "chapter_3/3.html#sec-3_2",
    "title": "3  概率论基础",
    "section": "3.2 样本空间和事件",
    "text": "3.2 样本空间和事件\n让我们思考这样的一个实验，在该实验中，我们无法提前确切的预测实验结果。虽然我们无法提前知晓实验结果，但我们可以假定该实验的、所有可能的、结果集合是已知的。所有可能的实验结果的集合，我们称之为实验的 样本空间（sample space），并用 \\(S\\) 来表示 样本空间。\n样本空间 的例子如下所示：\n\n例子 3.1 对于确定新生儿性别的实验，\\(S=\\{g,\\ b\\}\\)，其中，\\(g\\) 表示小孩为女孩，\\(b\\) 表示小孩为男孩。\n\n\n例子 3.2 对于确定已编号的 7 匹马（编号为 1~7 号）之间的赛马实验，\\(S=\\{(1, 2, 3, 4, 5, 6, 7)的所有排序\\}\\)。(2, 3, 1, 6, 5, 4, 7) 的实验结果意味着 2 号马排在第一名，3 号马排在第二名，然后是 1 号马，依此类推……\n\n\n例子 3.3 假如我们想确定患者的最小有效用药剂量，则这个实验的一个可能的样本空间就是让 \\(S\\) 包含所有的正数，即 \\(S=(0,\\ \\infty)\\)。如果用药剂量为 \\(x\\) 时开始对患者有效，但是任何低于 \\(x\\) 的用药剂量均对患者无效，那么此次试验的结果就是 \\(x\\)。\n\n样本空间 的任何子集 \\(E\\) 称之为一个 事件（event）。也就是说，一个 事件 是由实验的可能结果组成的集合。如果实验的结果存在于 \\(E\\) 中，那么我们就说， \\(E\\) 已经发生。如下是 事件 的一些例子：\n\n在 例子 3.1 中，如果 \\(E = \\{g\\}\\)，那么 \\(E\\) 表示的事件为：新生儿为女孩。类似的，如果 \\(F = \\{b\\}\\)，那么 \\(F\\) 表示的事件为：新生儿为男孩。\n在 例子 3.2 中，如果 \\(E=\\{以 3 为首的所有排序\\}\\)，则 \\(E\\) 表示的事件为：3 号马赢得比赛。\n\n对于样本空间 \\(S\\) 中的任意两个事件 \\(E\\) 和 \\(F\\)，我们定义一个新事件 \\(E \\cup F\\)，并称其为事件 \\(E\\) 和 \\(F\\) 的并集。\\(E \\cup F\\) 由所有属于 \\(E\\) 或 \\(F\\) 或同时属于 \\(E\\) 和 \\(F\\) 的结果组成。也就是说，如果 事件 \\(E\\) 或 事件 \\(F\\) 发生，那么事件 \\(E \\cup F\\) 就会发生。例如，在 例子 3.1 中，如果 \\(E = \\{g\\}\\) 且 \\(F = \\{b\\}\\)，那么 \\(E \\cup F = \\{g, b\\}\\)。也就是说，\\(E \\cup F\\) 是整个样本空间 \\(S\\)。在 例子 3.2 中，如果 \\(E = \\{所有以 6 为首的比赛结果\\}\\) 是 6 号马赢得比赛的事件，而 \\(F = \\{所有第二名是 6 的比赛结果\\}\\) 是 6 号马获得第二名的事件，那么 \\(E \\cup F\\) 就是6 号马获得前两名的事件。\n类似地，对于样本空间 \\(S\\) 中的任意两个事件 \\(E\\) 和 \\(F\\)，我们也可以定义一个新事件 \\(EF\\)（有时也记作 \\(E \\cap F\\)），并称之为事件 \\(E\\) 和 \\(F\\) 的交集。\\(E \\cap F\\) 由属于 \\(E\\) 并且同时属于 \\(F\\) 的所有结果组成。也就是说，只有当事件 \\(E\\) 和 \\(F\\) 都发生时，事件 \\(EF\\) 才会发生。例如，在 例子 3.3 中，如果 \\(E = (0, 5)\\) 是药品所需剂量小于 5 的事件，而 \\(F = (2, 10)\\) 是所需剂量在 2~10 之间的事件，那么 \\(EF = (2, 5)\\) 就是所需剂量在 2~5 之间的事件。在 例子 3.2 中，如果 \\(E = \\{所有以 5 结尾的结果\\}\\) 是5 号马获得最后一名的事件，而 \\(F = \\{所有以 5 为首的结果\\}\\) 是 5 号马获得第一名的事件，那么事件 \\(EF\\) 则不包含任何结果，因此事件 \\(EF\\) 不可能发生。对于不可能发生的事件，我们称其为 空事件，并用 \\(\\emptyset\\) 表示。因此，\\(\\emptyset\\) 指的是不包含任何实验结果的事件。如果 \\(EF = \\emptyset\\)，则意味着 \\(E\\) 和 \\(F\\) 不能同时发生，此时我们称 \\(E\\) 和 \\(F\\) 为 互斥事件。\n对于 \\(\\forall E\\)，我们定义事件 \\(E^c\\) 为事件 \\(E\\) 的补集。事件 \\(E^c\\) 由样本空间 \\(S\\) 中不属于 \\(E\\) 的所有结果组成。也就是说，当且仅当事件 \\(E\\) 不发生时，\\(E^c\\) 才会发生。在 例子 3.1 中，如果 \\(E = \\{b\\}\\) 是小孩为男孩的事件，那么 \\(E^c = \\{g\\}\\) 就是小孩为女孩的事件。需要注意，由于实验必须会产生某种结果，因此 \\(S^c = \\emptyset\\)。\n\n\n\n\n\n\n注释\n\n\n\n\\(E^c=\\{\\forall F \\subset S,\\ E \\cap F = \\emptyset 且 E \\cup F = S\\}\\)\n\n\n对于任意两个事件 \\(E\\) 和 \\(F\\)，如果事件 \\(E\\) 中的所有结果在事件 \\(F\\) 中都存在，那么我们说事件 \\(E\\) 包含在事件 \\(F\\) 中，并记作 \\(E \\subset F\\)。因此，如果 \\(E \\subset F\\)，那么事件 \\(E\\) 的发生意味着事件 \\(F\\) 必然发生。如果 \\(E \\subset F\\) 且 \\(F \\subset E\\)，那么我们说 \\(E\\) 和 \\(F\\) 相等（或相同），并记作 \\(E = F\\)。\n我们也可以定义超过两个事件的并集和交集。特别是，事件 \\(E_1, E_2, ..., E_n\\) 的并集，记作 \\(E_1 \\cup E_2 \\cup ... \\cup E_n\\) 或者 \\(\\cup_1^n{E_i}\\)。事件 \\(\\cup_1^n{E_i}\\) 至少包含一个 \\(E_i(i = 1, 2, ..., n)\\) 中的所有结果。类似地，事件 \\(E_i(i = 1, 2, ..., n)\\)的交集，记作 \\(E_1E_2...E_n\\)，为同时出现在所有事件 \\(E_i(i = 1, 2, ..., n)\\) 中的结果组成的事件。换句话说，当至少有一个事件 \\(E_i\\) 发生时，\\(E_i\\) 的并集就会发生；当所有事件 \\(E_i\\) 都发生时，则 \\(E_i\\) 的交集就会发生。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_3",
    "href": "chapter_3/3.html#sec-3_3",
    "title": "3  概率论基础",
    "section": "3.3 事件的代数运算和韦恩图表示",
    "text": "3.3 事件的代数运算和韦恩图表示\n韦恩图（Venn DIagram）是一种用来描述事件之间逻辑关系的、非常有用的图形化表示。用一个矩形表示样本空间 \\(S\\)，而用矩形内的圆表示样本空间中的事件 \\(E\\), \\(F\\), \\(G\\),… 对图中的特定区域进行着色以表示我们感兴趣的事件。例如，在 图 3.1 所示的三个韦恩图中，着色区域分别表示事件 \\(E \\cup F\\)（\\(E\\) 和 \\(F\\) 的并集），\\(EF\\)（\\(E\\) 和 \\(F\\) 的交集），以及 \\(E^c\\)（\\(E\\) 的补集）。图 3.2 所示的韦恩图表示 \\(E \\subset F\\)（\\(E\\) 是 \\(F\\) 的子集）。\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(E \\cup F\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(EF\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(E^c\\)\n\n\n\n\n\n\n\n图 3.1: 韦恩图\n\n\n\n\n\n\n\n\n\n图 3.2: \\(E \\subset F\\) 的韦恩图\n\n\n\n事件的并集、交集和补集操作类似于代数中的规则，例如：\n\n交换律：\\(E \\cup F = F \\cup E\\)，\\(EF=FE\\)\n结合律：\\((E \\cup F) \\cup G = E \\cup (F \\cup G)\\)，\\((EF)G=E(FG)\\)\n分配率：\\((E \\cup F)G = EG \\cup FG\\)，\\(E(F \\cup G) = (E \\cup G)(F \\cup G)\\)\n\n可以通过证明等式左侧事件中的任何结果也包含在等式右侧的事件中来验证如上的事件操作规则。可以通过韦恩图来证明这如上的规则，例如，可以通过 图 3.3 中所示的一系列韦恩图来证明分配率。\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(EG\\)\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(FG\\)\n\n\n\n\n\n\n\n\n\n\n\n(c) \\((E \\cup F )G\\)\n\n\n\n\n\n\n\n图 3.3: 利用韦恩图证明分配率： \\((E \\cup F )G = EG \\cup FG\\)\n\n\n\n基于事件的并集、交集和补集形成的如下的关系称之为德摩根定律（DeMorgan’s laws）。\n\n\\((E \\cup F)^c = E^cF^c\\)\n\\((FE)^c = E^c \\cup F^c\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_4",
    "href": "chapter_3/3.html#sec-3_4",
    "title": "3  概率论基础",
    "section": "3.4 概率论公理",
    "text": "3.4 概率论公理\n如果一个实验在完全相同的条件下不断重复，那么对于任何事件 \\(E\\)，随着重复次数的增加，包含与 \\(E\\) 中结果的比例会接近某个常数。例如，如果不断抛一枚硬币，随着抛掷次数的增加，正面​向上的比例将接近某个值。当我们谈到某个事件的概率时，我们通常指的是这种恒定的极限频率（constant limiting frequency）。\n纯从数学观点来看，对于具有样本空间 \\(S\\) 的实验中的每个事件 \\(E\\)，我们都假设存在一个数字 \\(P (E)\\) ，\\(P(E)\\) 满足以下三个公理（axiom）：\n\n公理1：\\(0 \\le P(E) \\le 1\\)\n公理2：\\(P(S) = 1\\)\n公理3：对于任何的互斥事件序列 \\(E_1\\)，\\(E_2\\)，……，\\(P\\bigg(\\bigcup_{i=1}^{n}E_i\\bigg) = \\sum_{i=1}^{n}{P(E_i)}\\)，\\(n = 1,2,...,\\infty\\)\n\n我们称 \\(P(E)\\) 为事件 \\(E\\) 的概率。\n因此，公理 1 表明实验的结果位于 \\(E\\) 中的概率是一个介于 0 和 1 之间的数。公理 2 表明实验结果将是样本空间 \\(S\\)（概率为 1） 的一中情况。公理 3 表明，对于任何一组互斥事件，至少一个事件发生的概率等于这组事件各自概率的和。\n应该注意的是，如果我们把 \\(P(E)\\) 看作大量重复执行实验时事件 \\(E\\) 的相对频率，那么 \\(P(E)\\) 确实会满足上述公理。例如，位于 \\(E\\) 中的实验结果的比例显然在 0 和 1 之间，而位于 \\(S\\) 中实验结果的比例是 1（因为所有结果都在 \\(S\\) 中）。此外，如果位于 \\(E\\) 和 \\(F\\) 中的结果没有交集，那么结果在 \\(E\\) 或 \\(F\\) 中的比例是它们各自频率的和。对于 公理 3，例如，假设实验为抛掷一对骰子，同时假设事件 \\(E\\) 为两枚骰子的点数总和是 2、3 或 12，事件 \\(F\\) 为点数总和是 7 或 11。如果 \\(E\\) 发生的概率为 11%，\\(F\\) 发生的概率为 22%，那么有 33% 的结果将是 2、3、12、7 或 11。\n现在，我们将使用这些公理来证明关于概率的两个简单命题（proposition）。首先，\\(E\\) 和 \\(E^c\\) 始终是互斥的，并且由于 \\(E \\cup E^c = S\\)，根据 公理 2 和 公理 3 有：\n\\[\n1 = P(S) = P(E \\cup E^c) = P(E) + P(E^c)\n\\]\n根据如上等式，我们有：\n\n命题 3.1 \\(P(E^c) = 1 - P(E)\\)\n\n换句话说，命题 3.1 表明，一个事件不发生的概率等于 1 减去它发生的概率。例如，如果抛一枚硬币，正面向上的概率是 3/8，那么反面向上的概率必须是 5/8。\n我们将证明的第二个命题给出了两个事件并集的概率与它们各自的概率以及他们的交集的概率之间的关系。\n\n命题 3.2 \\(P(E \\cup F) = P(E) + P(F) - P(EF)\\)\n\n\n\n\n\n\n\n证明 命题 3.2\n\n\n\n图 3.4 所示的韦恩图是证明 命题 3.2 的最简单的方法。在 图 3.4 中，区域 I、II、III 是互斥的，因此：\n\\[\n\\begin{align}\nP(E \\cup F) &= P(I) + P(II) + P(III) \\\\\nP(E) &= P(I) + P(II) \\\\\nP(F) & = P(II) + P(III) \\\\\n\\therefore P(E \\cup F) &= P(E) +P(F) - P(II) \\\\\n\\because P(II) &= P(EF) \\\\\n\\therefore P(E \\cup F) &= P(E) +P(F) - P(EF)\n\\end{align}\n\\]\n\n\n\n\n\n\n图 3.4: 韦恩图\n\n\n\n\n\n\n练习 3.1 内华达州有 28% 的男性吸烟，6% 的男性吸雪茄，3% 的男性既吸雪茄又吸烟。那么，有既不吸雪茄也不吸烟的男性占比是多少？\n\n\n答案 3.1. 设 \\(E\\) 为事件——随机选择的一名男性吸香烟，设 \\(F\\) 为事件——该男性吸雪茄。那么，这个人要么吸香烟，要么吸雪茄的概率是：\n\\[\nP(E \\cup F ) = P (E) + P (F ) − P (EF) = 0.28 + 0.06 − 0.03 = 0.31\n\\]\n则，该男性既不吸雪茄也不吸烟的概率为 1 - 0.31 = 0.69，这意味着有 69% 的男性既不吸雪茄也不吸烟。\n\n事件 A 的 赔率（odds）定义如下：\n\\[\n\\frac{P(A)}{P(A^c)} = \\frac{P(A)}{1 - P(A)}\n\\]\n因此，事件 \\(A\\) 的赔率表示 \\(A\\) 发生的可能性比它不发生的可能性多多少。例如，如果 \\(P(A) = \\frac{3}{4}\\)，那么 \\(\\frac{P(A)}{1 − P (A)} = 3\\)，所以其赔率是 3。因此，\\(A\\) 发生的可能性是它不发生的可能性的 3 倍。（通常的说法是，事件 \\(A\\) 的赔率是 3 比 1。）",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_5",
    "href": "chapter_3/3.html#sec-3_5",
    "title": "3  概率论基础",
    "section": "3.5 等概率样本空间",
    "text": "3.5 等概率样本空间\n对于执行大量次数的实验来说，我们会很自然地假设：样本空间中的每个结果发生的可能性是相等的。也就是说，对于许多实验而言，其样本空间 \\(S\\) 是一个有限集合，\\(S = \\{1,2,...,N\\}\\)，通常很自然地假设：\n\\[\nP(\\{1\\}) = P(\\{2\\}) = ··· = P(\\{N\\}) = p\n\\]\n根据 公理 2 和 公理 3，我们有：\\(1 = P(S) = P(\\{1\\}) + P(\\{2\\}) + ··· + P(\\{N\\}) = Np\\)，故而有：\n\\[\nP(\\{i\\}) = p = \\frac{1}{N}\n\\]\n由此，根据 公理 3，对于任意事件 \\(E\\)：\\(P(E)=\\frac{位于\\ E\\ 中的结果数}{N}\\)。\n也就是说，如果我们假设实验的每个结果发生的可能性是相等的，那么任何事件 \\(E\\) 的概率就等于样本空间中包含在 \\(E\\) 中的结果的比例。\n因此，为了计算概率，通常需要有效地计算出给定事件可以以多少种不同的方式发生。为此，我们将使用以下规则。\n\n3.5.1 计数的基本原理\n假设要执行两个实验，如果实验 1 可能有 \\(m\\) 种可能的结果，并且对于实验 1 的每一种结果，实验 2 都有 \\(n\\) 种可能的结果，那么这两个实验总共有 \\(mn\\) 种可能的结果。\n\n\n\n\n\n\n计数的基本原理的证明\n\n\n\n可以使用如下的方式来枚举所有可能的实验结果：\n\\[\n\\begin{array}{ccc}\n    (1,1), & (1,2), & ..., &(1,n) \\\\\n    (2,1), & (2,2), & ..., &(2,n) \\\\\n    \\ \\ \\ ... & \\\\\n    (m,1), & (m,2), & ..., &(m,n) \\\\\n\\end{array}\n\\]\n如果实验 1 产生了第 \\(i\\) 种可能的结果，并且实验 2 产生了第 \\(j\\) 种可能的结果，我们称实验结果为 \\((i, j)\\)。因此，可能的结果集由 \\(m\\) 行组成，其中每行包含 \\(n\\) 个元素。\n\n\n\n练习 3.2 从一个包含 6 个白球和 5 个黑球的碗中 “随机抽取” 两个球。其中一个球是白色的，另一个是黑色的概率是多少？\n\n\n答案 3.2. 如果我们认为选球的顺序非常重要，那么第一个抽取的球可能是 11 个中的任何一个，第二个抽取的球可能是剩下的 10 个中的任何一个，因此样本空间包含 11 × 10 = 110 个点。此外，有 6 × 5 = 30 种方式使得第一个球是白色的，第二个球是黑色的。同样地，有 5 × 6 = 30 种方式使得第一个球是黑色的，第二个球是白色的。因此，假设 “随机抽取” 意味着样本空间中的每个点都有相同的可能性，那么我们可以看出需要计算的概率是：\n\\[\n\\frac{30 + 30}{110} = \\frac{6}{11}\n\\]\n\n对于两个以上的实验，计数的基本原理 可以按如下的方式泛化（generalized）：\n\n\n\n\n\n\n计数基本原理的泛化\n\n\n\n如果要执行 \\(r\\) 个实验，其中第一个实验有 \\(n_1\\) 种可能的结果，如果对于这 \\(n_1\\) 种可能的结果，第二个实验有 \\(n_2\\) 种可能的结果，如果对于前两个实验的每种可能的结果，第三个实验有 \\(n_3\\) 种可能的结果，以此类推，那么这 \\(r\\) 个实验总共有 \\(n_1 \\cdot n_2 \\cdot \\cdot \\cdot n_r\\) 种可能的结果。\n\n\n为了说明 基本计数原理，让我们来确定 \\(n\\) 个不同对象的线性序（linear order）排列的方式的数量。例如，字母 a、b、c 有多少种不同的排列方式？\n通过直接枚举，我们可以发现有 6 种，即 abc、acb、bac、bca、cab、cba，其中的每一个都称为一个 排列（permutation）。因此，3 个对象有 6 种可能的 排列。如上的结果也可以从基本原理中得出，因为第一个对象可以是 3 个字母中的任何一个，第二个对象可以从剩下的 2 个字母中选择，第三个对象则从剩下的一个字母中选择。因此，有 3・2・1 = 6 种可能的 排列。\n以此类推，对于 \\(n\\) 个对象，其不同的排列种类为：\\(n \\cdot (n-1) \\cdot (n-2) \\cdot \\cdot \\cdot 3 \\cdot 2 \\cdot 1\\)。为了方便，我们将如上的式子记为 \\(n!\\)，读作“\\(n\\) 的阶乘”。为了方便，我们令 \\(0!=1\\)。\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdot \\cdot \\cdot 3 \\cdot 2 \\cdot 1\n\\]\n例如：\n\n\\(1! = 1\\)\n\\(2! = 2 \\cdot 1 = 2\\)\n\\(3! = 3 \\cdot 2 \\cdot 1 = 6\\)\n\\(4! = 4 \\cdot 3 \\cdot 2 \\cdot 1 = 24\\)\n\n\n练习 3.3 琼斯先生有 10 本书要放在他的书架上。其中，有 4 本是数学书，3 本是化学书，2 本是历史书，还有 1 本是语言书。琼斯想把这些书按主题分类放在一起排列在书架上。有多少种不同的排列方式？\n\n\n答案 3.3. 有 4! 3! 2! 1! 种排列方式使得数学书排在最前面，然后是化学书，接着是历史书，最后是语言书。同样地，对于每个可能的主题顺序，都有 4! 3! 2! 1! 种可能的排列方式。因此，由于有 4! 种可能的主题顺序，所以所求的答案是 4! × 4! × 3! × 2! × 1! = 6912。\n\n\n练习 3.4 一个概率论课程的班级由 6 名男生和 4 名女生组成。在一次考试中，根据学生的考试成绩进行了排名。假设 10 名学生的考试成绩都不相同：\n\n（a）学生的排名有多少种不同的可能？\n（b）如果所有排名的可能性都相同，那么女生获得前 4 名的概率是多少？\n\n\n\n答案 3.4. \n\n（a）因为每个排名都对应着 10 个人的一个特定有序排列，所以学生的排名可能性有 10! = 3,628,800 种。\n（b）由于女生有 4! 种可能的排名方式，男生有 6! 种可能的排名方式，根据 基本计数原理，女生获得前 4 名的可能排名有 (6!)(4!) = (720)(24) = 17,280 种。因此，所求的概率为：\\(\\frac{6!4!}{10!}=\\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{10 \\cdot 9 \\cdot 8 \\cdot 7} = \\frac{1}{210}\\)。\n\n\n现在，假设我们想要从 \\(n\\) 个对象中选择 \\(r\\) 个对象，并确定这 \\(r\\) 个不同对象所形成的排列方式的数量。例如，从五个物品 A、B、C、D、E 中选择 3 个物品，总共有多少种不同的选择方式？为了回答这个问题，由于有 5 种方式来选择第一个物品，4 种方式来选择下一个物品，3 种方式来选择最后一个物品。因此，当选择的物品存在顺序依赖时，有 5・4・3 种方式来选择这 3 个物品。然而，在存在顺序依赖时，任意选择的 3 个物品（比如 A、B 和 C ）都会被计算 6 次（ABC、ACB、BAC、BCA、CAB、CBA），因此可以形成的不同选择的总数是：(5・4・3)/(3・2・1) = 10。\n一般来说，\\(n (n − 1)・・・(n − r + 1)\\) 表示在顺序依赖条件下，从 \\(n\\) 个物品中选择 \\(r\\) 个物品的不同选择方式的数量。由于在这种计数中，每 \\(r\\) 个物品的选择方式都会被计算 \\(r!\\) 次，因此，从 \\(n\\) 个物品中可以形成的 \\(r\\) 个不同物品的数量是：\n\\[\n\\frac{n \\cdot (n-1) \\cdot \\cdot \\cdot(n-r+1)}{r!} = \\frac{n!}{(n-r)!r!}\n\\]\n\n\n3.5.2 组合的符号和术语\n\n定义 3.1 定义 \\(\\left(\\begin{array}{cc} n \\\\ r  \\end{array}\\right), \\forall r \\le n\\) 为一次性从 \\(n\\) 个物品中选择 \\(r\\) 个物品的组合数量，则：\n\\[\n\\left(\\begin{array}{cc}\nn \\\\\nr  \n\\end{array}\\right) = \\frac{n!}{(n-r)!r!}\n\\]\n\n\\(\\left(\\begin{array}{cc} n \\\\ r  \\end{array}\\right)\\) 表示在不考虑抽取顺序的情况下，从 \\(n\\) 个元素中选择 \\(r\\) 个元素的不同组合数。例如：\n\n从 8 个人中选择 2 个人的方式：\\(\\left(\\begin{array}{cc} 8 \\\\ 2  \\end{array}\\right) = \\frac{8 \\cdot 7}{2 \\cdot 1}=28\\)。\n从 10 个人中选择 2 个人的方式：\\(\\left(\\begin{array}{cc} 10 \\\\ 2  \\end{array}\\right) = \\frac{10 \\cdot 9}{2 \\cdot 1}=45\\)。\n\n特别注意的是，\\(\\left(\\begin{array}{cc} n \\\\ 0  \\end{array}\\right)\\) = \\(\\left(\\begin{array}{cc} n \\\\ n  \\end{array}\\right)\\) = 1。\n\n练习 3.5 要从 6 名男性和 9 名女性中随机选取 5 人组成一个委员会。如果是随机选择的话，这个委员会由 3 名男性和 2 名女性组成的概率是多少？\n\n\n答案 3.5. 随机选取意味着 \\(\\left(\\begin{array}{cc} 15 \\\\ 5  \\end{array}\\right)\\) 种可能的组合数中的任何一组被选取的可能性都是一致的。因为，3 名男性的选择方式有 \\(\\left(\\begin{array}{cc} 6 \\\\ 3  \\end{array}\\right)\\) 种，2 名女性的选择方式有 \\(\\left(\\begin{array}{cc} 9 \\\\ 2  \\end{array}\\right)\\) 种，根据 基本计数原理，委员会由 3 名男性和 2 名女性组成的概率为：\n\\[\n\\frac{\\left(\\begin{array}{cc} 6 \\\\ 3  \\end{array}\\right) \\cdot \\left(\\begin{array}{cc} 9 \\\\ 2  \\end{array}\\right)}{\\left(\\begin{array}{cc} 15 \\\\ 5  \\end{array}\\right)} = \\frac{240}{1001}\n\\]\n\n\n练习 3.6 从一个具有 \\(n\\) 个物品的集合中随机抽取大小为 \\(k\\) 的样本，则某个给定的物品被抽取到的概率是多少？\n\n\n答案 3.6. 如果某个给定的物品位于 \\(k\\) 中，则意味着 \\(k\\) 由给定的 1 个物品和剩余的 \\(k-1\\) 个物品（从 \\(n-1\\) 个物品中抽取的）组成，则 \\(k\\) 个物品的抽取方式为 \\(\\left(\\begin{array}{cc}  {n-1} \\\\ {k-1}  \\end{array}\\right)\\)。另外，从 \\(n\\) 个物品中抽取 \\(k\\) 个物品的方式总共有 \\(\\left(\\begin{array}{cc}  n \\\\ k  \\end{array}\\right)\\)。因此，从 \\(n\\) 个物品的集合中随机抽取大小为 \\(k\\) 的样本，则某个给定的物品被抽取到的概率为：\n\\[\n\\frac{\\left(\\begin{array}{cc}  {n-1} \\\\ {k-1}  \\end{array}\\right)}{\\left(\\begin{array}{cc}  n \\\\ k  \\end{array}\\right)} = \\frac{\\frac{(n-1)!}{(n-k)!(k-1)!}}{\\frac{n!}{(n-k)!k!}} = \\frac{k}{n}\n\\]\n\n\n练习 3.7 一个篮球队由 6 名黑人球员和 6 名白人球员组成。需要对这些球员随机地两两配对，以确定他们的室友。如果配对是随机进行的，那么黑人球员与白人球员不是室友的概率是多少？\n\n\n答案 3.7. 首先，我们设想对这 6 对球员进行编号，分别是：第 1 对，第 2 对，……。对于第 1 对 球员，有 \\(\\left(\\begin{array}{cc}  12 \\\\ 2  \\end{array}\\right)\\) 种配对方式。然后，第 2 对球员则有 \\(\\left(\\begin{array}{cc}  10 \\\\ 2  \\end{array}\\right)\\) 种配对方式。对于第 3 对球员，则有 \\(\\left(\\begin{array}{cc}  8 \\\\ 2  \\end{array}\\right)\\) 种配对方式，……因此，根据 基本计数原理的泛化规则，这 6 对球员的配对方式总共有 \\(\\left(\\begin{array}{cc}  12 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  10 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  8 \\\\  2 \\end{array}\\right) \\left(\\begin{array}{cc}  6 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  2 \\\\ 2  \\end{array}\\right) = \\frac{12!}{(2!)^6}\\)。所以，不考虑分组序号的情况下，配对方式总共有 \\(\\frac{12!}{2^6 \\cdot 6!}\\)。\n同理，6 名黑（白）人球员之间配对的方式均有 \\(\\frac{ 6! }{ 2^3 \\cdot 3! }\\)。因此，黑人球员与白人球员不是室友的概率为：\\(\\frac{ (\\frac{ 6! }{ 2^3 \\cdot 3! })^2 }{ \\frac{ 12! }{ 2^6 \\cdot 6! } } = \\frac{ 5 }{ 231 } = 0.0216\\)\n\n\n练习 3.8 房间里有 \\(n\\) 个人，则他们的生日不在同一天的概率是多少？如果这个概率要低于 50%，那么 \\(n\\) 至少是多少？\n\n\n答案 3.8. 在不考虑闰年的情况下，每个人的生日可以为一年 365 天中的任何一天，所以 \\(n\\) 个人的生日的可能性为 \\(365^n\\)。如果他们的生日均不在同一天，则其可能性为 \\(365 \\cdot 364 \\cdot \\cdot \\cdot (365 - n + 1)\\)。这是因为第一个人的生日可以是 365 天中的任何一天，第二个人的生日可以是剩下的 364 天中的任何一天，第三个人的生日可以是剩下的 363 天中的任何一天，以此类推。因此，他们的生日不在同一天的概率为 \\(\\frac{ 365 \\cdot 364 \\cdot \\cdot \\cdot (365 - n + 1) }{ (365)^n }\\)。\n令人惊讶的事实是，当 \\(n \\ge 23\\) 时，这个概率小于 50%。也就是说，如果房间里至少有 23 个人的时候，那么他们之中至少有两个人的生日相同的概率将超过 50%。对这个结果，许多人最初会感到惊讶，因为与 365（一年的天数）相比，23 这个数字显得如此之小。然而，每两个人其生日相同的概率是 \\(\\frac{ 365 }{ (365)^2 }=\\frac{ 1 }{ 365 }\\)。而在一个由 23 人组成的群体中，有 \\(\\left(\\begin{array}{cc}  23 \\\\ 2  \\end{array}\\right) = 253\\) 对不同的分组。从这个角度来看，这个结果就不再那么令人惊讶了。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_6",
    "href": "chapter_3/3.html#sec-3_6",
    "title": "3  概率论基础",
    "section": "3.6 条件概率",
    "text": "3.6 条件概率\n在本节中，我们将介绍概率论中最重要的概念之一 ——条件概率（conditional probability）。条件概率 的重要性体现在两个方面。首先，当涉及到实验结果的部分信息可用时，或者需要根据额外信息重新计算概率时，我们经常需要利用 条件概率 来计算概率。其次，事实证明，计算事件概率的最简单的方法通常是以另一事件是否发生作为先决条件。\n如下是一个 条件概率 的例子：假设某人抛了一对骰子，该实验的样本空间 \\(S\\) 可以看作是以下 36 个结果的集合：\n\\[\nS = \\{(i, j), \\ \\ i,j \\in [1,6] \\}\n\\]\n当第一个骰子为 \\(i\\) 点并且第二个骰子为 \\(j\\) 点时，我们称对应的实验结果为 \\((i,j)\\)。假设这 36 个结果发生的可能性都是一样的，则其概率为 \\(\\frac{ 1 }{ 36 }\\)。接下来，我们观察到第一个骰子的点数是 3，那么在这种情况下，两个骰子的点数之和为 8 的概率是多少？为了计算概率，我们做如下的推理：\n\n在第一个骰子的点数是 3 的情况下，我们的实验结果最多有 6 种可能：(3,1)，(3,2)，(3,3)，(3,4)，(3,5)，(3,6)。\n因为每种结果出现的概率都是相同的，因此在第一个骰子为 3 点的条件下，其 6 种可能出现的结果的每种结果出现的概率都是 \\(\\frac{ 1 }{ 6 }\\)。\n因此，两个骰子的点数之和为 8 的结果为 (3, 5)，其概率为 \\(\\frac{ 1 }{ 6 }\\)。\n\n如果我们令 \\(E\\) 表示两个骰子的点数之和为 8 这一事件，令 \\(F\\) 表示第一个骰子的点数为 3 这一事件，则我们刚才获取到的概率称之为在 \\(F\\) 发生的条件下，\\(E\\) 的 条件概率，并记作 \\(P(E|F)\\)。\n作为一个通用的公式，\\(P(E|F)\\) 可以应用于所有的事件 \\(E\\) 和 \\(F\\)。具体来说，如果事件 \\(F\\) 发生，那么为了使得 \\(E\\) 也发生，则实际发生的事件必须同时位于 \\(E\\) 和 \\(F\\) 中，也就是说，必须在 \\(EF\\) 中。然而，由于我们知道 \\(F\\) 已经发生，因此我们可以将 \\(F\\) 视为新的样本空间，因此事件 \\(P(E|F)\\) 发生的概率将等于 \\(EF\\) 相对于 \\(F\\) 的概率。即：\n\\[\np(E|F)=\\frac{ P(EF) }{ P(F) }\n\\tag{3.1}\\]\n如 图 3.5 所示，仅当 \\(P(F) &gt; 0\\) 时，方程式 3.1 才有意义，这意味着，当且仅当 \\(P(F) &gt; 0\\) 时，\\(P(E|F)\\) 才有意义。\n\n\n\n\n\n\n图 3.5: \\(P(E|F)=\\frac{ EF }{ F }\\)\n\n\n\n方程式 3.1 给出的条件概率的定义与在大量重复试验下使用相对频率作为概率的解释是一致的。为了理解这一点，假设重复执行实验 \\(n\\) 次，由于 \\(P(F)\\) 是多次执行条件下 \\(F\\) 发生的比例，因此 \\(F\\) 大约会发生 \\(n \\cdot P(F)\\) 次。类似地，在实验中，大约有 \\(n \\cdot P(EF)\\) 次实验会出现 \\(E\\) 和 \\(F\\) 都发生的情况。因此，在大约 \\(n \\cdot P (F)\\) 次 \\(F\\) 发生的实验中，大约有 \\(n \\cdot P(EF)\\) 次 \\(E\\) 也会发生。也就是说，对于那些结果属于事件 \\(F\\) 的实验，其结果也属于事件 \\(E\\) 的比例大约是：\\(\\frac{ n \\cdot P(EF) }{ n \\cdot P(F) } = \\frac{ P(EF) }{ P(F) }\\)。\n由于当 \\(n\\) 变得越来越大时，如上的近似计算会变得越来越精确，因此 方程式 3.1 给出了在 \\(F\\) 已经发生的情况下 \\(E\\) 也发生的 条件概率 的适当定义。\n\n练习 3.9 一个箱子里有 40 个晶体管，其中有 5 个残品（一开始就无法使用），10 个次品（使用几个小时后才无法使用），以及 25 个合格品。从箱子里随机选取一个晶体管并投入使用，如果该晶体管没有立即失效，那么它是合格品的概率是多少？\n\n\n答案 3.9. 因为抽取的晶体管没有立即失效，因此该晶体管不属于 5 个残品，因此待求解的概率为：\n\\[\n\\begin{align}\nP(合格品|非残品) &= \\frac{ P(合格品, 非残品) }{ P(非残品) } \\\\\n&= \\frac{ P(合格品) }{ P(非残品) } \\\\\n&= \\frac{ \\frac{ 25 }{ 40 } }{ \\frac{ 35 }{ 40 } } \\\\\n&= \\frac{ 5 }{ 7 }\n\\end{align}\n\\]\n应该注意的是，我们也可以通过直接处理缩减后的样本空间来获得结果。也就是说，由于我们知道所选的晶体管不是残品，问题就简化为：从包含 25 个合格品和 10 个次品的箱子中随机选择一个晶体管，该晶体管是合格品的概率是多少？显然，概率等于 \\(\\frac{ 25 }{ 35 }\\)。\n\n\n练习 3.10 琼斯所在的部门正在为那些至少有一个儿子的员工举办一场父子晚宴。这些员工都将受邀参加该晚宴，并会带上他们最小的儿子一起参加晚宴。如果已知琼斯有两个孩子，那么在他受邀参加晚宴的条件下，他的两个孩子都是男孩的概率是多少？假设样本空间为 \\(S\\) 且 \\(S =\\{(b,b),(b,g),(g,b),(g,g)\\}\\)，同时所有结果出现的可能性都相等（例如，\\((b,g)\\) 表示较小的孩子是男孩，较大的孩子是女孩）。\n\n\n答案 3.10. 琼斯受邀参加晚宴这一事实相当于知道他至少有一个儿子。因此，设 \\(B\\) 为两个孩子都是男孩的事件，\\(A\\) 为至少有一个孩子是男孩的事件，我们要求的概率 \\(P(B|A)\\) 为：\\(P(B|A)=\\frac{ P(AB) }{ P(A) }\\) \\(=\\) \\(\\frac{ P(\\{(b, b)\\}) }{ P(\\{(b, b), (b, g), (g, b)\\}) }\\) \\(=\\) \\(\\frac{ \\frac{ 1 }{ 4 } }{ \\frac{ 3 }{ 4 } }\\) \\(=\\) \\(\\frac{ 1 }{ 3 }\\)。\n许多读者错误地认为，在至少有一个男孩的条件下，有两个男孩的概率是 \\(\\frac{1}{2}\\)，而不是正确答案 \\(\\frac{1}{3}\\)。因为他们认为琼斯无法参加晚宴等价于其孩子是男孩或女孩的概率。然而，这个假设本身就是错误的。务必记住，最初有四种等可能的结果，现在，至少有一个孩子是男孩的信息等价于知道结果不是 \\((g, g)\\)。因此，我们只剩下三种等可能的结果：\\((b, b)\\)、\\((b, g)\\)、\\((g, b)\\)，从而表明琼斯参加晚宴时其另外一个孩子为女孩的可能性是为男孩的两倍。\n\n对 方程式 3.1 的两边都乘以 \\(P(F)\\)，我们得到：\n\\[\nP(EF) = P(F) \\cdot P(E|F)\n\\tag{3.2}\\]\n方程式 3.2 表明事件 \\(E\\) 和 \\(F\\) 同时发生的概率等于 \\(F\\) 发生的概率乘以在 \\(F\\) 发生条件下 \\(E\\) 发生的条件概率。在计算事件交集的概率时，方程式 3.2 通常非常有用。练习 3.11 所示的例子说明了这一点。\n\n练习 3.11 佩雷斯女士估计，她所在的公司有 30% 的可能性会在菲尼克斯设立分公司。如果设立了公司真的在菲尼克斯设立分公司，她有 60% 的把握让公司任命其为新的分公司的经理。那么，佩雷斯女士成为菲尼克斯分公司经理的概率是多少？\n\n\n答案 3.11. 令 \\(B\\) 表示公司会在菲尼克斯设立分公司，\\(M\\) 表示任命佩雷斯女士为新的分公司的经理，则待求解的概率为 \\(P(BM)\\)，根据 方程式 3.2 有：\\(P(BM) = P(B)P(M|B) = 0.3 \\cdot 0.6 = 0.18\\)。因此，佩雷斯女士有 18% 的概率成为菲尼克斯分公司的经理。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_7",
    "href": "chapter_3/3.html#sec-3_7",
    "title": "3  概率论基础",
    "section": "3.7 贝叶斯公式",
    "text": "3.7 贝叶斯公式\n令 \\(E\\) 和 \\(F\\) 为事件，则我们可以用如下的式子表示 \\(E\\)：\\(E = EF \\cup EF^c\\)。如 图 3.6 为了让一个点位于 \\(E\\) 中，要么这个点即位于 \\(E\\) 又位于 \\(F\\) 中，要么这个点位于 \\(E\\) 中但是不位于 \\(F\\) 中。\n\n\n\n\n\n\n图 3.6: \\(E=EF \\cup EF^c\\)\n\n\n\n因为 \\(EF\\) 和 \\(EF^c\\) 是互斥的，根据 公理3 有：\n\\[\n\\begin{align}\nP(E)&=P(EF) + P(EF^c) \\\\\n&=P(E|F)P(F) + P(E|F^c)P(F^c) \\\\\n&=P(E|F)P(F) + P(E|F^c)[1 - P(F)]\n\\end{align}\n\\tag{3.3}\\]\n方程式 3.3 表明，事件 \\(E\\) 的概率是 \\(F\\) 发生时 \\(E\\) 发生的条件概率和 \\(F\\) 不发生时 \\(E\\) 发生的条件概率的加权平均数，其中，每个条件概率的权重与它所基于的事件发生的概率相同。方程式 3.3 是一个极其有用的公式，因为 方程式 3.3 允许我们通过某个事件的先决条件事件是否发生来计算该事件的概率。也就是说，在许多情况下，直接计算事件的概率非常困难，但一旦我们知道某个第二事件是否发生，计算该事件的概率就变得比较简单了。\n\n练习 3.12 一家保险公司认为人可以分为两类——容易出意外的人和不容易出意外的人。他们的统计数据显示，一个容易出意外的人在固定的 1 年期内某个时间点发生意外的概率是 0.4，而对于一个不容易出意外的人来说，这个概率则降低到了 0.2。如果我们假设 30% 的人容易出意外，那么新购买保险的人在购买保险后一年内发生意外的概率是多少？\n\n\n答案 3.12. 首先根据新购买保险的人是否容易出意外进行条件化，以获得所需的概率。设 \\(A_1\\) 表示事件：新购买保险的人在购买后一年内会发生意外，设 \\(A\\) 表示新购买保险的人容易出意外事件。因此：\\(P(A_1)=P(A_1|A)P(A) + P(A_1|A^c)P(A^c) = 0.26\\)。\n\n在接下来的一系列示例中，我们将展示如何根据新的信息重新评估初始概率。也就是说，我们将展示如何将新信息与初始概率相结合，以获得新的概率。\n\n练习 3.13 双胞胎可以是同卵双胞胎，也可以是异卵双胞胎。同卵双胞胎，也称为单卵双胞胎，是由一个受精卵分裂成两个遗传上完全相同的胚胎。因此，同卵双胞胎总是拥有相同的基因组。异卵双胞胎，也称为双卵双胞胎，是由两个单独的卵子受精并进入到子宫所形成。异卵双胞胎之间的遗传联系与在不同时间出生的兄弟姐妹一样。洛杉矶某县的一位科学家想知道：目前该县出生的双胞胎中同卵双胞胎的比例，于是他委托该县的一位统计学家来研究这个问题。该统计学家最初要求县里的每家医院记录所有双胞胎的出生情况，并注明这些双胞胎是否是同卵双胞胎。然而，医院告诉她，确定新生双胞胎是否为同卵双胞胎并不是一项简单的任务，因为这需要双胞胎父母的许可，并执行复杂且昂贵的 DNA 研究，但是医院无力承担这些研究费用。经过一些讨论，统计学家只要求医院提供所有双胞胎出生情况的清单数据，并注明这些双胞胎是否是同性别。当统计学家收集到的数据表明，大约 64% 的双胞胎出生时是同性别时，统计学家宣称：大约 28% 的双胞胎是同卵双胞胎。统计学家是怎么得出这个结论的？\n\n\n答案 3.13. 统计学家认为同卵双胞胎总是同性别，而异卵双胞胎，就像任何一对兄弟姐妹一样，有 \\(\\frac{1}{2}\\) 的概率是同性别。设 \\(I\\) 为一对双胞胎是同卵双胞胎的事件，\\(SS\\) 为一对双胞胎是同性别的事件。则，\n\\[\n\\begin{align}\nP(SS) &= P(SS|I)P(I) + P(SS|I^c)P(I^c) \\\\\n&=1 \\cdot P(I) + \\frac{1}{2} \\cdot \\bigg(1 - P(I)\\bigg) \\\\\n&= \\frac{1}{2} + \\frac{1}{2}P(I) \\\\\n&\\approx 0.64 \\\\\n\\therefore P(I) &\\approx 0.28\n\\end{align}\n\\]\n\n\n练习 3.14 让我们重新思考 练习 3.12，假设一名新购买保险的人在购买保险后一年内发生了意外，则该人属于容易出意外的分类的概率是多少？\n\n\n答案 3.14. 最初，在购买保险的那一刻，我们假设他有 30% 的几率是属于容易出意外的分类。也就是说，\\(P(A) = 0.3\\)。然而，基于他在一年内发生了意外的事实，我们现在需要重新评估他容易出意外的概率：\n\\[\n\\begin{align}\nP(A|A_1)&=\\frac{ P(AA_1) }{ P(A_1) } \\\\\n&= \\frac{ P(A)P(A_1|A) }{ P(A_1) } \\\\\n&= \\frac{ 0.3 \\cdot 0.4 }{ 0.26 } \\\\\n&= 0.4615\n\\end{align}\n\\]\n\n\n练习 3.15 在回答一个多项选择题时，一个学生要么知道答案，要么猜答案。设 \\(p\\) 为她知道答案的概率，\\(1-p\\) 为她猜答案的概率。假设一个学生猜对的概率是 \\(\\frac{1}{m}\\)，其中 \\(m\\) 是多项选择题的选项数量。如果一个学生的回答是正确的，那么她知道问题答案的概率是多少？\n\n\n答案 3.15. 令 \\(C\\) 为事件：该学生回答对了该问题，\\(K\\) 为事件：该学生知道答案，则该学生回答正确时，她知道问题答案的概率为：\\(P(K|C) = \\frac{P(KC)}{P(C)}\\)。\n\\[\n\\begin{align}\n\\because P(KC) &= P(C|K)P(K) \\\\\n&=1 \\cdot p \\\\\n&=p\n\\end{align}\n\\]\n为了计算最终的概率，我们还需要计算 \\(P(C)\\) （该学生可以回答正确的概率）： \\[\n\\begin{align}\nP(C) &= P(C|K)P(K) + P(C|K^c)P(K^c) \\\\\n&=p + \\frac{1}{m} \\cdot (1-p) \\\\\n\\therefore P(K|C)&= \\frac{p}{p + \\frac{1}{m} \\cdot (1-p)} \\\\\n&=\\frac{mp}{1+(m-1)p}\n\\end{align}\n\\]\n因此，如果 \\(m=5\\)，\\(p=\\frac{1}{2}\\)，则如果该学生回答正确时，他知道答案的概率为 \\(\\frac{5}{6}\\)。\n\n\n练习 3.16 对于某种疾病的检测而言，实验室的血液检测有 99% 的准确率。然而，该血液检测也会对 1% 的健康受检者产生 “假阳性” 结果（也就是说，如果一个健康的人接受检测，那么检测结果会有 0.01 的概率显示他或她患有该疾病）。如果人群中有 0.5% 的人确实患有这种疾病，那么一个人的检测结果为阳性时，他患有这种疾病的概率是多少？\n\n\n答案 3.16. 令 \\(D\\) 为事件：受检测的人患有该疾病，\\(E\\) 为事件：检测结果为阳性。则：\n\\[\n\\begin{align}\nP(D|E) &= \\frac{P(DE)}{P(E)} \\\\\n&= \\frac{P(E|D)P(D)}{P(E|D)P(D) + P(E|D^c)P(D^c)} \\\\\n&=\\frac{0.99 \\cdot 0.005}{0.99 \\cdot 0.005 + 0.01 \\cdot 0.995} \\\\\n&= 0.3322\n\\end{align}\n\\]\n因此，如果检测结果为阳性，则该人实际上患有该疾病的概率只有 33%。因为血液检测似乎是一种很好的方式，因此很多学生认为这个比例应该会更高，所以他们经常对这个结果感到惊讶。因此是时候提出第二个论点了，尽管第二个论点不如前面的论点严格，但它可能更具启发性。\n由于实际患有这种疾病的人口比例为 0.5%，因此平均而言，每 200 个接受检测的人中就有 1 人患有这种疾病。该检测将以 0.99 的概率确认这个人患有疾病。因此，平均而言，每 200 个接受检测的人中，该检测将确认 0.99 人患有疾病。另一方面，在（平均）199 个健康人中，该检测将错误地认为有 \\(199 \\cdot 0.01\\) 的人患有疾病。因此，对于该检测确认的患有疾病的每 0.99 个病人而言，平均有 1.99 个健康人被错误地认为患有该疾病。因此，当检测结果显示一个人患病时，其结果是正确的比例是：\\(\\frac{0.99}{0.99 + 1.99}=0.3322\\)\n\n当需要根据新的信息更新概率时，方程式 3.3 非常有用。本章接下来的例子将体现这一点。\n\n练习 3.17 在刑事调查的某个阶段，负责调查的警官有 60% 的信心认为某个嫌疑人有罪。假设现在发现了新的证据，显示罪犯具有某种特征（如左撇子、秃头、棕色头发等）。如果有 20% 的人具有这种特征，那么如果嫌疑人具有犯罪特征时，警官对嫌疑人有罪的信心应该是多少？\n\n\n答案 3.17. 令 \\(G\\) 表示事件：嫌疑人有罪，\\(C\\) 表示事件：嫌疑人具有罪犯特征。则：\n\\[\n\\begin{align}\nP(G|C)&=\\frac{P(GC)}{P(C)} \\\\\n\\because P(GC) &= P(G)P(C|G) \\\\\n&= 0.6 \\cdot 1 \\\\\n&= 0.6 \\\\\n\\because P(C) &= P(C|G)P(G) + P(C|G^c)P(G^c) \\\\\n&=1 \\cdot 0.6 + 0.2 \\cdot 0.4 \\\\\n&=0.68\n\\end{align}\n\\]\n\\(P(C|G^c)\\) 表示如果嫌疑人实际上是清白的，那么他具有犯罪特征的概率，我们假设该概率和等于具有这种特征的人比例一致，也就是 0.2。于是：\\(P(G|C) = \\frac{0.6}{0.68} = 0.882\\)。\n\n\n练习 3.18 现在让我们假设犯罪者拥有犯罪特定的可能性为 90%，那么在这种情况下，嫌疑人犯罪的可能性有多大？\n\n\n答案 3.18. 在这种情况下，情况与以前相同，只是现在嫌疑人在犯罪的情况下具有该特征的概率是0.9，而不是1。于是：\n\\[\n\\begin{align}\nP(G|C)&=\\frac{P(GC)}{P(C)} \\\\\n\\because P(GC) &= P(G)P(C|G) \\\\\n&= 0.6 \\cdot 0.9 \\\\\n&= 0.54 \\\\\n\\because P(C) &= P(C|G)P(G) + P(C|G^c)P(G^c) \\\\\n&=0.9 \\cdot 0.6 + 0.2 \\cdot 0.4 \\\\\n&=0.62 \\\\\n\\therefore P(G|C) &= \\frac{0.54}{0.62} \\\\\n&=0.871\n\\end{align}\n\\]\n\n假设 \\(F_1, F_2, ..., F_n\\) 是互斥事件，则 \\(\\bigcup_{i=1}^{n}{F_i} = S\\)。换句话说，\\(F_i\\) 中有且仅有一个事件会发生。则有：\n\\[\nE = \\bigcup_{i=1}^{n}{(EF_i)}\n\\]\n基于 \\(EF_i\\) 为互斥事件的事实，我们有：\n\\[\n\\begin{align}\nP(E)&=\\sum_{i=1}^{n}{P(EF_i)} \\\\\n&=\\sum_{i=1}^{n}{\\big(P(E|F_i)P(F_i)\\big)}\n\\end{align}\n\\tag{3.4}\\]\n对于 \\(n\\) 个互斥事件而言，方程式 3.3 可以泛化为 方程式 3.4。方程式 3.4 表示在给定一组互斥事件 \\(F_1,F_2,...,F_n\\) 时，我们如何通过 \\(F_i\\) 发生时的 \\(E\\) 的条件概率来计算 \\(P(E)\\)。也就是说，\\(P(E)\\) 等于 \\(P(E|F_i)\\) 的加权平均值，其权重为对应的 \\(F_i\\) 发生的概率。\n现在假设 \\(E\\) 已经发生，我们希望确定哪一个 \\(F_j\\) 发生了。根据 方程式 3.4，我们有：\n\\[\n\\begin{align}\nP(F_j|E)&=\\frac{P(EF_j)}{P(E)} \\\\\n&=\\frac{P(E|F_j)P(F_j)}{\\sum_{i=1}^{n}{\\big(P(E|F_i)P(F_i)\\big)}}\n\\end{align}\n\\tag{3.5}\\]\n方程式 3.5 就是 贝叶斯公式（Bayes’ formula），其以英国哲学家 Thomas Bayes 的名字命名。 如果我们把事件 \\(F_j\\) 看作是关于某个主题的可能的“假设”（hypotheses），那么 贝叶斯公式 可以解释为：如何通过实验的证据来修改实验前对这些假设（\\(P(F_j)\\)）的看法。\n\n练习 3.19 一架飞机失踪了，人们推测它坠毁在三个可能区域的概率是相等的。假设 \\(1 - \\alpha_i\\) 表示当飞机确实坠毁在区域 \\(i\\) 时，搜索该区域能发现飞机的概率，其中 \\(i = 1, 2, 3\\)。（常数 \\(\\alpha_i\\) 被称为 忽视概率（overlook probabilities），因为它们代表忽视飞机的概率。\\(\\alpha_i\\) 通常归因于这些区域的地理和环境条件。在区域 1 没有搜索到飞机的情况下，飞机位于区域 \\(i\\) 的条件概率是多少（\\(i = 1, 2, 3\\)）？\n\n\n答案 3.19. 令 \\(R_i\\) 为事件：飞机位于区域 \\(i\\)，令 \\(E\\) 为事件：在区域 1 没有搜索到飞机。根据贝叶斯公式，我们有：\n\\[\n\\begin{align}\nP(R_1|E)&=\\frac{P(ER_1)}{P(E)} \\\\\n&=\\frac{P(E|R_1)P(R1)}{\\sum_{i=1}^{3}(P(E|R_i)P(R_i))} \\\\\n&=\\frac{\\alpha_1 \\cdot \\frac{1}{3}}{\\alpha_1 \\cdot \\frac{1}{3} + 1 \\cdot \\frac{1}{3} + 1 \\cdot \\frac{1}{3}} \\\\\n&=\\frac{\\alpha_1}{\\alpha_2 + 2} \\\\\nFor\\ j=&2,3: \\\\\nP(R_j|E)&=\\frac{P(E|R_j)P(R_j)}{P(E)} \\\\\n&=\\frac{1 \\cdot \\frac{1}{3}}{\\alpha_1 \\cdot \\frac{1}{3} + \\frac{1}{3} + \\frac{1}{3}} \\\\\n&=\\frac{1}{\\alpha_1 + 2}\n\\end{align}\n\\]\n因此，例如，如果 \\(\\alpha_1\\) = 0.4，那么在该区域搜索后未发现飞机的情况下，飞机位于区域 1 的条件概率为 \\(\\frac{1}{6}\\)，而飞机位于区域 2 和区域 3 的条件概率都等于 \\(\\frac{1}{2.4}=\\frac{5}{12}\\)。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sec-3_8",
    "href": "chapter_3/3.html#sec-3_8",
    "title": "3  概率论基础",
    "section": "3.8 独立事件",
    "text": "3.8 独立事件\n本章之前的例子表明，给定 \\(F\\) 时，\\(E\\) 的条件概率 \\(P(E|F)\\) 通常不等于 \\(E\\) 的无条件概率 \\(P(E)\\)。换句话说，如果 \\(F\\) 发生了，那么通常会改变 \\(E\\) 发生的可能性。对于特殊的场景下，当 \\(P(E|F)\\) 等于 \\(P(E)\\) 时，我们说 \\(E\\) 与 \\(F\\) 是 独立 的。也就是说，如果 \\(F\\) 是否发生不会改变 \\(E\\) 发生的概率，那么 \\(E\\) 就是 独立 于 \\(F\\) 的。\n因为 \\(P(E|F)=\\frac{ P(EF) }{ P(F) }\\)，如果\n\\[\nP(EF)=P(E)P(F)\n\\tag{3.6}\\]\n则 \\(E\\) 和 \\(F\\) 是 独立 的。\n因为 方程式 3.6 中，\\(E\\) 和 \\(F\\) 是对称的，因此如果 \\(E\\) 和 \\(F\\) 是 独立 的，那么 \\(F\\) 和 \\(E\\) 也是 独立 的。\n\n定义 3.2 如果两个事件 \\(E\\) 和 \\(F\\) 满足 \\(P(EF)=P(E)P(F)\\)，则 \\(E\\) 和 \\(F\\) 是 独立事件（independent events）。如果两个事件不是 独立事件，则他们之间是 相关的（dependent）。\n\n\n例子 3.4 从一副普通的扑克牌（52 张，去掉大小王）中随机抽取一张牌。如果 \\(A\\) 表示抽到的牌是 A，\\(H\\) 表示抽到的牌是红桃，那么 \\(A\\) 和 \\(H\\) 是独立的，因为 \\(P(AH) = \\frac{1}{52}\\)，而 \\(P(A) = \\frac{4}{52}\\) 且 \\(P(H) = \\frac{13}{52}\\)。\n\n\n例子 3.5 如果我们用 \\(E\\) 来表示下一任美国总统是共和党人，用 \\(F\\) 来表示未来一年内会发生大地震，那么大多数人可能都会假设 \\(E\\) 和 \\(F\\) 是独立的。然而，如果 \\(G\\) 表示未来两年内会发生经济衰退，则 \\(E\\) 与 \\(G\\) 是否是 独立事件 可能就会存在一些争议。\n\n接下来我们将说明：如果 \\(E\\) 和 \\(F\\) 是独立的，则 \\(E\\) 和 \\(F^c\\) 也是独立的。\n\n命题 3.3 如果 \\(E\\) 和 \\(F\\) 是 独立 的，则 \\(E\\) 和 \\(F^c\\) 也是 独立 的。\n\n\n\n\n\n\n\n命题 3.3 的证明过程\n\n\n\n假设 \\(E\\) 和 \\(F\\) 是 独立事件。因为 \\(E = EF \\cup EF^c\\)，并且显然， \\(EF\\) 和 \\(EF^c\\) 是互斥事件，于是有：\n\\[\n\\begin{align}\nP(E)&=P(EF) + P(EF^c) \\\\\n&=P(E)P(F) + P(EF^c) \\\\\n\\therefore P(EF^c)&= P(E)(1-P(F)) \\\\\n&=P(E)P(F^c)\n\\end{align}\n\\]\n\n\n因此，如果 \\(E\\) 独立于 \\(F\\)，那么 \\(E\\) 发生的概率不会因 \\(F\\) 是否发生而改变。\n现在假设 \\(E\\) 即独立于 \\(F\\)，也独立于 \\(G\\)。那么 \\(E\\) 是否肯定独立于 \\(FG\\)？令人惊讶的是，答案是否定的。\n\n例子 3.6 抛两颗公平（骰子的点是等概率事件）的骰子。令 \\(E_7\\) 表示两颗骰子的点数之和为 7，令 \\(F\\) 表示第一颗骰子的点数为 4，令 \\(T\\) 表示第二颗骰子的点数为 3。可以证明（问题 36）\\(E_7\\) 独立于 \\(F\\)，且 \\(E_7\\) 也独立于 \\(T\\)，但显然 \\(E_7\\) 不独立于 \\(FT\\)（因为 \\(P(E_7|FT) = 1\\)）。\n\n根据 例子 3.6，看起来，对于 3 个事件之间的独立性的定义，仅仅满足 \\(\\left(\\begin{array}{cc}  3 \\\\ 2  \\end{array}\\right)\\) 对事件之间是独立的是不够的。\n\n定义 3.3 对于三个事件：\\(E\\), \\(F\\), \\(G\\)，如果他们满足：\n\\[\n\\begin{align}\nP(EFG) &= P(E)P(F)P(G) \\\\\nP(EF) &= P(E)P(F) \\\\\nP(EG) &= P(E)P(G) \\\\\nP(FG) &= P(F)P(G)\n\\end{align}\n\\]\n则 \\(E\\)，\\(F\\)，\\(G\\) 是相互独立的。\n\n需要注意的是，如果事件 \\(E\\)、\\(F\\)、\\(G\\) 是独立的，那么 \\(E\\) 和由 \\(F\\) 和 \\(G\\) 形成的任何事件之间也是独立的。例如，\\(E\\) 与 \\(F \\cup G\\) 独立，因为：\n\\[\n\\begin{align}\nP\\bigg(E(F \\cup G)\\bigg) &= P(EF \\cup EG) \\\\\n&=P(EF) + P(EG) - P(EFG) \\\\\n&=P(E)P(F) + P(E)P(G) - P(E)P(FG) \\\\\n&=P(E)\\bigg(P(F) + P(G) - P(FG)\\bigg) \\\\\n&=P(E)P(F \\cup G)\n\\end{align}\n\\]\n当然，我们可以将 定义 3.3 扩展到大于 3 个事件的范围。对于 \\(n\\) 个事件 \\(E_1, E_2, ..., E_n\\)，如果这 \\(n\\) 个事件的所有的子集 \\(E_{1}, E_{2}, ..., E_{r},\\ r \\le n\\) 都满足 \\(P(E_{1}E_{2}...E_{r})\\) = \\(P(E_1)P(E_2)...P(E_r)\\)，则这 n 个事件是相互独立的。\n有时，我们所考虑的实验需要执行一系列子实验。例如，如果实验为连续抛掷硬币，那么我们可以将每次抛掷都视为一个子实验。在许多情况下，我们会假设任何一个子实验的结果对其他子实验没有影响，此时，我们说这些子实验之间是 独立 的。\n\n练习 3.20 如果一个系统由 \\(n\\) 个独立组件构成，且当至少有一个组件工作时，该系统就能工作，那么我们就称这个系统为并行系统，如 图 3.7。对于这样一个系统，如果组件 \\(i\\) 与其他组件独立，并以\\(p_i, i=1,2,...,n\\) 的概率发挥作用，那么整个系统可工作的概率是多少？\n\n\n\n\n\n\n图 3.7: 并行系统示意图\n\n\n\n\n\n答案 3.20. 令 \\(A_i\\) 表示事件：组件 \\(i\\) 可以工作，则：\n\\[\n\\begin{align}\nP(系统可工作) &= 1 - P(系统不可工作) \\\\\n&= 1 - P(所有组件均无法工作) \\\\\n&= 1 - P(A_1^c A_2^c \\cdot \\cdot \\cdot A_n^c) \\\\\n&= 1 - \\prod_{i=1}^{n}{P(A_i^c)} \\\\\n&= 1 - \\prod_{i=1}^{n}{(1-p_i)}\n\\end{align}\n\\]\n\n\n练习 3.21 有 \\(n\\) 张优惠券，每张优惠券的类型均不同且相互独立，第 \\(j\\) 张优惠券的类型为 \\(j\\)，且其出现的概率为 \\(p_j\\)，\\(\\sum_{j=1}^{n}{p_j}=1\\)。我们从其中选取 \\(k\\) 张优惠券，计算在第 \\(i\\) 类优惠券存在的情况下，第 \\(j\\) 类优惠券也存在的概率（\\(i \\ne j\\)）。\n\n\n答案 3.21. 令 \\(A_r\\) 为事件：我们收集的优惠券中存在类型为 \\(r\\) 的优惠券，则 \\(P(A_j|A_i)=\\frac{ P(A_jA_i) }{ P(A_i) }\\)。可以考虑使用补集来计算 \\(P(A_i)\\) 和 \\(P(A_jA_i)\\)：\n\\[\n\\begin{align}\nP(A_i) &= 1-P(A_i^c) \\\\\n&= 1-P\\{k张优惠券均不是第 i 类优惠券\\} \\\\\n&= 1 - \\prod_{l=1}^{k}{\\big(1 - P(A_i)\\big)} \\\\\n&= 1 - (1 - p_i)^k \\\\\nP(A_iA_j) &= 1 - P(A_i^c \\cup A_j^c) \\\\\n&= 1 - \\bigg(P(A_i^c) + P(A_j^c) - P(A_i^c A_j^c)\\bigg) \\\\\n&= 1 - (1-p_i)^k - (1 - p_j)^k + (1 - p_i - p_j)^k\n\\end{align}\n\\]\n因此，\\(P(A_j|A_i)=\\frac{ 1 - (1-p_i)^k - (1 - p_j)^k + (1 - p_i - p_j)^k }{ 1 - (1 - p_i)^k }\\)。\n\n\n\n\n\n\n\n务必区分 独立事件 和 互斥事件\n\n\n\n在 章节 3.2 中，我们提到：\n\n如果 \\(EF = \\emptyset\\)，则意味着 \\(E\\) 和 \\(F\\) 不能同时发生，此时我们称 \\(E\\) 和 \\(F\\) 为 互斥事件。\n\n在本节中，我们提到：\n\n如果 \\(F\\) 是否发生不会改变 \\(E\\) 发生的概率，那么 \\(E\\) 和 \\(F\\) 就是 相互独立 的。且 \\(P(EF)=P(E)P(F)\\)。\n\n我们往往会混淆 独立事件 和 互斥事件 的概念，互斥指的是两个随机事件没有共同的基本事件，也即这两个事件不可能同时发生。从集合观点看，即两个事件没有交集，即 \\(EF = \\emptyset\\)。\n那么，如果 \\(E\\) 和 \\(F\\) 独立，是否意味着：\n\\[\nE和F相互独立 \\Longleftrightarrow E和F没有关联 \\Longleftrightarrow E \\cap F = \\emptyset\n\\]\n显然，这是不对的。比如，生一个孩子，现有两事件：\n\n\\(E\\)：孩子是男孩\n\\(F\\)：孩子是女孩\n\n显然，\\(E\\) 和 \\(F\\) 是互斥的。\n如果生两个孩子，也有两个事件：\n\n\\(A\\)：第一个孩子是男孩\n\\(B\\)：第二个孩子是女孩\n\n此时，\\(A\\) 和 \\(B\\) 是相互独立的，因为第一个孩子的性别肯定和第二个孩子的性别是没有关联的。那么事件 \\(AB\\)（也就是生两个孩子，第一个孩子是男孩且第二个孩子是女孩）的概率是多少 呢？\n显然，\\(P(AB)=\\frac{ 1 }{ 4 }\\)。此时，即 \\(A\\) 和 \\(B\\) 是相互独立的，\\(A \\cap B\\) 也是存在的。",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#问题",
    "href": "chapter_3/3.html#问题",
    "title": "3  概率论基础",
    "section": "问题",
    "text": "问题\n\n一个盒子里有三个弹珠——一个红色，一个绿色，和一个蓝色。考虑一个实验：从盒子里取出一个弹珠，然后将其放回盒子中，再从中抽取第二个弹珠。\n\n\n描述该实验的样本空间。\n在取出第一个弹珠后不将其放回盒子，然后取出第二个弹珠，在该场景下，描述该实验的样本空间。\n\n\n一个实验为抛三次硬币，则这个实验的样本空间是什么？实验结果中正面朝上的次数多于反面朝上的次数的事件是什么？\n令 \\(S = \\{1,2,3,4,5,6,7\\}\\)，\\(E = \\{1,3,5,7\\}\\)，\\(F = \\{7,4,6\\}\\)，\\(G = \\{1,4\\}\\)，计算如下事件：\n\n\n\\(EF\\)\n\\(EG^c\\)\n\\(E^c(F \\cup G)\\)\n\\(E \\cup FG\\)\n\\(EF^c \\cup G\\)\n\\(EG \\cup FG\\)\n\n\n抛两枚骰子，设 \\(E\\) 为事件：两枚骰子点数之和为奇数；\\(F\\) 为事件：第一枚骰子点数为 1；\\(G\\) 为事件：两枚骰子点数之和为 5。描述如下的事件：\\(EF\\)、\\(E \\cup F\\)、\\(FG\\)、\\(EF\\) 的补集（\\(EF^c\\)）以及 \\(EFG\\)。\n一个系统由四个组件组成，每个组件要么正常工作，要么不工作。考虑一个实验，该实验包括观察每个组件的状态，并将实验的结果表示为向量 \\((x_1, x_2, x_3, x_4)\\)，如果第 \\(i\\) 个组件正在工作，则 \\(x_i\\) 等于 1，否则 \\(x_i\\) 等于 0。\n\n\n这个实验的样本空间中有多少种结果？\n假设系统将在以下情况下工作：如果组件 1 和 2 都正常工作，或者如果组件 3 和 4 都正常工作。则系统可以工作的事件中所有的结果是什么？\n设 \\(E\\) 为事件：组件 1 和 3 都不工作，则事件 \\(E\\) 中包含多少种结果？\n\n\n\\(E\\)，\\(F\\)，\\(G\\) 是三个事件，给出如下事件的表达式：\n\n\n只有 \\(E\\) 发生\n只有 \\(E\\) 和 \\(F\\) 发生，但是 \\(F\\) 不发生\n至少有一个事件发生\n至少有两个事件发生\n三个事件都发生\n三个事件都不发生\n最多有一个事件发生\n最多有两个事件发生\n只有两个事件发生\n最多三个事件都发生\n\n\n给出如下的表达式所表示的事件：\n\n\n\\(E \\cup E^c\\)\n\\(EE^c\\)\n\\((E \\cup F)(E \\cup F^c)\\)\n\\((E \\cup F)(E^c \\cup F)(E \\cup F^c)\\)\n\\((E \\cup F)(F \\cup G)\\)\n\n\n用韦恩图来表示如下的关系：\n\n\n如果 \\(EF \\subset E\\)， 则 \\(E \\subset E \\cup F\\)\n如果 \\(E \\subset F\\)，则 \\(F^c \\subset E^c\\)\n交换律是正确的\n结合律是正确的\n\\(F = FE \\cup FE^c\\)\n\\(E \\cup F = E \\cup E^cF\\)\n德摩根定律是正确的\n\n\n对于如下的韦恩图，用 \\(E\\)、\\(F\\) 和 \\(G\\) 来描述图中罗马数字 I~VII 表示的事件。\n\n\n10.证明：如果 \\(E \\subset F\\)，则 \\(P(E) \\le P(F)\\)。\n\n证明如下所示的布尔不等式（Boole’s inequality）：\n\n\\[\nP\\bigg(\\bigcup_{i=1}^{n}{E_i}\\bigg) \\le \\sum_{i=1}^{n}{P(E_i)}\n\\]\n\n证明：如果 \\(P(E)=0.9\\)，\\(P(F)=0.9\\)，则 \\(P(EF) \\ge 0.8\\)。\n\n\n证明邦费罗尼不等式（Bonferroni’s inequality）：\\(P(EF) \\ge P(E) + P(F) -1\\)。\n\n\n证明：\n\n\n\\(P(EF^c)=P(E) - P(EF)\\)\n\\(P(E^cF^c) = 1 - P(E) -P(F) + P(EF)\\)\n\n\n证明：事件 \\(E\\) 或 \\(F\\) 中恰好有一个发生的概率等于 \\(P(E) + P(F) - 2P(EF)\\)。\n计算表达式的值：\\(\\left(\\begin{array}{cc}  9 \\\\ 3  \\end{array}\\right)\\)，\\(\\left(\\begin{array}{cc}  9 \\\\ 6  \\end{array}\\right)\\)，\\(\\left(\\begin{array}{cc}  7 \\\\ 2  \\end{array}\\right)\\)，\\(\\left(\\begin{array}{cc}  7 \\\\ 5  \\end{array}\\right)\\)，\\(\\left(\\begin{array}{cc}  10 \\\\ 7  \\end{array}\\right)\\)。\n证明：\\(\\left(\\begin{array}{cc}  n \\\\ r  \\end{array}\\right)\\) = \\(\\left(\\begin{array}{cc}  n \\\\ n-r  \\end{array}\\right)\\)。\n证明：\\(\\left(\\begin{array}{cc}  n \\\\ r  \\end{array}\\right)\\) = \\(\\left(\\begin{array}{cc}  n-1 \\\\ r-1  \\end{array}\\right) + \\left(\\begin{array}{cc}  n-1 \\\\ r  \\end{array}\\right)\\)。\n5 个男孩和 10 个女孩随机排成一行——也就是说，15! 中的每种排列的可能性都是一样的。\n\n\n第 4 个位置的人是男孩的概率是多少？\n第 12 个位置的人是男孩的概率是多少？\n某个男孩排在第 3 个位置的概率是多少？\n\n\n考虑一个由 23 个不相关的人组成的集合。因为每两个人在同一天出生的概率为 ，并且总共有 \\(\\left(\\begin{array}{cc}  23 \\\\ 2  \\end{array}\\right)\\) = 253 对组合方式。那么，为什么至少两个人在同一天出生的概率不是 \\(\\frac{253}{365}\\)？\n把 3 个不同的整数值分别写在 3 张不同的卡片上，并随机地将卡片标记为 A、B 和 C。比较 A 卡片和 B 卡片上的值，这两个值中较小的值所在的卡片与 C 卡片上的值比较，那么 A、B 两张卡片中较小数值的卡片的数值小于 C 卡片上的数值的概率是多少？\n事件 \\(A\\) 发生的可能性是 60%。如果 \\(A\\) 不发生，那么 \\(B\\) 发生的可能性是 10%。\n\n\nA 或 B 中至少有一个发生的概率是多少？\n如果 \\(A\\) 是事件：民主党在 2012 年赢得总统竞选，\\(B\\) 是事件：2013 年洛杉矶发生 6.2 级或更高级别地震，你认为 \\(A\\) 和 \\(B\\) 同时发生的概率是多少？你做出了什么假设？\n\n\n一个大型会计公司的 100 名会计师的年薪样本均值为 130000 美元，样本标准差为 20000 美元。如果从这个群体中随机选择一名会计师，则：\n\n\n其年薪在 90000 美元和 170000 美元之间的概率是多少？\n其年薪超过 150,000 美元的概率是多少？\n\n\n提示：使用切比雪夫不等式。\n\n\n有三张卡片，一张两面都涂成红色，一张两面都涂成黑色，还有一张一面涂成红色、另一面涂成黑色。随机选择一张卡片放在桌子上，如果朝上的一面是红色，那么另一面也是红色的概率是多少？\n一对夫妇有两个孩子。如果老大是女孩，那么两个孩子都是女孩的概率是多少？\n某大学的学生中有 52% 是女性。这所大学中，主修计算机科学的学生占比 5%，主修计算机科学的女生占比 2%。如果随机选择一名学生，计算以下条件概率：\n\n\n如果该学生主修计算机科学，该该学生是女生的概率。\n如果该学生是女生，该学生主修计算机科学的概率。\n\n\n调研 500 对参加工作的已婚夫妇的年薪，得到了以下信息：\n\n\n\n\n\n\n\n\n\n\nHusband &lt; $50,000\nHusband &gt; $50,000\n\n\n\n\nWife &lt; $50,000\n212\n198\n\n\nWife &gt; $50,000\n36\n54\n\n\n\n从上表中可以看出，妻子的收入超过丈夫，并且丈夫的收入低于 50000 美元的夫妇数量为 36。\n如果从这 500 对夫妇中随机选择一对，那么：\n\n丈夫的收入低于 50000 美元的概率是多少？\n丈夫收入超过 50000 美元的情况下，妻子收入超过 50000 美元的条件概率是多少？\n丈夫收入低于 50000 美元的情况下，妻子收入超过 50000 美元的条件概率是多少？\n\n\n当地有两家工厂生产微波炉。A 工厂生产的每个微波炉有 0.05 的概率是次品，B 工厂生产的每个微波炉有 0.01 的概率是次品。假设你购买了两台在同一工厂生产的微波炉，这两台微波炉是这两家工作生产的可能性是相同的。如果你发现第一台微波炉是次品，那么另一台也是次品的条件概率是多少？\n抛三个骰子，其中一个红色、一个蓝色、一个黄色。我们关注的是蓝色骰子的点数小于黄色骰子的点数，而黄色骰子的点数又小于红色骰子的点数的概率。（也就是说，如果 B、R、Y 分别代表蓝色、红色、黄色骰子的点数，那么我们关心的是 P(B &lt; Y &lt; R) 的概率。\n\n\n三个骰子的点数都不同的概率是多少？\n三个骰子的点数都不同时，B &lt; Y &lt; R 的条件概率是多少？\n\\(P(B&lt;Y&lt;R)\\) 是多少？\n如果我们将实验的结果视为向量 \\((B, R, Y)\\)，那么样本空间中有多少种可能的结果？\n不使用 (c) 的答案，计算 B &lt; Y &lt; R 的结果数量。\n使用 (d) 和 (e) 部分的结果来验证你对 (c) 的答案。\n\n\n在你度假的时候，你让邻居帮忙给一棵生病的植物浇水。如果没有水，这颗植物的死亡概率是 0.8，如果有水，它的死亡概率是 0.15。你有 90% 的把握确认你的邻居会记得给植物浇水。\n\n\n当你回来时，植物存活的概率是多少？\n如果植物死了，你的邻居忘记浇水的概率是多少？\n\n\n有两个球，每个球都有相同的可能性被染成红色或蓝色，把这两个球放入一个瓮中。从翁中随机选择一个球，记下球的颜色，然后将其放回瓮中。如果前两次抽取到的球都是红色，那么\n\n\n瓮中两个球都是红色的概率是多少？\n下一次选中红球的概率是多少？\n\n\n一个养老院社区总共有 1000 人，其中 600 人为共和党人，而其他人为民主党人。在一次地方选举中，养老院的所有人都投了票，其中 60 名共和党人把票投给了民主党候选人，50 名民主党人把票投给了共和党候选人。如果随机选择的一名社区成员把票投给了共和党候选人，那么她是民主党的概率是多少？\n有两个涂成黑色或者金色的球放入一个瓮中。假设每个球涂成黑色的概率是 $，且这些事件是相互独立的。\n\n\n假设你得知至少有一个球是金色的，计算两个球都被涂成金色的条件概率。\n假设现在瓮发生了倾斜，然后一个球掉了出来。如果这个球是金色的，那么两个球都是金色的概率是多少？请解释。\n\n\n有两个外观相同的柜子，每个柜子都有两个抽屉。柜子 A 的每个抽屉里都有一个银币，而柜子 B 的一个抽屉里有银币，另一个抽屉里有金币。随机选择一个柜子，打开其中一个抽屉，发现了一枚银币。则打开该柜子的另一个抽屉，里面有银币的概率是多少？\n前列腺癌是男性中最常见的癌症类型。医生通常会进行一项测试——测量仅由前列腺腺产生的 PSA 蛋白（前列腺特异性抗原）水平——来作为男性是否患有前列腺癌的指标。尽管较高的 PSA 水平表明有癌症，但这项测试非常不可靠。事实上，正常男性的 PSA 水平升高的概率约为 0.135；如果男性确实患有癌症，这一概率将增加到约 0.268。基于其他因素，如果医生有 70% 的把握确定男性患有前列腺癌，那么给定以下条件，他患有癌症的条件概率是多少？\n\n\n测试显示 PSA 水平升高\n测试显示 PSA 水平没有升高\n假设医生最初认为该男性有 30% 的可能性患有前列腺癌，则他患有癌症的条件概率是多少？\n\n测试显示 PSA 水平升高\n测试显示 PSA 水平没有升高\n\n\n\n假设一家保险公司将人们分为三类：低风险、平均风险和高风险。根据他们的记录，低风险、平均风险和高风险的人在一年内发生事故的概率分别为 0.05、0.15 和 0.30。如果 20% 的人口是 “低风险” 人群，50% 是 “平均风险”人群，30% 是 “高风险”人群，那么在固定年份中，有多少人会发生事故？如果购买保险者 A 在 1987 年没有发生事故，那么该人是低风险或者平均风险的概率是多少？\n抛两枚骰子，令 \\(E\\) 表示事件：骰子点数之和等于 7。\n\n\n证明 \\(E\\) 与第一个骰子的点数是 4 之间是独立的。\n证明 \\(E\\) 与第二个骰子的点数是 3 之间是独立的。\n\n\n下图所示电路中，第 \\(i\\) 个继电器关闭的概率为 \\(p_i\\)。如果所有继电器都是独立工作的，那么对于各自的电路，A 和 B 之间有电流的概率是多少？\n\n\n\n\n\n\n\n\n\n\n\n(a) A\n\n\n\n\n\n\n\n\n\n\n\n(b) B\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) C\n\n\n\n\n\n\n\n图 3.8\n\n\n\n一个工程系统由 \\(n\\) 个组件组成，当且仅当至少有 \\(k\\) 个组件正常工作时，系统才能正常工作，这种工程系统称之为 k-out-of-n 系统（k ≤ n）。假设系统中的所有组件都独立工作。\n\n\n如果第 \\(i\\) 个组件正常工作的概率为 \\(P_i\\)，计算一个 2-out-of-4 系统正常工作的概率。\n如果第 \\(i\\) 个组件正常工作的概率为 \\(P_i\\)，计算一个 3-out-of-5 系统正常工作的概率。\n\n\n抛 5 次硬币，计算以下情况的概率：\n\n\n前三次结果相同的概率。\n前三次结果相同或者后三次结果相同的概率。\n前三次中至少有两次正面向上，并且最后三次中至少有两次反面向上的概率。\n\n\n假设进行 \\(n\\) 次独立试验，每次试验的结果为 0、1、2，其对应的概率分别为 0.3、0.5、0.2。计算结果 1 和结果 2 都至少发生一次的概率。\n一个并行系统，至少有一个组件可以工作该系统就可以正常工作。一个由 \\(n\\) 个组件组成的并行系统，假设每个组件独立工作的概率为 \\(\\frac{1}{2}\\)。计算系统正常工作时，组件 1 也正常工作的条件概率。\n某种生物拥有 5 种不同基因对（我们用英文字母表的前 5 个字母来表示）。每种基因都有两种形式（我们用小写字母和大写字母表示）。大写字母表示显性基因，这意味着：如果一个生物拥有基因对 \\(xX\\)，它将在外表上呈现出 \\(X\\) 基因的特征。例如，如果 \\(X\\) 代表棕色眼睛，\\(x\\) 代表蓝色眼睛，那么拥有基因对 \\(XX\\) 或 \\(xX\\) 的个体将拥有棕色眼睛，而拥有基因对 \\(xx\\) 的个体将是蓝眼睛。生物的外观特征被称为其表型（phenotype），而其遗传构成（即基因对）被称为其基因型。（因此，具有不同基因型 \\(aA, bB, cc, dD, ee\\) 和 \\(AA, BB, cc, DD, ee\\) 的两个生物体具有相同的表现型。）在两个生物体交配时，对于每个基因对，每个生物体会随机贡献其基因对中的一个。假设一个生物体的 5 个基因对是独立的，并且与其伴侣的基因贡献无关。在具有基因型 \\(aA, bB, cC, dD, eE\\) 和 \\(aa, bB, cc, Dd, ee\\) 的两个生物体交配时，则其后代：\n\n\n在表现型上，类似于：\n\n第一个亲本；\n第二个亲本；\n任意一个亲本；\n两个亲本都不像？\n\n在基因型上，类似于：\n\n第一个亲本；\n第二个亲本；\n任意一个亲本；\n两个亲本都不像？\n\n\n\n狱卒告知三名囚犯，会从他们三人中随机选择一个处决，而释放其他两人。囚犯 A 要求狱卒私下告诉他哪一位同伴将被释放，并声称透露这一信息并无害处，因为他已经知道另外两人中至少有一人会被释放。狱卒拒绝回答这个问题，并指出如果 A 知道哪一位同伴将被释放，那么他自己被处决的概率将从三分之一上升到二分之一，因为那时他将是剩下的两个囚犯中的一个。你如何看待狱卒的推理？\n尽管我的父母都有棕色的眼睛，但我的眼睛是蓝色的。你认为我妹妹有蓝色眼睛的概率是多少？（如问题 42 所述，一个从父母双方都获得蓝色眼睛基因的人会有蓝色的眼睛，而一个从父母一方获得蓝色眼睛基因、另一方获得棕色眼睛基因的人会有棕色的眼睛。）\n在一个 7 局 4 胜制的比赛中，首先赢得 4 局比赛的队伍将是获胜者。假设每局比赛中，A 获胜的概率为 \\(p\\)，\n\n\n如果一方以 3 比 0 领先，那么领先的是队伍 A 的概率是多少？\n如果一方以 3 比 0 领先，那么该队伍赢得比赛的概率是多少？\n如果 \\(p = \\frac{1}{2}\\)，那么赢得第一局比赛的队伍赢得整场比赛的概率是多少？\n\n\n假设 3 张卡片上分别写有互不相同的整数值。假设这些卡片将以随机顺序提供给你。当提供给你一张卡片时，你必须立即决定是否接受它。一旦你接受了一张卡片，整个过程就结束了。如果你拒绝了一张卡片，那么将提供下一张卡片给你（如果还有的话）。如果你拒绝了前两张卡片，那么你必须接受最后一张卡片。\n\n\n如果你打算接受第一张牌，那么你接受的牌上的数值最大的概率是多少？\n如果你打算拒绝第一张牌，并且只有在第二张牌的数值大于第一张牌时才接受第二张牌，那么你接受的牌上其数值最大的概率是多少？\n\n\n假设 \\(A, B, C\\) 是三个事件，\\(P (A) = 0.2\\)，\\(P (B) = 0.3\\)，\\(P (C) = 0.4\\)。\n\n\n计算以下情况下事件 \\(A\\) 和 \\(B\\) 中至少有一个发生的概率：\n\n如果 A 和 B 是互斥的。\n如果 A 和 B 是独立的。\n\n找出以下情况下事件 \\(A, B, C\\) 都发生的概率：\n\n如果 A, B, C 是独立的；\n如果 A, B, C 是互斥的。\n\n\n\n在参与常规筛查的 45 岁女性中，有 2% 的女性患有乳腺癌。在这些患有乳腺癌的女性中，有 90% 的女性的乳腺 X 光检查呈阳性。而正常女性中，也有 10% 的女性的乳腺 X 光检查会呈阳性。已知一个女性的乳腺 X 光检查呈阳性，她患有乳腺癌的概率是多少？\n12% 的美国家庭居住在加利福尼亚州。总共有 3.3% 的美国家庭年收入超过 250000 美元，而加利福尼亚州总共有 6.3% 的家庭年收入超过 250000 美元。如果随机选择一个年收入超过 250000 美元的美国家庭，它来自加利福尼亚州的概率是多少？\n事件 \\(A\\) 发生的概率是 60%。如果 \\(A\\) 不发生，事件 \\(B\\) 发生的概率是 10%。事件 \\(A\\) 或 \\(B\\) 中至少有一个发生的概率是多少？\n假设三张卡片上分别写有不同的数值，然后随机将这三张卡片标记为 A、B、C 。比较卡片 A 和 B 上的值，这两个值中较小的那个值也小于卡片 C 上的值的概率是多少？",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>概率论基础</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html",
    "href": "chapter_4/4.html",
    "title": "4  随机变量和期望",
    "section": "",
    "text": "4.1 随机变量\n当执行随机实验时，我们并不总是对实验结果的全部细节都感兴趣，我们仅对由结果确定的某些 数值量（numerical quantity）的值感兴趣。例如，在抛骰子时，对于每个骰子的点数而言，我们并不感兴趣；我们通常对两个骰子的点数之和感兴趣。也就是说，我们可能想知道点数总和是 7 的情况，而并不关心实际结果是否是：（1, 6）、（2, 5）、（3, 4）、（4, 3）、（5, 2）、（6, 1）。此外，对于土木工程师而言，他们可能不关心水库水位的日常涨落（我们可以将水库水位的日常涨落数据视为实验结果），他们只关心雨季结束时的水位。由实验结果确定的我们感兴趣的这些 量化指标（quantities），我们称为 随机变量（random variables）。\n因为 随机变量 的值是由实验结果确定的，因此，对于 随机变量 的可能的值，我们可以对其给与概率赋值。\n换句话说，随机变量 \\(X\\) 的取值为 2~12 之间的任何整数值，其每个取值的概率由 方程式 4.1 给出。由于 \\(X\\) 必须为某个取值，因此我们必有：\n\\[\n1 = P(S) = P\\Bigg( \\bigcup_{i=2}^{12}{\\{X=i\\}} \\Bigg) = \\sum_{i=2}^{12}{P\\{X=i\\}}\n\\tag{4.2}\\]\n利用 方程式 4.1 可以非常简单的验证 方程式 4.2。\n在这个实验中，我们感兴趣的另一个 随机变量 是第一个骰子的点数。令 \\(Y\\) 表示 随机变量：抛两个骰子时第一个骰子的点数。则 \\(Y\\) 的取值为 1~6 之间的任何值。也就是说：\n\\[\nP\\{Y=i\\} = \\frac{1}{6}, i=1,2,3,4,5,6 \\quad \\blacksquare\n\\tag{4.3}\\]\n我们令 \\(X\\) 表示购买的两个电子元器件中没有缺陷的元器件数量，那么 \\(X\\) 是一个 随机变量，且其取值为 0、1、2 中的一个：\n\\[\n\\begin{align}\nP\\{X=0\\} &= 0.09 \\\\\nP\\{X=1\\} &= 0.42 \\\\\nP\\{X=2\\} &= 0.49\n\\end{align}\n\\tag{4.4}\\]\n如果我们主要关注这两个电子元器件是否至少有一个没有缺陷，则我们可以对 随机变量 \\(I\\) 作如下定义：\n\\[\nI = \\begin{cases}\n1, \\quad & if \\ X=1, 2 \\\\\n0, \\quad & if \\ X=0\n\\end{cases}\n\\tag{4.5}\\]\n如果 \\(A\\) 表示事件：至少一个元器件没有缺陷，则根据 \\(A\\) 是否发生，\\(I\\) 将等于 1 或 0。因此，我们称 随机变量 \\(I\\) 为 事件 \\(A\\) 的 指示随机变量（indicator random variable）。\\(I\\) 的可能取值的概率为：\n\\[\n\\begin{align}\n&P\\{I=1\\}=0.91 \\\\\n&P\\{I=0\\}=0.09 \\qquad \\blacksquare\n\\end{align}\n\\tag{4.6}\\]\n在 例子 4.1 和 例子 4.2 这两个例子中，我们感兴趣的 随机变量 的可能取值的数量是有限的。对于那些取值可以写成有限序列 \\(x_1,..., x_n\\) 或者无限序列 \\(x_1,...\\) 的 随机变量 称为 离散随机变量（discrete random variables）。例如，一个取值集合为非负整数的 随机变量 就是 离散随机变量。然而，也存在取值为连续数值的 随机变量，我们称这种 随机变量 为 连续随机变量（continous random variables）。例如，假定汽车的寿命位于某个区间 \\((a,b)\\) 时，表示汽车寿命的 随机变量 就是 连续随机变量。\n随机变量 \\(X\\) 的累积分布函数（cumulative distribution function）\\(F\\) 的定义如下：\n\\[\nF(x) = P\\{X \\le x\\}\n\\tag{4.7}\\]\n也就是说，\\(F(x)\\) 是 随机变量 \\(X\\) 取值小于或等于 \\(x\\) 的概率。\n我们可以用 随机变量 \\(X\\) 的分布函数 \\(F\\) 来回答所有关于 \\(X\\) 的概率问题。例如，假如我们想计算 \\(P\\{a \\lt X \\le b\\}\\)。要计算该概率，我们首先注意到 事件 \\({X \\le b}\\) 可以表示为两个 互斥事件 \\({X \\le a}\\) 和 \\({a \\lt X \\le b}\\) 的并集。因此，根据 公理3（章节 3.4），我们得到：\n\\[\n\\begin{align}\nP\\{X \\le b\\}&=P\\{X \\le a\\} + P\\{a \\lt X \\le b\\} \\\\\n\\therefore P\\{a \\lt X \\le b\\} &= F(b) - F(a)\n\\end{align}\n\\tag{4.8}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#随机变量",
    "href": "chapter_4/4.html#随机变量",
    "title": "4  随机变量和期望",
    "section": "",
    "text": "例子 4.1 令 \\(X\\) 表示随机变量：抛 2 个骰子的点数之和，则：\n\\[\n\\begin{align}\nP\\{X=2\\} &= P(\\{(1,1)\\}) = \\frac{1}{36} \\\\\nP\\{X=3\\} &= P(\\{(1,2), (2,1)\\}) = \\frac{2}{36} \\\\\nP\\{X=4\\} &= P(\\{(1,3), (2,2), (3,1)\\}) = \\frac{3}{36} \\\\\nP\\{X=5\\} &= P(\\{(1,4), (2,3), (3,2), (4,1)\\}) = \\frac{4}{36} \\\\\nP\\{X=6\\} &= P(\\{(1,5), (2,4), (3,3), (4,2), (5,1)\\}) = \\frac{5}{36} \\\\\nP\\{X=7\\} &= P(\\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}) = \\frac{6}{36} \\\\\nP\\{X=8\\} &= P(\\{(2,6), (3,5), (4,4), (5,3), (6,2)\\}) = \\frac{5}{36} \\\\\nP\\{X=9\\} &= P(\\{(3,6), (4,5), (5,4), (6,3)\\}) = \\frac{4}{36} \\\\\nP\\{X=10\\} &= P(\\{(4,6), (5,5), (6,4)\\}) = \\frac{3}{36} \\\\\nP\\{X=11\\} &= P(\\{(5,6), (6,5)\\}) = \\frac{2}{36} \\\\\nP\\{X=12\\} &= P(\\{(6,6)\\}) = \\frac{1}{36}\n\\end{align}\n\\tag{4.1}\\]\n\n\n\n\n\n\n\n例子 4.2 假设一个人购买了两个电子元器件，每个电子元器件或者有缺陷（用 d 表示）或者没有缺陷（用 a 表示）。则这两个电子元器件有四种可能的结果：(d, d)、(d, a)、(a, d)、(a, a)，假设这四种结果的概率分别为：0.09、0.21、0.21、0.49（其中 (d, d) 表示两个元器件都有缺陷，(d, a) 表示第一个元器件有缺陷、第二个元件没有缺陷，依此类推）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n随机变量 的累积分布函数也可简称为 分布函数（distribution function）。\n\n\n\n\n\n\n\n\n提示\n\n\n\n我们将使用 \\(X \\thicksim F\\) 来表示 \\(F\\) 是 随机变量 \\(X\\) 的分布函数。\n\n\n\n\n\n练习 4.1 假设 随机变量 \\(X\\) 的分布函数为：\n\\[\nF(x) = \\begin{cases}\n0, \\quad & x \\le 0 \\\\\n1-e^{-x^2}, \\quad & x \\gt 0\n\\end{cases}\n\\]\n计算 \\(P\\{X \\gt 1\\}\\)？\n\n\n答案 4.1. \\[\n\\begin{align}\nP\\{X \\gt 1\\} &= 1 - P\\{X \\le 1\\} \\\\\n&= 1 - F(1) \\\\\n&= e^{-1} \\\\\n&= 0.368 \\qquad \\blacksquare\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#随机变量的类型",
    "href": "chapter_4/4.html#随机变量的类型",
    "title": "4  随机变量和期望",
    "section": "4.2 随机变量的类型",
    "text": "4.2 随机变量的类型\n如前所述，取值为一个序列集的 随机变量 称为 离散随机变量。对于 离散随机变量 \\(X\\)，我们定义其 概率质量函数 \\(p(a)\\)（probability mass function）为：\n\\[\np(a) = P\\{X=a\\}\n\\tag{4.9}\\]\n对于 \\(a\\) 的可数个取值，其 概率质量函数 \\(p(a)\\) 为正数。也就是说，如果 \\(X\\) 的取值必须为 \\(x_1,x_2,...,x_n\\)，则 \\(p(x_i) \\gt 0\\)，\\(i=1,2,...\\)；对于其他的取值，\\(p(x)=0\\)。\n因为 \\(X\\) 必须为 \\(x_i\\) 中的某个值，所以 \\(\\sum_{i=1}^{\\infty}{p(x_i)}=1\\)。\n\n例子 4.3 随机变量 \\(X\\) = 1，2，3，如果已知：\\(p(1)=\\frac{1}{2}\\)，\\(p(2)=\\frac{1}{3}\\)，则 \\(p(3)=\\frac{1}{6}\\)。\\(p(x)\\) 的线图如 图 4.1。 \\(\\blacksquare\\)\n\n\n\n代码\nlibrary(ggplot2)\n\ndf &lt;- data.frame(\n    value = c(1, 2, 3),\n    p = c(1/2, 1/3, 1/6),\n    start = rep(0, 3)\n)\n\ndf$value &lt;- factor(df$value, levels = df$value, ordered = TRUE)\n\nggplot(df, aes(x = value, y = start, yend = p, color = value)) +  \n  geom_segment(size = 2) +                    # 绘制水平线表示每个“条形”  \n  geom_point(aes(y = p), size = 3) +          # 在每个“条形”的末端添加点  \n  theme_minimal() +  \n  labs(x = \"x\", y = \"p(x)\") +  \n  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +  \n  theme(legend.position = \"none\")           # 调整图例位置\n\n\n\n\n\n\n\n\n图 4.1: \\(p(x)\\) 的线图，例子 4.3\n\n\n\n\n\n可以使用 \\(p(x)\\) 来表示 随机变量 \\(X\\) 的累积分布函数 \\(F\\)：\n\\[\nF(a) = \\sum_{all \\ x \\le a}{p(x)}\n\\tag{4.10}\\]\n如果 \\(X\\) 是一个离散随机变量，其可能的取值是 \\(x_1,x_2,x_3,...\\)，其中 \\(x_1&lt;x_2&lt;x_3&lt;...\\)，那么 \\(X\\) 的分布函数 \\(F\\) 是一个阶跃函数（step function）。也就是说，\\(F\\) 的值在区间 \\([x_{i−1},x_i)\\) 是恒定的，然后在 \\(x_i\\) 处有大小为 \\(p(x_i)\\) 的跃变。\n例如，假设 \\(X\\) 的概率质量函数（如 例子 4.3）为：\\(p(1)=\\frac{1}{2}\\)，\\(p(2)=\\frac{1}{3}\\)，\\(p(3)=\\frac{1}{6}\\)。则 \\(X\\) 的累积分布函数 \\(F\\) 为：\n\\[\nF(a) = \\begin{cases}\n0, \\quad & a \\lt 1 \\\\\n\\frac{1}{2}, \\quad & 1 \\le a \\lt 2 \\\\\n\\frac{5}{6}, \\quad & 2 \\le a \\lt 3 \\\\\n1, \\quad & 3 \\le a\n\\end{cases}\n\\tag{4.11}\\]\n方程式 4.11 如 图 4.2 所示。\n\n\n代码\nlibrary(ggplot2)\n\ndf &lt;- data.frame(\n  value = c(1, 2, 3),\n  p = c(1/2, 1/3, 1/6)\n)\n\ndf$cpf &lt;- cumsum(df$p)\n\ndf1 &lt;- data.frame(\n  value = c(0, 1, 1, 2, 2, 3, 3, 4),\n  cpf = c(0, 0, df$cpf[1], df$cpf[1], df$cpf[2], df$cpf[2], df$cpf[3], df$cpf[3])\n)\n#df1$value &lt;- factor(df$value, levels = df$value, ordered = TRUE)\n\nggplot(df1, aes(x = value, y = cpf)) +  \n  geom_line() +\n  labs(x = \"x\", y = \"F(x)\") +  \n  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +  \n  theme(legend.position = \"none\")           # 调整图例位置\n\n\n\n\n\n\n\n\n图 4.2: \\(F(x)\\) 的折线图\n\n\n\n\n\n离散随机变量 的可能取值是一个序列集合，但是我们通常必须考虑那些取值是一个区间的 随机变量。假设 \\(X\\) 为一个取值是一个区间的 随机变量。如果存在一个定义域为所有实数 \\(x \\in (−\\infty, \\infty)\\) 的非负函数 \\(f(x)\\)，且对于任意实数集 \\(B\\)，\\(f(x)\\) 都满足：\n\\[\nP\\{X \\in B\\} = \\int_{B}{f(x)\\mathrm{d} x}\n\\tag{4.12}\\]\n则我们称 \\(X\\) 是一个 连续随机变量（continous random variable），而函数 \\(f(x)\\) 为 随机变量 \\(X\\) 的 概率密度函数（probability density function）。\n换句话说，方程式 4.12 指出，对集合 \\(B\\) 上的概率密度函数进行积分运算可以得到 \\(X\\) 在 \\(B\\) 中的概率。由于 \\(X\\) 必须为某个值，所以 \\(f(x)\\) 必须满足：\n\\[\n1 = P\\{X \\in (-\\infty, \\infty)\\} = \\int_{-\\infty}^{\\infty}{f(x)\\mathrm{d} x}\n\\tag{4.13}\\]\n概率密度函数 \\(f(x)\\) 可以用于回答所有关于 随机变量 \\(X\\) 的概率问题，例如，令 \\(B=[a,b]\\)，根据 方程式 4.12，我们有：\n\\[\nP\\{a \\le X \\le b\\}=\\int_{a}^{b}{f(x)\\mathrm{d} x}\n\\tag{4.14}\\]\n在 方程式 4.14 中，如果令 \\(a=b\\)，则：\n\\[\nP\\{X=a\\}=\\int_{a}^{a}{f(x)\\mathrm{d} x} = 0\n\\tag{4.15}\\]\n换句话说，对于 连续随机变量 而言，其取值为某个特殊值的概率为 0，如 图 4.3 所示。\n\n\n代码\nlibrary(ggplot2)\n\nx &lt;- seq(0, 5, 0.1)\ny &lt;- exp(-x)\ndf &lt;- data.frame(x=x, y=y)\n\nggplot(df, aes(x=x, y=y)) + \n  geom_line() + \n  geom_segment(x=1, y=exp(-1), xend=1, yend=0) + \n  geom_segment(x=3, y=exp(-3), xend=3, yend=0) +\n  geom_ribbon(data = subset(df, x &gt;= 1 & x &lt;= 3), aes(ymin = 0, ymax = y), fill = \"gray\") +\n  annotate(\"text\", x = 1, y = -0.02, label = \"a\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 3, y = -0.02, label = \"b\", hjust = 1, vjust = 0, size = 3) + \n  annotate(\"text\", x = 2.2, y = 0.05, label = \"P{a&lt;X&lt;b}\", hjust = 1, vjust = 0, size = 5)  \n\n\n\n\n\n\n\n\n图 4.3: 概率密度函数 \\(f(x)=\\begin{cases} e^{-x}, \\quad & x \\ge 0 \\\\ 0, \\quad & x \\lt 0 \\end{cases}\\)\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n连续随机变量的概率是其密度函数 \\(f(x)\\) 在某个区间上积分的结果，因此对于某个特殊的取值，其结果必然为 0。\n\n\n累积分布函数 \\(F(\\cdot)\\) 和概率密度函数 \\(f(\\cdot)\\) 之间的关系如下所示：\n\\[\n\\begin{align}\nF(a)&=P\\{X \\in (-\\infty,a]\\} = \\int_{-\\infty}^{a}{f(x)\\mathrm{d} x} \\\\\n两边&求微分得：\\\\\n\\frac{dF(a)}{da}&=f(a)\n\\end{align}\n\\tag{4.16}\\]\n也就是说，概率密度函数是累积分布函数的导数。根据 方程式 4.14，概率密度函数的更直观的解释如下：\n\\[\nP\\{a - \\frac{\\varepsilon}{2} \\le X \\le a + \\frac{\\varepsilon}{2}\\} = \\int_{a-\\frac{\\varepsilon}{2}}^{a+\\frac{\\varepsilon}{2}}{f(x)\\mathrm{d} x} \\approx \\varepsilon f(a)\n\\tag{4.17}\\]\n其中，\\(\\varepsilon\\) 是一个非常小的数。也就是说，\\(X\\) 的取值位于区间 \\([a - \\frac{\\varepsilon}{2},a + \\frac{\\varepsilon}{2}]\\) 内时的概率大约为 \\(\\varepsilon f(a)\\)。由此，我们可以看出，\\(f(a)\\) 是对随机变量 \\(X\\) 的取值接近 \\(a\\) 的可能性大小的一种度量。\n\n练习 4.2 假设 \\(X\\) 是一个连续随机变量，其概率密度函数为：\n\\[\nf(x)=\\begin{cases}\nC(4x - 2x^2), \\quad &0 \\lt x \\lt 2 \\\\\n0, \\quad &其它\n\\end{cases}\n\\]\n则：\n\n计算 \\(C\\) 的值？\n计算 \\(P\\{X \\gt 1\\}\\)？\n\n\n\n答案 4.2. 因为 \\(f(x)\\) 是一个概率密度函数，因此必有：\\(\\int_{-\\infty}^{\\infty}{f(x)\\mathrm{d} x}=1\\)。因此，有：\n\\[\n\\begin{align}\nC\\int_0^2{(4x-2x^2)\\mathrm{d} x} &=1 \\\\\nC\\bigg(2x^2-\\frac{2}{3}x^3\\bigg)\\Bigg|_{x=0}^{x=2} &= 1\n\\end{align}\n\\]\n所以，\\(C = \\frac{3}{8}\\)。所以，\\(P\\{X \\gt 1\\}=\\int_{1}^{\\infty}{f(x)\\mathrm{d} x}=\\frac{3}{8}\\int_1^2{(4x-2x^2)\\mathrm{d} x}=\\frac{1}{2}\\)。 \\(\\blacksquare\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#联合分布",
    "href": "chapter_4/4.html#联合分布",
    "title": "4  随机变量和期望",
    "section": "4.3 联合分布",
    "text": "4.3 联合分布\n对于一个给定的实验，我们不仅对单个 随机变量 的概率分布函数感兴趣；对两个或多个 随机变量 之间的关系，我们同样感兴趣。例如，在一项关于癌症可能原因的实验中，我们可能对每天平均吸烟数量与个体患癌症年龄之间的关系感兴趣。同样，工程师可能对钢板样品的抗剪强度和点焊直径之间的关系感兴趣。\n为了描述两个 随机变量 之间的关系，我们定义 \\(X\\) 和 \\(Y\\) 的联合累积概率分布函数（joint cumulative probability distribution function）：\n\\[\nF(x,y) = P\\{X \\le x,Y \\le y\\}\n\\tag{4.18}\\]\n至少在理论上，可以根据联合概率分布函数来计算任何关于 \\(X\\) 和 \\(Y\\) 的概率。例如，可以从 \\(X\\) 和 \\(Y\\) 的联合分布函数 \\(F\\) 中得到 \\(X\\) 的分布函数 \\(F_X\\)：\n\\[\n\\begin{align}\nF_X(x) &= P\\{X \\le x\\} \\\\\n&= P\\{X \\le x, Y \\le \\infty \\} \\\\\n&= F(x, \\infty)\n\\end{align}\n\\tag{4.19}\\]\n同理，\\(Y\\) 的累积分布函数为 \\(F_Y(y) = F(\\infty, y)\\)。\n如果 \\(X\\) 和 \\(Y\\) 都是 离散随机变量，且其可能的取值分别为：\\(x_1, x_2, ...\\) 和 \\(y_1, y_2, ...\\)，定义 \\(X\\) 和 \\(Y\\) 的联合概率质量函数（joint probability mass function）\\(p(x_i, y_j)\\) 为：\n\\[\np(x_i, y_j) = P\\{X = x_i, Y = y_j\\}\n\\tag{4.20}\\]\n由于 \\(Y\\) 必须取某个值 \\(y_j\\)，并且所有的 \\(y_j\\) 之间都是 互斥事件，因此 事件 \\(\\{X = x_i\\}\\) 可以写作 \\(\\{X = x_i, Y = Y_j\\}\\) 在所有 \\(j\\) 上的并集。即：\n\\[\n\\{X = x_i\\} = \\bigcup_{all\\ j}{\\{X = x_i, Y = y_j\\}}\n\\tag{4.21}\\]\n根据 公理3（章节 3.4），有：\n\\[\n\\begin{align}\nP\\{X = x_i\\} &= P\\bigg(\\bigcup_{all\\ j}{\\{X = x_i, Y = y_j\\}}\\bigg) \\\\\n&= \\sum_{all \\ j}{P\\{X = x_i, Y = y_j\\}} \\\\\n&= \\sum_{all \\ j}{p(x_i, y_j)}\n\\end{align}\n\\tag{4.22}\\]\n同理，我们可以得到 \\(P\\{Y = y_j\\}\\)：\n\\[\n\\begin{align}\nP\\{Y = y_i\\} &= \\sum_{all \\ i}{P\\{X = x_i, Y = y_j\\}} \\\\\n&= \\sum_{all \\ i}{p(x_i, y_j)}\n\\end{align}\n\\tag{4.23}\\]\n因此，随机变量 的联合概率质量函数总是可以决定单个 随机变量 的概率质量函数。然而，需要注意的是：反之，并不成立。即，即便知道 \\(P\\{X = x_i\\}\\) 和 \\(P\\{Y = y_j\\}\\) 的值也不能决定 \\(P\\{X = x_i, Y = y_j\\}\\) 的值。\n\n例子 4.4 假设共有 12 块电池，其中包含 3 块新电池、4 块用过的但还有电量的电池、5 块没有电量的电池。现在，我们从这 12 块电池中随机抽取 3 块。令 \\(X\\) 为抽取的电池中的新电池的数量，令 \\(Y\\) 为抽取的电池中用过但还有电量的电池的数量。则 \\(X\\) 和 \\(Y\\) 的联合概率质量函数 \\(p(i, j) = P\\{X = i, Y = j\\}\\) 为：\n\\[\np(i, j) = \\frac{\\left(\\begin{array}{cc}  3 \\\\ i  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ j  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 3 - i -j  \\end{array}\\right) }{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)}\n\\]\n从 12 块电池里随机抽取 3 块电池的抽取方式为 \\(\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)\\)。根据 章节 3.5.1 中的 计数基本原理，抽取的 3 块电池中恰好有 \\(i\\) 块新电池、\\(j\\) 块用过但还有电量的电池、\\(3 - i - j\\) 块没有电量的电池的抽取方式为 \\(\\left(\\begin{array}{cc}  3 \\\\ i  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ j  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 3 - i -j  \\end{array}\\right)\\)。因此：\n\\[\n\\begin{align}\np(0, 0) &= \\frac{\\left(\\begin{array}{cc}  5 \\\\ 3  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{10}{220} \\\\\np(0, 1) &= \\frac{\\left(\\begin{array}{cc}  4 \\\\ 1  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 2  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{40}{220} \\\\\np(0, 2) &= \\frac{\\left(\\begin{array}{cc}  4 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 1  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{30}{220} \\\\\np(0, 3) &= \\frac{\\left(\\begin{array}{cc}  4 \\\\ 3  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{4}{220} \\\\\np(1, 0) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 1  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 2  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{30}{220} \\\\\np(1, 1) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 1  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ 1  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 1  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{60}{220} \\\\\np(1, 2) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 1  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ 2  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{18}{220} \\\\\np(2, 0) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  5 \\\\ 1  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{15}{220} \\\\\np(2, 1) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 2  \\end{array}\\right) \\left(\\begin{array}{cc}  4 \\\\ 1  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{12}{220} \\\\\np(3, 0) &= \\frac{\\left(\\begin{array}{cc}  3 \\\\ 3  \\end{array}\\right)}{\\left(\\begin{array}{cc}  12 \\\\ 3  \\end{array}\\right)} = \\frac{1}{220}\n\\end{align}\n\\]\n可以通过 表格 4.1 的表格格式来更简单的表示如上的概率。\n\n\n\n表格 4.1: \\(P\\{X=i, Y=j\\}\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(j\\) = 0\n\\(j\\) = 1\n\\(j\\) = 2\n\\(j\\) = 3\n\\(P\\{X = i\\}\\)\n\n\n\n\n\\(i\\) = 0\n\\(\\frac{10}{220}\\)\n\\(\\frac{40}{220}\\)\n\\(\\frac{30}{220}\\)\n\\(\\frac{4}{220}\\)\n\\(\\frac{84}{220}\\)\n\n\n\\(i\\) = 1\n\\(\\frac{30}{220}\\)\n\\(\\frac{60}{220}\\)\n\\(\\frac{10}{220}\\)\n0\n\\(\\frac{108}{220}\\)\n\n\n\\(i\\) = 2\n\\(\\frac{15}{220}\\)\n\\(\\frac{12}{220}\\)\n0\n0\n\\(\\frac{27}{220}\\)\n\n\n\\(i\\) = 3\n\\(\\frac{1}{220}\\)\n0\n0\n0\n\\(\\frac{1}{220}\\)\n\n\n\\(P\\{Y = j\\}\\)\n\\(\\frac{56}{220}\\)\n\\(\\frac{112}{220}\\)\n\\(\\frac{48}{220}\\)\n\\(\\frac{4}{220}\\)\n\n\n\n\n\n\n\n读者应该注意，通过计算行的和所得到的 \\(X\\) 的概率质量函数和 方程式 4.22 的结果是一致的；同时，通过计算列的和所得到的 \\(Y\\) 的概率质量函数和 方程式 4.23 的结果也是一致的。因为 \\(X\\) 和 \\(Y\\) 的各自的概率质量函数出现在 表格 4.1 所示的联合概率分布表的边缘（margin），因此，我们又常常称 \\(X\\) 和 \\(Y\\) 的各自的概率质量函数为 边缘概率质量函数（marginal probability mass function）。应该注意的是，为了检查类似 表格 4.1 这样的表的正确性，我们可以对表中的最后一行（或最右一列）求和，并验证其结果是否为 1。（为什么最后一行或最右一列的和必须等于 1？） \\(\\blacksquare\\)\n\n\n例子 4.5 假设某个社区中，15% 的家庭没有孩子，20% 的家庭有 1 个孩子，35% 的家庭有 2 个孩子，30% 的家庭有 3 个孩子。又假设对于每个家庭而言，每个孩子是男孩或女孩的可能性相等并且独立。\n如果从这个社区中随机选择一个家庭，那么这个家庭中男孩的数量 \\(B\\) 和女孩的数量 \\(G\\) 具有 表格 4.2 所示的联合概率质量函数。\n\n\n\n表格 4.2: \\(P\\{B=i, G=j\\}\\)\n\n\n\n\n\n\n\\(j\\) = 0\n\\(j\\) = 1\n\\(j\\) = 2\n\\(j\\) = 3\n\\(P\\{B = i\\}\\)\n\n\n\n\n\\(i\\) = 0\n0.15\n0.10\n0.0875\n0.0375\n0.3750\n\n\n\\(i\\) = 1\n0.10\n0.175\n0.1125\n0\n0.3875\n\n\n\\(i\\) = 2\n0.0875\n0.1125\n0\n0\n0.2000\n\n\n\\(i\\) = 3\n0.0375\n0\n0\n0\n0.0375\n\n\n\\(P\\{G = j\\}\\)\n0.3750\n0.3875\n0.2000\n0.0375\n\n\n\n\n\n\n\n于是，我们可以得到如下的概率：\n\\[\n\\begin{align}\nP\\{B=0, G=0\\} &= P\\{没有孩子\\} = 0.20 \\cdot \\frac{1}{2} = 0.15 \\\\\nP\\{B=0, G=1\\} &= P\\{有 1 个孩子且为女孩\\} = 0.35 \\cdot (\\frac{1}{2})^2 = 0.1 \\\\\nP\\{B=0, G=3\\} &= P\\{有 3 个孩子且都为女孩\\} = = 0.30 \\cdot (\\frac{1}{2})^3 = 0.0375 \\\\\n\\end{align}\n\\]\n您可以验证 表格 4.2 的其余部分，通过 表格 4.2 我们可以知道，所选择的家庭至少有一个女孩的概率为 0.625（\\(1-P\\{B=i, G=0\\}\\)）。\\(\\blacksquare\\)\n\n\\(X\\) 和 \\(Y\\) 是两个连续 随机变量，对于 \\(x \\in (-\\infty, \\infty)\\) 和 \\(y \\in (-\\infty, \\infty)\\)，对于任何一个 \\(x\\) 和 \\(y\\) 构成的 数据对 集合 \\(C\\)（\\(C\\) 是一个二维平面中的集合），如果存在函数 \\(f(x,y)\\)，使得：\n\\[\nP\\{(X,Y) \\in C\\} = \\iint_{(x,y) \\in C}{f(x,y)\\mathrm{d} x \\mathrm{d} y}\n\\tag{4.24}\\]\n我们称 \\(X\\) 和 \\(Y\\) 是联合连续随机变量，称函数 \\(f(x,y)\\) 为 \\(X\\) 和 \\(Y\\) 的 联合概率密度函数（joint probability density function）。如果令 \\(A\\) 和 \\(B\\) 为两个实数集，并令 \\(C = \\{(x,y): x \\in A, y \\in B\\}\\)，则 方程式 4.24 可以写作：\n\\[\nP\\{X \\in A, Y \\in B\\} = \\int_{B} \\int_{A} {f(x,y)\\mathrm{d} x \\mathrm{d} y}\n\\tag{4.25}\\]\n因为：\n\\[\n\\begin{align}\nF(a,b) &= P\\{X \\in (-\\infty, a], Y \\in (-\\infty, b]\\} \\\\\n&= \\int_{-\\infty}^{b} \\int_{-\\infty}^{a} {f(x,y)\\mathrm{d} x \\mathrm{d} y}\n\\end{align}\n\\tag{4.26}\\]\n所以，对 方程式 4.26 两边微分得到：\n\\[\n\\frac{\\partial^{2}{F(a,b)}}{\\partial a \\ \\partial b} = f(a,b)\n\\tag{4.27}\\]\n也就是说，联合概率密度函数 \\(f(\\cdot)\\) 是联合概率分布函数 \\(F(\\cdot)\\) 的偏微分。根据 方程式 4.25，我们有：\n\\[\n\\begin{align}\nP\\{a \\lt X \\lt a + \\Delta a, b \\lt Y \\lt b + \\Delta b\\} &= \\int_{b}^{b + \\Delta b} \\int_{a}^{a + \\Delta a} {f(x,y)\\mathrm{d} x \\mathrm{d} y} \\\\\n&\\approx f(a,b) \\Delta a \\Delta b\n\\end{align}\n\\tag{4.28}\\]\n因为 \\(\\Delta a\\) 和 \\(\\Delta b\\) 都是非常小的数，并且 \\(f(x,y)\\) 在 \\((a,b)\\) 处是连续的。因此 \\(f(a,b)\\) 是对 \\((X,Y)\\) 靠近 \\((a,b)\\) 的可能性大小的一种度量。\n如果 \\(X\\) 和 \\(Y\\) 是联合连续随机变量，则 \\(X\\) 和 \\(Y\\) 各自都是连续随机变量，则 \\(X\\) 的概率密度函数为：\n\\[\n\\begin{align}\nP\\{X \\in A\\} &= P\\{X \\in A, Y \\in (-\\infty, \\infty)\\} \\\\\n&= \\int_{A} \\int_{-\\infty}^{\\infty} {f(x,y) \\mathrm{d} y\\mathrm{d} x} \\\\\n&= \\int_{A}{f_X{(x)\\mathrm{d} x}} \\\\\n其中\\ f_X{(x)} &= \\int_{-\\infty}^{\\infty}{f(x,y) \\mathrm{d} y}\n\\end{align}\n\\tag{4.29}\\]\n同理，\\(Y\\) 的概率密度函数为：\n\\[\n\\begin{align}\nP\\{Y \\in B\\} &= P\\{X \\in (-\\infty, \\infty), Y \\in B\\} \\\\\n&= \\int_{B} \\int_{-\\infty}^{\\infty} {f(x,y)\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{B}{f_Y{(y) \\mathrm{d} y}} \\\\\n其中\\ f_Y{(y)} &= \\int_{-\\infty}^{\\infty}{f(x,y)\\mathrm{d} x}\n\\end{align}\n\\tag{4.30}\\]\n\n练习 4.3 \\(X\\) 和 \\(Y\\) 的联合概率密度函数如下：\n\\[\nf(x,y) = \\begin{cases}\n2e^{-x}e^{-2y}, \\quad & 0 \\lt x \\lt \\infty, 0 \\lt y \\lt \\infty \\\\\n0, \\quad & otherwise\n\\end{cases}\n\\]\n计算：\n\n\\(P\\{X \\gt 1, Y \\lt 1\\}\\)\n\\(P\\{X \\lt Y\\}\\)\n\\(P\\{X \\lt a\\}\\)\n\n\n\n答案 4.3. \n\n\n\n\n\n\n\\(P\\{X \\gt 1, Y \\lt 1\\}\\)\n\n\n\n\\[\n\\begin{align}\nP\\{X \\gt 1, Y \\lt 1\\} &= \\int_{0}^{1} \\int_{1}^{\\infty} {2e^{-x}e^{-2y}\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{0}^{1}{2e^{-2y}(-e^{-x} \\big |_{1}^{\\infty})} \\mathrm{d} y \\\\\n&= e^{-1}\\int_{0}^{1}2e^{-2y} \\mathrm{d} y \\\\\n&= e^{-1}(1-e^{-2})\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\\(P\\{X \\lt Y\\}\\)\n\n\n\n\\[\n\\begin{align}\nP\\{X \\lt Y\\} &= \\iint_{(x,y):x \\lt y}{2e^{-x}e^{-2y}\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{0}^{\\infty} \\int_{0}^{y} {2e^{-x}e^{-2y}\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{0}^{\\infty}{2e^{-2y}(1-e^{-y}) \\mathrm{d} y} \\\\\n&= \\int_{0}^{\\infty}{2e^{-2y} \\mathrm{d} y} - \\int_{0}^{\\infty}{2e^{-3y} \\mathrm{d} y} \\\\\n&= 1-\\frac{2}{3} \\\\\n&= \\frac{1}{3}\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\\(P\\{X \\lt a\\}\\)\n\n\n\n\\[\n\\begin{align}\nP\\{X \\lt a\\} &= \\int_{0}^{a} \\int_{0}^{\\infty}{2e^{-2y}e^{-x} \\mathrm{d} y\\mathrm{d} x} \\\\\n&= \\int_{0}^{a}{e^{-x}\\mathrm{d} x} \\\\\n&= 1-e^{-a}\n\\end{align}\n\\]\n\n\n\\(\\blacksquare\\)\n\n\n4.3.1 独立随机变量\n对于任意的两个实数集 \\(A\\) 和 \\(B\\)，如果随机变量 \\(X\\) 和 \\(Y\\) 满足 方程式 4.31，我们称 \\(X\\) 和 \\(Y\\) 是相互独立的。\n\\[\nP\\{X \\in A, Y \\in B\\} = P\\{X \\in A\\}P\\{Y \\in B\\}\n\\tag{4.31}\\]\n换句话说，对于所有的 \\(A\\)、\\(B\\)，如果事件 \\(E_A={X \\in A}\\) 和 \\(E_B={Y \\in B}\\) 是相互独立的，那么 随机变量 \\(X\\) 和 \\(Y\\) 也是相互独立的。\n根据 章节 3.4 中的概率论 三大公理，对于所有的 \\(a\\)、\\(b\\)，方程式 4.31 满足：\n\\[\nP\\{X \\le a, Y \\le b\\} = P\\{X \\le a\\}P\\{Y \\le b\\}\n\\tag{4.32}\\]\n因此，就 \\(X\\) 和 \\(Y\\) 的联合分布函数 \\(F\\) 而言，如果 \\(F(a,b) = F_X(a)F_Y(b)\\)，则 \\(X\\) 和 \\(Y\\) 是独立的。\n当 \\(X\\) 和 \\(Y\\) 是离散随机变量时，方程式 4.31 等价于：\n\\[\np(x,y)=p_X{(x)}p_Y{(y)} \\quad for \\ all \\ x,y\n\\tag{4.33}\\]\n其中，\\(p_X\\) 和 \\(p_Y\\) 分别为 \\(X\\) 和 \\(Y\\) 的概率质量函数。\n如果 方程式 4.31 成立，那么我们令 \\(A={x}\\)，\\(B={y}\\)，于是我们能够得到 方程式 4.33。此外，如果 方程式 4.33 成立，那么对于任何集合 \\(X \\in A\\)、\\(Y \\in B\\)，都有：\n\\[\n\\begin{align}\nP\\{X \\in A, Y \\in B\\} &= \\sum_{y \\in B}\\sum_{x \\in A}{p(x,y)} \\\\\n&= \\sum_{y \\in B}\\sum_{x \\in A}{p_X{(x)}p_Y{(y)}} \\\\\n&= \\sum_{y \\in B}{p_Y{(y)}} \\sum_{x \\in A}{p_X{(x)}} \\\\\n&= P\\{Y \\in B\\}P\\{X \\in A\\} \\\\\n&= P\\{X \\in A\\}P\\{Y \\in B\\}\n\\end{align}\n\\]\n即，方程式 4.33 成立也意味着 方程式 4.31 成立。因此，方程式 4.31 和 方程式 4.33 是等价的。\n同理，当 \\(X\\) 和 \\(Y\\) 是连续随机变量时，方程式 4.31 等价于：对于所有的 \\(x\\)、\\(y\\)，都有 \\(f(x,y) = f_X(x)f_Y(y)\\)。如果一个随机变量 \\(X\\) 的取值不会改变另一个随机变量 \\(Y\\) 的分布，那么我们可以大致认为 \\(X\\) 和 \\(Y\\) 是独立的。不独立的随机变量称为 依赖随机变量。\n\n练习 4.4 假设 \\(X\\) 和 \\(Y\\) 是两个独立随机变量，其概率密度函数均为：\n\\[\nf(x)=\\begin{cases}\ne^{-x}, \\quad & x \\gt 0 \\\\\n0, \\quad & otherwise\n\\end{cases}\n\\]\n求 随机变量 \\(\\frac{X}{Y}\\) 的概率密度函数？\n\n\n答案 4.4. 首先，求 \\(\\frac{X}{Y}\\) 的概率分布函数 \\(F\\)：\n\\[\n\\begin{align}\n\\forall a & \\gt 0, \\\\\nF_{\\frac{X}{Y}}{(a)} &= P\\{\\frac{X}{Y} \\le a\\} \\\\\n&= \\iint_{\\frac{x}{y} \\le a}{f(x,y)\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\iint_{\\frac{x}{y} \\le a}{e^{-x}e^{-y}\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{0}^{\\infty} \\int_{0}^{ay} {e^{-x}e^{-y}\\mathrm{d} x \\mathrm{d} y} \\\\\n&= \\int_{0}^{\\infty} {(1-e^{-ay})e^{-y} \\mathrm{d} y} \\\\\n&= \\bigg(-e^{-y} + \\frac{e^{-(a+1)y}}{a+1}\\bigg) \\bigg | _{0}^{\\infty} \\\\\n&= 1 - \\frac{1}{a+1}\n\\end{align}\n\\]\n对 \\(F_{\\frac{X}{Y}}{(a)}\\) 求导得到 \\(f_{\\frac{X}{Y}(a)} = \\frac{1}{(1+a)^2}\\)。 \\(\\blacksquare\\)\n\n我们可以用定义 2 个 随机变量 的联合概率分布函数的方式来定义 \\(n\\) 个 随机变量的联合概率分布函数。对于 \\(n\\) 个 随机变量 \\(X_1,X_2,...,X_n\\)，其联合累积概率分布函数 \\(F(a_1,a_2,...,a_n)\\) 为：\n\\[\nF(a_1,a_2,...,a_n) = P\\{X_1 \\le a_1, X_2 \\le a_2,..., X_n \\le a_n\\}\n\\tag{4.34}\\]\n对于离散随机变量，则其联合概率质量函数 \\(p(x_1,x_2,...,x_n)\\) 为：\n\\[\np(x_1,x_2,...,x_n) = P\\{X_1=x_1, X_2=x_2,..., X_n=x_n\\}\n\\tag{4.35}\\]\n此外，对于 \\(n\\) 维空间中的集合 \\(C\\)，如果存在一个函数 \\(f(\\cdot)\\) 使得：\n\\[\nP\\{(X_1,X_2,...,X_n) \\in C\\} = \\idotsint_{(x_1,...,x_n) \\in C}{f(x_1,...,x_n)\\mathrm{d} x_1 \\cdots \\mathrm{d} x_n}\n\\tag{4.36}\\]\n我们称 \\(f(x_1,...,x_n)\\) 为这 \\(n\\) 个联合连续随机变量的联合概率密度函数。\n特殊的，对于任意的 \\(n\\) 个实数集 \\(A_1,A_2,...,A_n\\)：\n\\[\n\\begin{align}\nP\\{X_1 \\in A_1, X_2 \\in A_2, ..., X_n \\in A_n\\} &= \\\\\n\\int_{A_n} \\int_{A_{n-1}} \\cdots \\int_{A_1}{f(x_1,...,x_n)\\mathrm{d} x_1\\mathrm{d} x_2 \\cdots \\mathrm{d} x_n} &\n\\end{align}\n\\tag{4.37}\\]\n当然，也可以为两个之上的 随机变量 定义独立性。一般来的，对于 \\(n\\) 个 随机变量 \\(X_1,X_2,...,X_n\\)，如果对于所有实数集 \\(A_1,A_2,...,A_n\\) 都有：\n\\[\nP\\{X_1 \\in A_1, X_2 \\in A_2, ..., X_n \\in A_n\\} = \\Pi_{i=1}^{n}{P\\{X_i \\in A_i\\}}\n\\tag{4.38}\\]\n则我们称这 \\(n\\) 个随机变量时相互独立的。正如 方程式 4.31 和 方程式 4.33 所述，方程式 4.38 等价于 方程式 4.39：\n\\[\nP\\{X_1 \\le a_1, X_2 \\le a_2, ..., X_n \\le a_n\\} = \\Pi_{i=1}^{n}{P\\{X_i \\in a_i\\}}\n\\tag{4.39}\\]\n对于一个随机变量的无限集合 \\(S\\)，如果 \\(S\\) 的所有的子集中的 随机变量 均是独立的，我们说 \\(S\\) 中的所有随机变量之间是相互独立的。（定义 3.3 的一般形式）\n\n例子 4.6 假设某支股票的股价的连续每日变化是一个独立且同分布的随机变量，其概率质量函数为：\n\\[\nP\\{第 i 日变化\\} = \\begin{cases}\n-3, \\quad &概率为 0.05 \\\\\n-2, \\quad &概率为 0.10 \\\\\n-1, \\quad &概率为 0.20 \\\\\n0, \\quad &概率为 0.30 \\\\\n1, \\quad &概率为 0.20 \\\\\n2, \\quad &概率为 0.10 \\\\\n3, \\quad &概率为 0.05\n\\end{cases}\n\\]\n令 \\(X_i\\) 表示第 \\(i\\) 天的股价变化，那么，这只股票在未来的连续 3 天里，股价分别上涨 1%、2%、0% 的概率为：\n\\[\nP\\{X_1=1, X_2=2, X_3=0\\} = 0.20 \\cdot 0.10 \\cdot 0.30 = 0.006 \\quad \\blacksquare\n\\]\n\n\n\n4.3.2 条件分布\n对于两个 随机变量，通常可以利用其中一个变量在另一个变量的给定值的情况下的条件分布来确定这两个 随机变量 之间的关系。回顾一下，对于任意两个事件 \\(E\\) 和 \\(F\\)，只要 \\(P(F)&gt;0\\)，则在给定 \\(F\\) 条件下 \\(E\\) 的条件概率为：\n\\[\nP(E|F)=\\frac{P(EF)}{P(F)}\n\\]\n因此，如果 \\(X\\) 和 \\(Y\\) 是两个离散随机变量，那么在给定 \\(Y=y\\) 的条件下，\\(X\\) 的条件概率质量函数为：\n\\[\n\\begin{align}\np_{X|Y}(x|y) &= P\\{X=x | Y=y\\} \\\\\n&= \\frac{P\\{X=x, Y=y\\}}{P\\{Y=y\\}} \\\\\n&= \\frac{p(x,y)}{p_Y(y)}\n\\end{align}\n\\]\n其中，对于所有的 \\(y\\)，\\(p_Y(y) \\gt 0\\)。\n\n练习 4.5 在 例子 4.5 中，如果我们知道所选择的这个家庭有 1 个女孩，计算该家庭的小孩中男孩数量的条件概率质量函数。\n\n\n答案 4.5. 首先，根据 表格 4.2，\\(P\\{G=1\\}=0.3875\\)，因此，\n\\[\n\\begin{align}\nP\\{B=0 | G=1\\} &= \\frac{P\\{B=0, G=1\\}}{P\\{G=1\\}} = \\frac{0.10}{0.3875} = \\frac{8}{31} \\\\\nP\\{B=1 | G=1\\} &= \\frac{P\\{B=1, G=1\\}}{P\\{G=1\\}} = \\frac{0.175}{0.3875} = \\frac{14}{31} \\\\\nP\\{B=2 | G=1\\} &= \\frac{P\\{B=2, G=1\\}}{P\\{G=1\\}} = \\frac{0.1125}{0.3875} = \\frac{9}{31} \\\\\nP\\{B=3 | G=1\\} &= \\frac{P\\{B=3, G=1\\}}{P\\{G=1\\}} = 0 \\\\\n\\end{align}\n\\]\n因此，在有 1 个女孩的条件下，该家庭至少有 1 个男孩的概率为 \\(\\frac{23}{31}\\)。\\(\\blacksquare\\)\n\n\n练习 4.6 假设 随机变量 \\(X\\)、\\(Y\\) 的联合概率质量函数 \\(p(x,y)\\) 为：\n\\[\np(0,0)=0.4, \\quad p(0,1)=0.2, \\quad p(1,0)=0.1, \\quad p(1,1)=0.3\n\\]\n计算 \\(P\\{X|Y=1\\}\\)？\n\n\n答案 4.6. \\[\n\\begin{align}\n\\because\\ P\\{Y = 1\\} &= \\sum_{x}p(x,1) = p(0,1) + p(1,1) = 0.5 \\\\\n\\therefore\\ P\\{X=0|Y=1\\} &= \\frac{p(0,1)}{P\\{Y=1\\}} = \\frac{2}{5} \\\\\nP\\{X=1|Y=1\\} &= \\frac{p(1,1)}{P\\{Y=1\\}} = \\frac{3}{5} \\qquad \\blacksquare\n\\end{align}\n\\]\n\n如果 \\(X\\) 和 \\(Y\\) 的联合概率密度函数为 \\(f(x,y)\\)，则在 \\(Y=y\\) 的条件下，\\(X\\) 的条件概率密度函数为：\n\\[\nf_{X|Y}(x|y) = \\frac{f(x,y)}{f_Y{(y)}}, \\quad \\forall y: \\ f_Y(y) \\gt 0\n\\tag{4.40}\\]\n在 方程式 4.40 的左边乘以 \\(\\Delta x\\)，右边乘以 \\(\\frac{\\Delta x \\Delta y}{\\Delta y}\\) 得到：\n\\[\n\\begin{align}\nf_{X|Y}(x|y) \\Delta x &= \\frac{f(x,y) \\Delta x \\Delta y}{f_Y{(y)} \\Delta y} \\\\\n& \\approx \\frac{P\\{x \\le X \\le x + \\Delta x, y \\le Y \\le y + \\Delta y\\}}{P\\{y \\le Y \\le y + \\Delta y\\}} \\\\\n&= P\\{x \\le X \\le x + \\Delta x\\ | y \\le Y \\le y + \\Delta y\\}\n\\end{align}\n\\tag{4.41}\\]\n也就是说，对于非常小的 \\(\\Delta x\\) 和 \\(\\Delta y\\) ，\\(f_{X|Y}(x|y) \\Delta x\\) 表示在 \\(Y \\in [y, y + \\Delta y]\\) 的条件下，\\(X \\in [x, x + \\Delta x]\\) 的条件概率。\n我们可以使用条件概率密度函数来定义：在给定一个随机变量的值下，另一个随机变量的条件概率。也就是说，如果 \\(X\\) 和 \\(Y\\) 都是连续 随机变量，那么，对于任何集合 \\(A\\)，都有：\n\\[\nP\\{X \\in A, Y=y\\} = \\int_{A}f_{X|Y}(x|y)\\mathrm{d} x\n\\]\n\n练习 4.7 \\(X\\) 和 \\(Y\\) 的联合概率密度函数为：\n\\[\nf(x,y) = \\begin{cases}\n\\frac{12}{5}x(2-x-y), \\quad & 0 \\lt x \\lt 1, 0 \\lt y \\lt 1\\\\\n0, \\quad & otherwise\n\\end{cases}\n\\]\n计算 \\(Y=y: 0 \\lt y \\lt 1\\) 下，\\(X\\) 的条件密度函数 \\(f_{X|Y}(x|y)\\)。\n\n\n答案 4.7. 对于 \\(0 \\lt x \\lt 1\\)，\\(0 \\lt y \\lt 1\\)，我们有：\n\\[\n\\begin{align}\nf_{X|Y}(x|y) &= \\frac{f(x,y)}{f_Y(y)} \\\\\n&= \\frac{f(x,y)}{\\int_{-\\infty}^{\\infty}{f(x,y)\\mathrm{d} x}} \\\\\n&= \\frac{x(2-x-y)}{\\int_0^1{x(2-x-y)\\mathrm{d} x}} \\\\\n&= \\frac{x(2-x-y)}{\\frac{2}{3} - \\frac{y}{2}} \\\\\n&= \\frac{6x(2-x-y)}{4-3y} \\quad \\blacksquare\n\\end{align}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#期望",
    "href": "chapter_4/4.html#期望",
    "title": "4  随机变量和期望",
    "section": "4.4 期望",
    "text": "4.4 期望\n随机变量 的 期望（expectation）是概率论中最重要的概念之一。如果 \\(X\\) 是一个离散 随机变量，其可能的取值为 \\(x_1\\)，\\(x_2\\)，……那么 \\(X\\) 的 期望 或 期望值 \\(E[X]\\) 为：\n\\[\nE[X] = \\sum_{i}{x_iP\\{X = x_i\\}}\n\\tag{4.42}\\]\n换句话说，\\(X\\) 的 期望 是其可能取值的加权平均数，其中每个可能取值的权重为该值对应的概率。\n例如，如果 \\(X\\) 的概率质量函数为 \\(p(0)=p(1)=\\frac{1}{2}\\)，则 \\(E[X]\\) 只是 \\(X\\) 的两个可能取值（0、1）的平均数：\n\\[\nE[X] = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = \\frac{1}{2}\n\\]\n如果 \\(p(0)=\\frac{1}{3}\\)，\\(p(1)=\\frac{2}{3}\\)，则 \\(E[X]\\) 是其两个可能取值（0、1）的加权平均值，其中 1 的权重是 0 的 2 倍（因为 \\(p(1)=2p(0)\\)）：\n\\[\nE[X] = 0 \\cdot \\frac{1}{3} + 1 \\cdot \\frac{2}{3} = \\frac{2}{3}\n\\]\n我们也可以利用概率的频率解释（章节 3.1）来定义随机变量的 期望。概率的评率解释认为，如果独立的重复执行一个实验无数次，那么对于任何事件 \\(E\\)，\\(E\\) 发生的概率 \\(P(E)\\) 就是其发生的次数的占比。现在，考虑一个随机变量 \\(X\\)，它的取值为 \\(x_1,x_2,...,x_n\\)，其概率分别为 \\(p(x_1),p(x_2),...,p(x_n)\\)。把 \\(X\\) 想象成我们在一个 机会游戏（game of chance）中得到的奖金，也就是说，我们将赢得 \\(x_i\\) 单位奖金的概率为 \\(p(x_i)\\)。根据概率的频率解释，如果我们继续玩这个游戏，那么我们赢得 \\(x_i\\) 的次数占比将是 \\(p(x_i)\\)。因此，我们在 \\(n\\) 次比赛中的平均奖金将是：\n\\[\n\\sum_{i=1}^{n}{x_ip(x_i)} = E[X]\n\\tag{4.43}\\]\n为了更清楚地看到 方程式 4.43 所示的结论，假设我们玩 \\(N\\) 次游戏，其中 \\(N\\) 是一个非常大的数。在这些游戏中，我们将赢得 \\(x_i\\) 的次数大约为 \\(Np(x_i)\\)，因此我们在 \\(N\\) 次比赛中的总奖金将是：\n\\[\n\\sum_{i=1}^{n}{x_i \\cdot Np(x_i)}\n\\]\n所以，我们可以获得的平均奖金为：\n\\[\n\\sum_{i=1}^{n}{\\frac{x_i \\cdot Np(x_i)}{N}} = \\sum_{i=1}^{n}{x_ip(x_i)} = E[X]\n\\]\n\n练习 4.8 令 随机变量 \\(X\\) 为我们抛一个骰子所获得的点数，计算 \\(E[X]\\)。\n\n\n答案 4.8. \\[\n\\begin{align}\n\\because\\ & p(1)=p(2)=p(3)=p(4)=p(5)=p(6)=\\frac{1}{6} \\\\\n\\therefore\\ & E[X] = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} = \\frac{7}{2}\n\\end{align}\n\\]\n读者应该注意，在 练习 4.8 中，\\(X\\) 的期望值并不是 \\(X\\) 的可能取值（也就是说，抛一个骰子，我们不可能得到 的点数）。因此，即使我们称 \\(E[X]\\) 为 \\(X\\) 的期望，我们也不能应该把 \\(E[X]\\) 看作我们期望 \\(X\\) 具有的值，而应该看作在大量重复实验中 \\(X\\) 的平均值。也就是说，如果我们连续抛一个骰子，那么在抛了很多次之后，所得结果的平均点数将大约是 \\(\\frac{7}{2}\\)。（感兴趣的读者可以尝试一下这个实验。）\\(\\blacksquare\\)\n\n\n例子 4.7 如果一个事件 \\(A\\) 的 指示随机变量 为 \\(I\\)，如果\n\\[\nI = \\begin{cases}\n1, \\quad & 如果 A 发生\\\\\n0, \\quad & 如果 A 不发生\n\\end{cases}\n\\]\n则 \\(E[I] = 1 \\cdot P(A) + 0 \\cdot P(A^c) = P(A)\\)。因此，指示随机变量 的期望就是对应的事件发生的概率。\\(\\blacksquare\\)\n\n\n例子 4.8 熵（Entropy）。给定一个 随机变量 \\(X\\)，\\(X=x\\) 传递了多少信息（information）？让我们通过如下的方式来开始尝试量化 \\(X=x\\) 中所传递的信息：\\(X=x\\) 的信息量应该取决于 \\(X\\) 等于 \\(x\\) 的可能性。\\(X\\) 等于 \\(x\\) 的可能性越小，他所包含的信息就越多，这看起来是合理的。例如：如果 \\(X\\) 表示抛两个骰子的点数之和，则 \\(X = 12\\) 包含的信息量比 \\(X = 7\\) 包含的信息量要大（因为 \\(P\\{X=12\\}=\\frac{1}{36}\\)，而 \\(P\\{X=7\\}=\\frac{1}{6}\\)）。\n让我们用 \\(I(p)\\) 来表示一个概率为 \\(p\\) 的事件发生时的信息量。显然，\\(I(p)\\) 应该是 \\(p\\) 的非负递减函数。为了确定 \\(I(p)\\)，令 \\(X\\) 和 \\(Y\\) 是独立 随机变量，假设 \\(P\\{X=x\\}=p\\)、\\(P\\{Y=y\\}=q\\)。那么 \\(X=x\\)、\\(Y=y\\) 包含多少信息量？\n\n首先，\\(X=x\\) 中包含的信息量是 \\(I(p)\\)。\n此外，由于我们已经知道 \\(Y=y\\) 的概率并不受 \\(X=x\\) 的影响（因为 \\(X\\) 和 \\(Y\\) 是独立的），所以 \\(Y=y\\) 中包含的额外信息量应该等于 $I(q)。\n因此，\\(X=x\\)、\\(Y=y\\) 中的信息量为 \\(I(p)+I(q)\\)。\n另一方面，我们有 \\(P\\{X=x, Y=y\\}=P\\{X=x\\}P\\{Y=y\\}=pq\\)，这意味着 \\(X=x\\)、\\(Y=y\\) 中的信息量为 \\(I(pq)\\)。\n因此，看起来，\\(I\\) 应该满足：\\(I(pq) = I(p) + I(q)\\)。\n如果我们定义函数 \\(G\\) 为：\\(G(p)=I(2^{-p})\\)，于是有：\n\\[\n\\begin{align}\nG(p+q) &= I(2^{-(p+q)}) \\\\\n&= I(2^{-p} \\cdot 2^{-q}) \\\\\n&= I(2^{-p}) + I(2^{-q}) \\\\\n&= G(p) + G(q)\n\\end{align}\n\\]\n可以证明，满足上述关系的唯一的单调函数 \\(G\\) 是 \\(G(p) = cp\\)，其中 \\(c\\) 为常数。\n于是，我们有 \\(I(2^{-p}) = cp\\)，令 \\(q=2^{-p}\\)，则 \\(I(q) = -c \\log_2{q}\\)（其中，\\(c\\) 是一个大于 0 的常数）。我们经常令 \\(c=1\\)，并且说：用 位（bits） 来测量信息量。\n\n现在，考虑一个随机变量 \\(X\\)，它的取值为 \\(x_1,x_2,...,x_n\\)，其概率分别为 \\(p_1,p_2,...,p_n\\)。因为 \\(X=x\\) 的信息量为 \\(-\\log_2(p_i)\\)，因此，\\(X=x_i\\) 所包含的信息量的 期望 为：\n\\[\nH(X) = - \\sum_{i=1}^{n}{p_i \\log_2{p_i}}\n\\]\n在信息论中，\\(H(X)\\) 就是众所周知的 随机变量 \\(X\\) 的 熵（entropy）。 \\(\\blacksquare\\)\n\n我们还可以定义连续 随机变量 的 期望。假设 \\(X\\) 是一个概率密度函数为 \\(f\\) 的连续 随机变量。对于一个较小的数 \\(\\Delta x\\)，有：\n\\[\nf(x) \\Delta x \\approx P\\{x \\lt X \\lt x + \\Delta x\\}\n\\]\n如果 \\(x\\) 的权重等于 \\(X\\) 在 \\(x\\) 附近的概率，则 \\(X\\) 的所有可能值的加权平均数就是 \\(xf(x) \\Delta x\\) 在所有 \\(x\\) 上的积分。通常，定义 \\(X\\) 的期望为：\n\\[\nE[X] = \\int_{-\\infty}^{\\infty}{xf(x) \\mathrm{d} x}\n\\]\n\n例子 4.9 假设您在下午 5 点后的某个时间期待一条消息。根据经验，您知道在下午 5 点后的 \\(X\\) 个小时内会收到消息，并且 \\(X\\) 是一个 随机变量，其概率密度函数为：\n\\[\nf(x) = \\begin{cases}\n\\frac{1}{1.5}, \\quad & 0 \\lt x \\lt 1.5 \\\\\n0, \\quad & otherwise\n\\end{cases}\n\\]\n则下午 5 点之后可以收到消息的期望时间为：\\(E[X] = \\int_{0}^{1.5}{\\frac{1}{1.5} \\mathrm{d} x} = 0.75\\)。因此，您等待消息的时间平均为 45 分钟。 \\(\\blacksquare\\)\n\n\n\n\n\n\n\n备注\n\n\n\n\n期望 的概念类似于物理中的 重心 的概念。考虑一个离散 随机变量 \\(X\\)，其概率质量函数为 \\(p(x_i), i \\ge 1\\)。如果我们现在想象一个质量可以忽略不计的杆（weightless rod），在这根杆上的 \\(x_i\\) 处的质量为 \\(p(x_i)\\)（\\(i \\ge 1\\))（见 图 4.4）。那么这根杆处于平衡状态的点称为重心（the center fo gravity）。对于那些熟悉统计学基础的读者来说，很容易证明这根杆的重心位于 \\(E[X]\\) 1。\n\n\n\n\n\n\n图 4.4: 重心位于 0.9 处\n\n\n\n\\(E[X]\\) 的计量单位与 \\(X\\) 相同。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#sec-4_5",
    "href": "chapter_4/4.html#sec-4_5",
    "title": "4  随机变量和期望",
    "section": "4.5 期望的特征",
    "text": "4.5 期望的特征\n假设我们给定一个 随机变量 \\(X\\) 和其 概率分布。又假设，我们对计算 \\(X\\) 的 期望 不感兴趣，而对计算关于 \\(X\\) 的某个函数 \\(g(X)\\) 的 期望 感兴趣。如何计算 \\(g(X)\\) 的 期望？如下就是一种计算方法。由于 \\(g(X)\\) 本身是一个 随机变量，因此 \\(g(X)\\) 必存在一个概率分布，并且这个概率分布可以通过 \\(X\\) 的概率分布来计算。一旦我们得到了 \\(g(X)\\) 的分布，我们就可以通过期望的定义来计算 \\(E[g(X)]\\)。\n\n\n\n\n\n\n概率分布\n\n\n\n概率分布即——离散 随机变量 的 概率质量函数 或连续 随机变量 的 概率密度函数。\n\n\n\n练习 4.9 假设 \\(X\\) 的概率质量函数函数为：\\(p(0)=0.2\\)，\\(p(1)=0.5\\)，\\(p(2)=0.3\\)，计算 \\(E[X^2]\\)。\n\n\n答案 4.9. 令 \\(Y=X^2\\)，则 \\(Y\\) 是一个取值为 \\(0^2\\)，\\(1^2\\)，\\(2^2\\) 的 随机变量，并且其可能取值的概率分别为：\n\\(p_Y(0) = P\\{Y = 0^2\\} = 0.2\\)\n\\(p_Y(1) = P\\{Y = 1^2\\} = 0.5\\)\n\\(p_Y(2) = P\\{Y = 2^2\\} = 0.3\\)\n因此，\\(E[X^2] = E[Y] = 0 \\cdot 0.2 + 1 \\cdot 0.5 + 4 \\cdot 0.3 = 1.7\\)。\\(\\blacksquare\\)\n\n\n练习 4.10 定位并修复某工厂的电气故障所需的时间（以小时为单位）是一个 随机变量 \\(X\\)，其概率密度函数为：\n\\[\nf_X(x) = \\begin{cases}\n1, \\quad & 0 \\lt x \\lt 1 \\\\\n0, \\quad & otherwise\n\\end{cases}\n\\]\n如果对修复时间 \\(x\\) 的细分成本是 \\(x^3\\)，那么这种细分的期望成本是多少？\n\n\n答案 4.10. 令 \\(Y = X^3\\)，我们首先计算 \\(Y\\) 的分布函数：\n\\[\n\\begin{align}\nF_Y(a) &= P\\{Y \\le a\\} \\\\\n&= P\\{X^3 \\le a\\} \\\\\n&= P\\{X \\le a^{\\frac{1}{3}}\\} \\\\\n&= \\int_{0}^{a^{\\frac{1}{3}}}{1  \\mathrm{d} x} \\\\\n&= a^{\\frac{1}{3}} \\\\\n其中，& 0 \\le a \\le 1\n\\end{align}\n\\]\n对 \\(F_Y(a)\\) 求导得到概率密度函数 \\(f_Y(a)=\\frac{1}{3}a^{-\\frac{2}{3}},\\ 0 \\le a \\le 1\\)。因此：\n\\[\n\\begin{align}\nE[X^3] &= E[Y] = \\int_{-\\infty}^{\\infty}{a \\cdot f_Y(a) da} \\\\\n&= \\int_{0}^{1}{a \\cdot a^{-\\frac{2}{3}} da} \\\\\n&= \\frac{1}{3} \\int_{0}^{1}{a^{\\frac{1}{3}}da} \\\\\n&= (\\frac{1}{3} \\cdot \\frac{3}{4} \\cdot a^{\\frac{4}{3}}) \\big |_{0}^{1} \\\\\n&= \\frac{1}{4} \\quad \\blacksquare\n\\end{align}\n\\]\n\n虽然上述过程允许我们可以在理论上利用 \\(X\\) 的分布来计算 \\(X\\) 的任何函数的 期望，但我们还有一种更简单的方法。例如，假设我们想计算 \\(g(X)\\) 的 期望。当 \\(X=x\\) 时，\\(g(X)\\) 的取值为 $g(x)，因此 \\(E[g(X)]\\) 应该是 \\(g(X)\\) 的加权平均数，其中 \\(g(x)\\) 的权重就是 \\(X=x\\) 的概率（或概率密度）。事实上，我们可以证明上述过程是正确的，因此我们有以下的命题。\n\n命题 4.1 一个 随机变量 的函数的 期望：\n\n如果一个离散 随机变量 \\(X\\) 的概率质量函数为 \\(p(x)\\)，则对于任一函数 \\(g\\)，\\(E[g(X)] = \\sum_{x}{g(x)p(x)}\\)。\n如果一个连续 随机变量 \\(X\\) 的概率密度函数为 \\(f(x)\\)，则对于任一函数 \\(g\\)，\\(E[g(X)] = \\int_{-\\infty}^{\\infty}{g(x)f(x) \\mathrm{d} x}\\)。\n\n\n\n例子 4.10 利用 命题 4.1 来计算 练习 4.9 有：\n\\(E[X^2] = 0^2 \\cdot 0.2 + 1^2 \\cdot 0.5 + 2^2 \\cdot 0.3 = 1.7\\)。\\(\\blacksquare\\)\n\n\n例子 4.11 利用 命题 4.1 来计算 练习 4.10 有：\n\\(E[X^3] = \\int_{0}^{1}{x^3} \\mathrm{d} x = \\frac{1}{4}\\)。 \\(\\blacksquare\\)\n\n根据 命题 4.1，我们有 推论 4.1。\n\n推论 4.1 如果 \\(a\\) 和 \\(b\\) 是常数，则 \\(E[aX + b] = aE[X] + b\\)。\n\n\n论证. \n\n对于离散随机变量： \\[\n\\begin{align}\nE[aX + b] &= \\sum_{x}{(ax + b)p(x)} \\\\\n&= a\\sum_{x}{xp(x)} + b\\sum_{x}{p(x)} \\\\\n&= aE[X] + b\n\\end{align}\n\\]\n对于连续随机变量： \\[\n\\begin{align}\nE[aX + b] &= \\int_{-\\infty}^{\\infty}{(ax + b)f(x) \\mathrm{d} x} \\\\\n&= a\\int_{-\\infty}^{\\infty}{xf(x) \\mathrm{d} x} + b\\int_{-\\infty}^{\\infty}{f(x) \\mathrm{d} x} \\\\\n&= aE[X] + b \\quad \\blacksquare\n\\end{align}\n\\]\n\n\n如果令 \\(a=0\\)，则根据 推论 4.1 有：\\(E[b] = b\\)。也就是说，常量的 期望 就是它本身。（这符合你的直觉吗？）另外，如果我们令 \\(b=0\\)，那么我们得到 \\(E[aX] = aE[X]\\)。\n换句话说，常数乘以 随机变量 的 期望 就是该常数乘以这个 随机变量 的期望。随机变量 \\(X\\) 的 期望 \\(E[X]\\) 也称为 \\(X\\) 的平均值或一阶矩（the first moment）。当 \\(n \\ge 1\\) 时，\\(E[X^n]\\) 称为 \\(X\\) 的 \\(n\\)-阶矩。根据 命题 4.1，我们有：\n\\[\nE[X^n] = \\begin{cases}\n\\sum_{x}{x^np(x)}, \\quad & X 为离散随机变量\\\\\n& \\\\\n& \\\\\n\\int_{-\\infty}^{\\infty}{x^nf(x) \\mathrm{d} x}, \\quad & X 为连续随机变量\n\\end{cases}\n\\]\n\n4.5.1 随机变量和的期望\n对于 命题 4.1 而言，如果有两个 随机变量 \\(X\\)、\\(Y\\)，并且 \\(g\\) 为关于 \\(X\\)、\\(Y\\) 的函数，那么有：\n\\[\nE[g(X,Y)] = \\begin{cases}\n\\sum_{y} \\sum_{x} g(x,y)p(x,y), \\quad & 离散随机变量\\\\\n& \\\\\n& \\\\\n\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}g(x,y)f(x,y) \\mathrm{d} x \\mathrm{d} y, \\quad & 连续随机变量\n\\end{cases}\n\\]\n例如，如果 \\(g(X,Y)=X+Y\\) 且 \\(X\\)、\\(Y\\) 为连续 随机变量，则：\n\\[\n\\begin{align}\nE[X+Y] &= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x+y)f(x,y) \\mathrm{d} x \\mathrm{d} y \\\\\n&= \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}xf(x,y) \\mathrm{d} x \\mathrm{d} y + \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}yf(x,y) \\mathrm{d} x \\mathrm{d} y \\\\\n&= E[X] + E[Y]\n\\end{align}\n\\]\n类似的，对于离散随机变量而言，也有：\n\\[\nE[X+Y]=E[X] + E[Y]\n\\tag{4.44}\\]\n重复应用 方程式 4.44，我们可以证明：任意数量的 随机变量 之和的 期望 等于它们各自 期望 的和。例如，\n\\[\n\\begin{align}\nE[X+Y+Z] &= E[(X+Y)+Z] \\\\\n&= E[X+Y] + E[Z]  \\\\\n&= E[X] + E[Y] + E[Z]  \n\\end{align}\n\\]\n更一般的，对于任意的 \\(n\\)，\n\\[\nE[X_1 + X_2 + ... + X_n] = E[X_1] + E[X_2] + ... + E[X_n]\n\\tag{4.45}\\]\n方程式 4.45 是一个非常有用的公式，接下来，我们将通过一系列的例子来说明其作用。\n\n练习 4.11 抛两个骰子，计算两个骰子的和的期望值。\n\n\n答案 4.11. 如果令 \\(X\\) 是两个骰子的和，则\n\\(E[X]=\\sum_{i=2}^{12}{iP\\{X=i\\}}\\)\n我们令 \\(X_1\\)、\\(X_2\\) 分别表示这两个骰子的点数，则有 \\(X = X_1 + X_2\\)，于是有：\n\\(E[X] = E[X_1 + X_2] = E[X_1] + E[X_2]\\)，根据 方程式 4.45 有 \\(E[X] = 7\\)。\\(\\blacksquare\\)\n\n\n练习 4.12 一家建筑公司最近投标了三个项目，这三个项目可以获得的利润分别为 1 万美元、2 万美元、4 万美元。对这三个项目，如果该公司中标的概率分别为 0.2、0.8、0.3，那么该公司的预期总利润是多少？\n\n\n答案 4.12. 令 \\(X_i\\) 表示投标的第 \\(i\\) 个项目的利润，其中 \\(i=1,2,3\\)。令 \\(X\\) 表示总利润，则 \\(X = X_1 + X_2 + X_3\\)。所以，\n\\(E[X] = E[X_1 + X_2 + X_3] = E[X_1] + E[X_2] + E[X_3] = 3 万美元\\)。\\(\\blacksquare\\)\n\n\n练习 4.13 秘书打印出了 \\(N\\) 封信件以及信件对应的信封。当信封掉在地板上时，他们会混在一起。如果这 \\(N\\) 封信件以完全随机的方式放在已经混淆的信封里（每封信件放在任何一个信封的概率相同），则放到正确的信封中的信件数量的期望值是多少？\n\n\n答案 4.13. 令 \\(X\\) 表示放到正确的信封中的信件数量，则：\n\\(X = X_1 + X_2 + ... + X_N\\)，其中 \\(X_i = \\begin{cases} 1, \\quad & 第 i 封信放在了第 i 个信封中\\\\ 0, \\quad & 其他 \\end{cases}\\)。\n由于第 \\(i\\) 封信放入 \\(N\\) 个信封中的可能性是相同的，因此，\\(P\\{X_i=1\\}=\\frac{1}{N}\\)。\n所以有：\\(E[X_i]=1 \\cdot P\\{X_i = 1\\} + 0 \\cdot P\\{X_i = 0\\} = \\frac{1}{N}\\)，根据 方程式 4.45 有：\n\\(E[X] = E[X_1] + ... + E[X_N] = \\frac{1}{N} N =1\\)。\n因此，不管有多少封信，平均来说，只有一封信会放在正确的信封里。\\(\\blacksquare\\)\n\n\n练习 4.14 假设有 20 种不同类型的优惠券，并且每次获取优惠券时得到每一种优惠券的可能性都是相等的。如果现在获得了 10 张优惠券，计算其中包含的优惠券种类的预期数量。\n\n\n答案 4.14. 令 \\(X\\) 表示这 10 张优惠券中包含的优惠券类型的数量，则：\n\\(X = X_1 + ... + X_20\\)，其中 \\(X_i = \\begin{cases} 1, \\quad & 至少有 1 张第 i 种优惠券\\\\ 0, \\quad & 其他 \\end{cases}\\)。\n所以有：\n\\[\n\\begin{align}\nE[X_i] &= P\\{X_i = 1\\} \\\\\n&= P\\{在 10 张优惠券中至少有 1 张第 i 种优惠券\\} \\\\\n&= 1 - P\\{在 10 张优惠券中不存在第 i 种优惠券\\} \\\\\n&= 1 - \\bigg(\\frac{19}{20}\\bigg)^{10}\n\\end{align}\n\\]\n所以 \\(E[X] = E[X_1] + ... + E[X_20] = 20 \\cdot \\Bigg(1 - \\big(\\frac{19}{20}\\big)^{10}\\Bigg) = 8.025\\)。\\(\\blacksquare\\)\n\n当我们必须预测一个 随机变量 的值时，均值（mean）的一个重要属性就显现出来了。也就是说，假设要预测一个 随机变量 \\(X\\) 的值，如果我们预测 \\(X\\) 将等于 \\(c\\)，那么预测“误差”（或者称为：残差）的平方将是 \\((X−c)^2\\)。接下来，我们将证明：当 \\(X\\) 的预测值等于它的均值 \\(\\mu\\) 时，均方误差的值是最小的。\n对于任何常数 \\(c\\) 有：\n\\[\n\\begin{align}\nE[(X-c)^2] &= E[(X - \\mu + \\mu - c)^2] \\\\\n&= E[(X - \\mu)^2 + 2(X - \\mu)(\\mu - c) + (\\mu -c)^2] \\\\\n&= E[(X - \\mu)^2] + 2(\\mu - c)E[(X - \\mu)] + (\\mu -c)^2 \\\\\n&= E[(X - \\mu)^2] + (\\mu -c)^2, \\qquad \\because E[X - \\mu] = E[X] - \\mu = 0 \\\\\n&\\ge E[(X - \\mu)^2]\n\\end{align}\n\\]\n因此，当 随机变量 的平方误差的期望最小时，可以得到 随机变量 的最佳预测器——即其平均值。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#方差",
    "href": "chapter_4/4.html#方差",
    "title": "4  随机变量和期望",
    "section": "4.6 方差",
    "text": "4.6 方差\n给定一个 随机变量 \\(X\\) 及其概率分布函数，如果我们能够定义某些合适的度量并用来总结质量函数的基本特征，那将是非常有用的。期望 \\(E[X]\\) 就是其中的一个度量。虽然 \\(E[X]\\) 生成了 \\(X\\) 的可能值的加权平均数，但 \\(E[X]\\) 却没有告诉我们 \\(X\\) 的这些可能值的变化。例如，当 随机变量 \\(W\\)、\\(Y\\)、\\(Z\\) 的概率质量函数分别为：\n\\(W=0 \\quad 概率为 1\\)\n\\(Y=\\begin{cases} -1, \\quad & 概率为 \\frac{1}{2}\\\\ 1, \\quad & 概率为 \\frac{1}{2} \\end{cases}\\)\n\\(Y=\\begin{cases} -100, \\quad & 概率为 \\frac{1}{2}\\\\ 100, \\quad & 概率为 \\frac{1}{2} \\end{cases}\\)\n虽然这三个 随机变量 的期望都是 0，但是 \\(Y\\) 的变化幅度比 \\(W\\) 要大，同时 \\(Z\\) 的变化幅度比 \\(Y\\) 也要大。\n因为我们期望 \\(X\\) 在其平均值 \\(E[X]\\) 附近取值，所以可以利用 \\(X\\) 的实际取值与 \\(E[X]\\) 之间的距离来测量 \\(X\\) 的变化。可以同过量化 \\(E[|X − \\mu|]\\) 来计算 \\(X\\) 的实际取值与 \\(E[X]\\) 之间的距离，其中 \\(\\mu = E[X]\\)，\\(|X − \\mu|\\) 代表 \\(X - \\mu\\) 的绝对值。然而，事实证明，在数学上处理 \\(E[|X − \\mu|]\\) 极其麻烦。因此，我们通常会用一个更容易处理的数据——即 \\(X\\) 与其平均值之差的平方的期望。\n\n定义 4.1 如果 \\(X\\) 是一个均值为 \\(\\mu\\) 的 随机变量，则 \\(X\\) 的 方差（variance）\\(\\textup{Var}(X)\\) 为：\\(\\textup{Var}(X) = E[(X - \\mu)^2]\\)。\n\n于是，我们有如下的推导：\n\\[\n\\begin{align}\n\\textup{Var}(X) &= E[(X - \\mu)^2] \\\\\n&= E[X^2 - 2 \\mu X + \\mu ^2] \\\\\n&= E[X^2] - 2 \\mu E[X] + \\mu ^2 \\\\\n&= E[X^2] - (E[X])^2 \\quad \\because E[X] = \\mu \\\\\n\\end{align}\n\\]\n所以有：\n\\[\n\\textup{Var}(X) = E[X^2] - (E[X])^2\n\\tag{4.46}\\]\n换句话说，\\(X\\) 的方差等于 \\(X\\) 的平方的期望减去 \\(X\\) 的期望的平方。实际上，通常，方程式 4.46 是计算 \\(\\textup{Var}(X)\\) 的最简单的方法。\n\n练习 4.15 令 \\(X\\) 为抛一个骰子的点数，计算 \\(\\textup{Var}(X)\\)。\n\n\n答案 4.15. 因为 \\(P\\{X=i\\}=\\frac{1}{6}\\)，\\(i=1,2,...,6\\)，因此：\n\\(E[X^2] = \\sum_{i=1}^{6}{i^2 \\cdot P\\{X=i\\}} = \\frac{91}{6}\\)。\n在 练习 4.8 中，我们知道 \\(E[X]=\\frac{7}{2}\\)，根据 方程式 4.46：\n\\(\\textup{Var}(X)=E[X^2] - (E[X])^2 = \\frac{91}{6} - (\\frac{7}{2})^2 = \\frac{35}{12}\\)。\\(\\blacksquare\\)\n\n\n例子 4.12 指示随机变量的方差，对于事件 \\(A\\)，指示随机变量 \\(I\\) 为：\n\\(I = \\begin{cases} 1, \\quad & 如果 A 发生\\\\ 0, \\quad & 如果 A 不发生 \\end{cases}\\)\n根据 例子 4.7 有，\\(E[I] = P(A)\\)，所以有： \\[\n\\begin{align}\n\\textup{Var}(I) &= E[I^2] - (E(I))^2 \\\\\n&= E[I] - (E[I])^2 \\quad \\because I^2=I \\\\\n&= E[I](1-E[I]) \\\\\n&= P(A)(1-P(A)) \\qquad \\blacksquare\n\\end{align}\n\\]\n\n因为 \\((X - \\mu)^2 \\ge 0\\)，因此，\\(\\textup{Var}(X) = E[(X - \\mu)^2] \\ge 0\\)，根据 方程式 4.46 有：\n\\[\nE[X^2] \\ge \\mu^2\n\\tag{4.47}\\]\n也就是说，一个 随机变量 的平方的 期望 至少与其 期望 的平方一样大。\n\n例子 4.13 友谊悖论（friendship paradox）表明：平均而言，你的朋友的朋友数量比你的朋友数量要更多。更正式地，假设某个人群中有 \\(n\\) 个人，标记为 \\(1,2,...,n\\)，这些人中的某些人之间是朋友。这个 朋友网络 （friendship network）可以用 图（graphic）来表示：用顶点表示每个人，然后用顶点与顶点之间的连线表示这些人是朋友。例如，如 图 4.5 所示，该社区中有 4 个人，第 1 个人和第 2 个人是朋友，第 1 个人和第 3 个人是朋友，第 1 个人和第 4 个人是朋友，第 2 个人和第 4 个人是朋友。\n\n\n代码\nlibrary(igraph)\n \nvertices &lt;- c(1, 2, 3, 4)  \nedges &lt;- cbind(c(1, 1, 1, 2), c(3, 2, 4, 4))  \ng &lt;- graph_from_edgelist(edges, directed = FALSE)  \nV(g)$label &lt;- vertices\n\nplot(g, vertex.label.cex = 1.5)\n\n\n\n\n\n\n\n\n图 4.5: 一个朋友网络图\n\n\n\n\n\n令 \\(f(i)\\) 表示第 \\(i\\) 个人的朋友数，令 \\(f=\\sum_{i=1}^{n}{f(i)}\\)。在 图 4.5 中，\\(f(1)=3\\)，\\(f(2)=2\\)，\\(f(3)=1\\)，\\(f(4)=2\\)，\\(f = 8\\)。\n我们随机选择一个人，并用 \\(X\\) 表示，\\(X\\) 可以是 \\(1,2,...,n\\) 中的任何一个，并且选取到的概率是一致的。也就是说，\n\\(P(X=i)=\\frac{1}{n}\\)\n根据 命题 4.1，\\(X\\) 的朋友数量的期望 \\(E[f(X)]\\) 为：\n\\(E[f(X)] = \\sum_{i=1}^{n}{f(i)P(X=i)}=\\sum_{i=1}^{n}{\\frac{f(i)}{n}} = \\frac{f}{n}\\)\n假设这 \\(n\\) 个人中的每个人都将他所有朋友的名字分别写在了一张单独的纸上（一个名字一张纸）。因此，一个有 \\(k\\) 个朋友的人将使用 \\(k\\) 张纸。因为第 \\(i\\) 个人有 \\(f(i)\\) 个朋友，因此总共会有 \\(\\sum_{i=1}^{n{f(i)}}\\) 张纸来记录名字。\n现在随机选择一张纸，令 \\(Y\\) 表示纸上的名字，并计算所选纸上的人的朋友数量的期望 \\(E[f(Y)]\\)。\n\n首先，因为第 \\(i\\) 个人有 \\(f(i)\\) 个朋友， 所以有 \\(f(i)\\) 张纸上的名字写的是 \\(i\\)，因此，所选择的纸上的名字为 \\(i\\) 的概率为 \\(\\frac{f(i)}{f}\\)，即：\n\\(P(Y=i)=\\frac{f(i)}{f}, i = 1,...,n\\)\n于是，\\(E[f(Y)] = \\sum_{i=1}^{n}{f(i)P(Y=i)} = \\frac{\\sum_{i=1}^{n}{f^2(i)}}{f}\\)。\n因为 \\(P(X=i)=\\frac{1}{n}\\)，\\(E[f(X)] = \\frac{f}{n}\\)，所以 \\(f = \\frac{E[f(x)]}{P(X=i)}\\)，所以有：\n\\[\n\\begin{align}\nE[f(Y)] &= \\frac{\\sum_{i=1}^{n}{f^2(i)}}{f} \\\\\n&= \\frac{\\sum_{i=1}^{n}{f^2(i)P(X=i)}}{E[f(X)]} \\\\\n&= \\frac{E[f^2(X)]}{E[f(X)]} \\\\\n&\\ge E[f(X)], \\ \\because E[X^2] \\ge \\mu^2\n\\end{align}\n\\]\n\n因此，\\(E[f(X)] \\le E[f(Y)]\\)，这表明随机选择的某个人的平均朋友数量小于或等于其朋友的平均朋友数量。\n\n\n\n\n\n\n备注\n\n\n\n从直觉上讲，友谊悖论的原因在于：\n\n选择 \\(X\\) 的概率是相同的（\\(X\\) 为 \\(n\\) 个人中的任何一个的概率是相同）。\n选择 \\(Y\\) 的概率与其朋友数量成正比。\n所以，一个人拥有的朋友越多，这个人就越有可能是 \\(Y\\)。因此，\\(Y\\) 偏向于拥有大量朋友的那个人。\n因此，\\(Y\\) 拥有的平均朋友数量大于 \\(X\\) 拥有的平均朋友数量也就不足为奇了。\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n“友谊悖论”（friendship paradox）这一现象由社会学家斯科特·费尔德（Scott L. Feld）于1991年发现，其原因在于，那些在社交网络中连接较为广泛的人（即拥有较多朋友的人）更容易被其他人选为朋友，从而使得在统计上呈现出这样看似矛盾的结果。\n\n\n\\(\\blacksquare\\)\n\n对于任意的常数 \\(a\\)、\\(b\\)，有：\n\\[\n\\textup{Var}(aX + b) = a^2 \\textup{Var}(X)\n\\tag{4.48}\\]\n\n论证. 令 \\(\\mu = E[X]\\)，根据 推论 4.1 有 \\(E[aX + b] = a \\mu + b\\)，根据方差的定义 定义 4.1 有：\n\\[\n\\begin{align}\n\\textup{Var}(aX + b) &= E[(aX + b - E[aX + b])^2] \\\\\n&= E[(aX + b - a \\mu - b)^2] \\\\\n&= E[(aX - a \\mu)^2] \\\\\n&= E[a^2(X - \\mu)^2] \\\\\n&= a^2E[(X - \\mu)^2] \\\\\n&= a^2\\textup{Var}(X)\n\\end{align}\n\\]\n\n方程式 4.48 中，对于特定的 \\(a\\) 和 \\(b\\) 可以导出其他的推论。例如，如果 \\(a=0\\)，则有：\n\\(\\textup{Var}(b) = 0\\)\n即：常数的方差为 0（这符合直觉吗？）。类似的，令 \\(a = 1\\)，则有：\n\\(\\textup{Var}(X + b) = \\textup{Var}(X)\\)\n也就是说，随机变量 加一个常数的方差等于该 随机变量 的方差。最后，令 \\(b=0\\)，则有：\n\\(\\textup{Var}(aX) = a^2\\textup{Var}(X)\\)\n\\(\\sqrt{\\textup{Var}(X)}\\) 称为 \\(X\\) 的标准差（standard deviation）。随机变量 的标准差和均值具有相同的单位。\n\n\n\n\n\n\n备注\n\n\n\n与 均值 是质量分布的 重心 的概念类似，在力学中，方差 代表 惯性矩（the moment of inertia）。\n\n\n\n\n\n\n\n\n惯性矩\n\n\n\n在力学中，惯性矩（又称转动惯量）是一个用于描述物体绕轴转动时惯性大小的物理量。\n具体来说，它衡量了物体对于绕某一特定轴转动的抵抗能力。惯性矩越大，物体绕该轴转动就越困难，也就越不容易改变其转动状态；反之，惯性矩越小，物体就相对更容易改变其转动状态。\n其数学定义通常是对于质量分布为 \\(m_i\\)、距离转动轴为 \\(r_i\\) 的多个质点组成的物体，惯性矩等于各质点质量与该质点到转动轴距离平方的乘积之和，即 \\(I=\\sum m_ir_i^2\\)。\n例如，对于一个均匀圆盘，其绕中心轴的惯性矩与圆盘的质量和半径的平方有关；对于一个细长的直杆，绕垂直于杆且通过一端的轴转动时，其惯性矩也有特定的表达式。惯性矩在研究物体的转动运动、机械设计等方面都有着重要的应用。\n方差和惯性矩有一定的相似性，但不能简单地说方差就是惯性矩。方差主要是用来描述一组数据离散程度的统计量。它反映了数据相对于均值的偏离程度。而惯性矩是在力学中用于衡量物体绕轴转动时惯性大小的物理量。\n从某种意义上来说，它们有一些相似之处。比如两者都涉及到对“差异”或“偏离”的一种度量。在惯性矩中，是质量分布相对于转动轴的偏离程度；在方差中，是数据点相对于均值的偏离程度。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#协方差以及随机变量的和的方差",
    "href": "chapter_4/4.html#协方差以及随机变量的和的方差",
    "title": "4  随机变量和期望",
    "section": "4.7 协方差以及随机变量的和的方差",
    "text": "4.7 协方差以及随机变量的和的方差\n在 章节 4.5 中，我们证明了任意数量的 随机变量 之和的 期望 等于它们各自 期望 的和（方程式 4.45）。但是，对于 方差 而言，却并非如此。例如：\n\\[\n\\begin{align}\nVar(X+X) &= Var(2X) \\\\\n&= 2^2 Var(X) \\\\\n&= 4 Var(X) \\\\\n& \\ne Var(X) + Var(X)\n\\end{align}\n\\]\n然而，当这些 随机变量 是独立的条件时，随机变量 的和的 方差 等于这些 随机变量 各自的方差的和。但是，在证明这一点之前，我们先定义两个 随机变量 的 协方差（covariance） 的概念。\n\n定义 4.2 两个 随机变量 \\(X\\)、\\(Y\\) 的 协方差 \\(\\textup{Cov}(X,Y)\\) 的定义如下：\n\\(\\textup{Cov}(X,Y) = E[(X - \\mu_x)(Y - \\mu_y)]\\)，其中 \\(\\mu_x\\) 和 \\(\\mu_y\\) 分别为 \\(X\\) 和 \\(Y\\) 的均值。\n\n对 定义 4.2 中的等式右边进行展开，则有：\n\\[\n\\begin{align}\n\\textup{Cov}(X,Y) &= E[XY - \\mu_x Y -\\mu_y X + \\mu_x \\mu_y] \\\\\n&= E[X,Y] - \\mu_xE[Y] - \\mu_yE[X] + \\mu_x \\mu_y \\\\\n&= E[XY] - \\mu_x \\mu_y - \\mu_y \\mu_x + \\mu_x \\mu_y \\\\\n&= E[XY] - E[X]E[Y]\n\\end{align}\n\\tag{4.49}\\]\n根据 定义 4.2，我们可以知道 协方差 满足如下的性质：\n\n\n\n\n\n\n提示\n\n\n\n\\[\n\\textup{Cov}(X,Y) = \\textup{Cov}(Y,X)\n\\tag{4.50}\\]\n\\[\n\\textup{Cov}(X,X) = \\textup{Var}(X)\n\\tag{4.51}\\]\n\\[\n\\textup{Cov}(aX, Y) = a \\textup{Cov}(X, Y)\n\\tag{4.52}\\]\n\n\n与 期望 一样，协方差 也具有加和性（additive property）。\n\n引理 4.1 \\(\\textup{Cov}(X_1 + X_2, Y) = \\textup{Cov}(X_1, Y) + \\textup{Cov}(X_2,Y)\\)\n\n\n论证. \\[\n\\begin{align}\n\\textup{Cov}(X_1 + X_2,Y) &= E[(X_1+X_2)Y] - E[X_1+X_2]E[Y] \\\\\n&= E[X_1Y] + E[X_2Y]-(E[X_1] + E[X_2])E[Y] \\\\\n&= E[X_1Y] - E[X_1]E[Y] + E[X_2Y] - E[X_2]E[Y] \\\\\n&= \\textup{Cov}(X_1,Y) + \\textup{Cov}(X_2,Y) \\quad \\blacksquare\n\\end{align}\n\\]\n\n引理 4.1 的一般形式如下：\n\\[\n\\textup{Cov}\\bigg( \\sum_{i=1}^{n}{X_i},Y \\bigg) = \\sum_{i=1}^{n}{\\textup{Cov}(X_i,Y)}\n\\tag{4.53}\\]\n\n命题 4.2 \\[\n\\textup{Cov}\\bigg( \\sum_{i=1}^{n}{X_i},\\sum_{j=1}^{m}{Y_j} \\bigg) = \\sum_{i=1}^{n} \\sum_{j=1}^{m} {\\textup{Cov}(X_i,Y_j)}\n\\]\n\n\n论证. \\[\n\\begin{align}\n\\textup{Cov}\\bigg( \\sum_{i=1}^{n}{X_i},\\sum_{j=1}^{m}{Y_j} \\bigg) &= \\sum_{i=1}^{n}{\\textup{Cov}\\bigg(X_i, \\sum_{j=1}^{m}{Y_j}\\bigg)} \\\\\n&= \\sum_{i=1}^{n}{\\textup{Cov}\\bigg(\\sum_{j=1}^{m}{Y_j}, X_i\\bigg)} \\\\\n&= \\sum_{i=1}^{n} \\sum_{j=1}^{m} {\\textup{Cov}(Y_j,X_i)} \\\\\n&= \\sum_{i=1}^{n} \\sum_{j=1}^{m} {\\textup{Cov}(X_i,Y_j)} \\quad \\blacksquare\n\\end{align}\n\\]\n\n使用 方程式 4.51 可以得到 随机变量 之和的方差的公式。\n\n推论 4.2 \\[\n\\textup{Var}\\bigg( \\sum_{i=1}^{n}{X_i} \\bigg) = \\sum_{i=1}^{n}{\\textup{Var}(X_i)} + \\sum_{i=1}^{n} \\sum_{\\begin{align} &j=1 \\\\ &j \\ne i \\end{align}}^{n} {\\textup{Cov}(X_i, X_j)}\n\\]\n\n\n论证. 因为 \\(\\textup{Cov}(X, X) = \\textup{Var}(X)\\)（方程式 4.51），根据 命题 4.2 有：\n\\[\n\\begin{align}\n\\textup{Var}\\bigg( \\sum_{i=1}^{n}{X_i} \\bigg) &= \\textup{Cov}\\bigg( \\sum_{i=1}^{n}{X_i}, \\sum_{j=1}^{n}{X_j} \\bigg) \\\\\n&= \\sum_{i=1}^{n} \\sum_{j=1}^{n} {\\textup{Cov}(X_i, X_j)} \\\\\n&= \\sum_{i=1}^{n} \\bigg( \\sum_{j \\ne i}{\\textup{Cov}(X_i, X_j)} + \\textup{Cov}(X_i, X_i)\\bigg) \\\\\n&= \\sum_{i=1}^{n} \\sum_{j \\ne i} {\\textup{Cov}(X_i, X_j)} + \\sum_{i=1}^{n}{\\textup{Cov}(X_i, X_i)} \\\\\n&= \\sum_{i=1}^{n} \\sum_{j \\ne i} {\\textup{Cov}(X_i, X_j)} + \\sum_{i=1}^{n}{\\textup{Var}(X_i)} \\quad \\blacksquare\n\\end{align}\n\\]\n\n当 \\(n = 2\\) 时，推论 4.2 变为：\n\\(\\textup{Var}(X+Y) = \\textup{Var}(X) + \\textup{Var}(Y) + \\textup{Cov}(X,Y) + \\textup{Cov}(Y,X)\\)\n根据 方程式 4.50 有：\n\\[\n\\textup{Var}(X+Y) = \\textup{Var}(X) + \\textup{Var}(Y) + 2\\textup{Cov}(X,Y)\n\\tag{4.54}\\]\n\n定理 4.1 如果 \\(X\\) 和 \\(Y\\) 是独立 随机变量，则 \\(\\textup{Cov}(X,Y) = 0\\)。\n更一般的，如果 \\(X_1,...,X_n\\) 是相互独立的 随机变量，则 \\(\\textup{Var}\\bigg( \\sum_{i=1}^{n}{X_i} \\bigg)=\\sum_{i=1}^{n}{\\textup{Var}(X_i)}\\)。\n\n论证. 要证明 \\(\\textup{Cov}(X,Y) = 0\\)，根据 方程式 4.49 可知，我们需要证明：\n\\(E[XY] = E[X]E[Y]\\)\n如果 \\(X\\)、\\(Y\\) 为独立离散随机变量，则有：\n\\[\n\\begin{align}\nE[XY] &= \\sum_{j}^{} \\sum_{i}^{} {x_i y_i P\\{X=x_i, Y=y_j\\}} \\\\\n&= \\sum_{j}^{} \\sum_{i}^{} {x_i y_i P\\{X=x_i\\}P\\{Y=y_j\\}} \\quad \\because X,Y 相互独立 \\\\\n&= \\sum_{y}^{}{y_jP\\{Y=y_j\\}} \\cdot \\sum_{j}^{}{x_iP\\{X=x_i\\}} \\\\\n&= E[Y]E[X]\n\\end{align}\n\\]\n故而有 \\(\\textup{Cov}(X,Y)=E[XY] - E[X]E[Y] = 0\\)。对于连续随机变量而言，该等式依然成立。所以 定理 4.1 得证。\n\n\n\n练习 4.16 抛 10 次骰子，计算这 10 次获得的点数之和的 方差。\n\n\n答案 4.16. 令 \\(X_i\\) 表示第 \\(i\\) 次的点数，则根据 练习 4.15 有，\\(\\textup{Var}(X_i) = \\frac{35}{12}\\)，所以： \\[\n\\begin{align}\n\\textup{Var}\\bigg( \\sum_{i=1}^{10}{X_i} \\bigg) &= \\sum_{i=1}^{10}{\\textup{Var}(X_i)} \\\\\n&= 10 \\frac{35}{12} \\\\\n&= \\frac{175}{6} \\quad \\blacksquare\n\\end{align}\n\\]\n\n\n练习 4.17 抛 10 次硬币，计算正面向上的次数的 方差。\n\n\n答案 4.17. 令 \\(I_j = \\begin{cases} 1, \\quad & 第 j 次结果为正面向上\\\\ 0, \\quad & 第 j 次结果为反面向上 \\end{cases}\\)，\n则 正面向上的总次数为 \\(\\sum_{j=1}^{10}{I_j}\\)。\n根据 定理 4.1 有：\\(\\textup{Var}\\bigg( \\sum_{j=1}^{10}{I_j} \\bigg) = \\sum_{j=1}^{10}{\\textup{Var}(I_j)}\\)。\n现在，由于 \\(I_j\\) 是概率为 的 事件 的指示 随机变量，从 例子 4.12 可知：\n\\(\\textup{Var}(I_j) = \\frac{1}{2}(1-\\frac{1}{2}) = \\frac{1}{4}\\)，因此：\n\\(\\textup{Var}\\bigg( \\sum_{j=1}^{10}{I_j} \\bigg) = \\frac{10}{4}\\)。\\(\\blacksquare\\)\n\n\n\n\n\n\n\n重要\n\n\n\n两个 随机变量 的 协方差 可以作为一个重要指标以衡量它们之间的关系。例如，考虑 \\(X\\) 和 \\(Y\\) 是 事件 \\(A\\) 和 事件 \\(B\\) 是否发生的指标随机变量，即：\n\\(X = \\begin{cases} 1, \\quad & 如果 A 发生\\\\ & \\\\ 0, \\quad & 如果 A 不发生 \\end{cases},  \\quad Y = \\begin{cases} 1, \\quad & 如果 B 发生\\\\ & \\\\ 0, \\quad & 如果 B 不发生 \\end{cases}\\)\n并且：\n\\(XY = \\begin{cases} 1, \\quad & 如果 X=1, Y=1\\\\ & \\\\ 0, \\quad & 其他 \\end{cases}\\)\n因此：\n\\(\\begin{align} \\textup{Cov}(X,Y) &= E[XY] - E[X]E[Y] \\\\ &= P\\{X=1,Y=1\\} - P\\{X=1\\}P\\{Y=1\\} \\end{align}\\)\n故而：\n\\(\\begin{align} \\textup{Cov}(X,Y) \\gt 0 & \\Leftrightarrow P\\{X=1,Y=1\\} \\gt P\\{X=1\\}P\\{Y=1\\} \\\\ & \\Leftrightarrow \\frac{P \\{X=1,Y=1\\}}{P\\{X=1\\}} \\gt P\\{Y=1\\} \\\\ & \\Leftrightarrow P\\{Y=1|X=1\\} \\gt P\\{Y=1\\} \\end{align}\\)\n如果 \\(X=1\\) 时，\\(Y=1\\) 的可能性更小，而 \\(Y=0\\) 的可能性更大，则 \\(\\textup{Cov}(X,Y) \\lt 0\\) 。（根据 协方差 的交换律，当 \\(X\\) 和 \\(Y\\) 互换时，如上的内容仍然正确。）\n\n\n\n\n\n\n\n\n相关系数\n\n\n\n一般来说，\\(\\textup{Cov}(X,Y) \\gt 0\\) 表明 \\(Y\\) 会随着 \\(X\\) 的增加而增加，而 \\(\\textup{Cov}(X,Y) \\lt 0\\) 表明 \\(Y\\) 会随着 \\(X\\) 的增加而减少。可以用 \\(X\\) 和 \\(Y\\) 之间的相关性来表示 \\(X\\) 和 \\(Y\\) 之间关系的强度。\\(X\\) 和 \\(Y\\) 之间的相关性是其 协方差 除以其各自 标准差 的乘积得到的 无量纲量（dimensionless）。即：\n\\[\n\\textup{Corr}(X,Y) = \\frac{\\textup{Cov}(X,Y)}{\\sqrt{\\textup{Var}(X) \\textup{Var}(Y)}}\n\\tag{4.55}\\]\n可以证明，\\(\\textup{Corr}(X,Y)\\) 的值总是介于 −1 和 +1 之间。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#矩生成函数",
    "href": "chapter_4/4.html#矩生成函数",
    "title": "4  随机变量和期望",
    "section": "4.8 矩生成函数",
    "text": "4.8 矩生成函数\n\n\n\n\n\n\n注释\n\n\n\n矩生成函数（Moment Generating Function）是概率论中的一个重要概念，主要用于描述 随机变量 的概率分布。矩生成函数是 随机变量 的特征函数，我们可以利用矩生成函数得到 随机变量 的所有矩（平均值、方差、偏度等统计量）。\n\n\n随机变量 \\(X\\) 的矩生成函数 \\(\\phi(t)\\) 的定义如下：\n\\[\n\\phi(t) = E[e^{tX}] = \\begin{cases}\n\\sum_{x}{e^{tx}p(x)}, \\quad & 如果 X 为离散随机变量 \\\\\n& \\\\\n& \\\\\n\\int_{-\\infty}^{\\infty}{e^{tx}f(x) \\mathrm{d} x}, \\quad & 如果 X 为连续随机变量 \\\\\n\\end{cases}\n\\tag{4.56}\\]\n因为 \\(X\\) 的所有的矩都可以通过对 \\(\\phi(t)\\) 求 \\(k\\) 阶导数来获得，因此我们称 \\(\\phi(t)\\) 为矩生成函数。例如\n\n\\(\\phi'(0)=E[X]\\)：\n\n\\[\n\\begin{align}\n\\phi'(t) &= \\frac{\\mathrm{d} {E[e^{tX}]}}{\\mathrm{d} t} \\\\\n&= E\\bigg[ \\frac{\\mathrm{d} {e^{tX}}}{\\mathrm{d} t} \\bigg] \\\\\n&= E[Xe^{tX}] \\\\\n\\therefore \\phi'(0) &= E[Xe^{0 \\cdot X}] = E[X]\n\\end{align}\n\\tag{4.57}\\]\n\n\\(\\phi''(0)=E[X^2]\\)\n\n\\[\n\\begin{align}\n\\phi''(t) &= \\frac{\\mathrm{d} {\\phi'(t)}}{\\mathrm{d} t} \\\\\n&= \\frac{\\mathrm{d} {E[Xe^{tX}]}}{\\mathrm{d} t} \\\\\n&= E\\bigg[ \\frac{\\mathrm{d} {(Xe^{tX})}}{\\mathrm{d} t} \\bigg] \\\\\n&= E[X^2e^{tX}] \\\\\n\\therefore \\phi''(0) &= E[X^2]\n\\end{align}\n\\tag{4.58}\\]\n\n更一般的，在 \\(t=0\\) 处的 \\(\\phi(t)\\) 的 \\(n\\) 阶导数等于 \\(E[X^n]\\)，即：\n\n\\[\n\\phi^{n}(0) = E[X^n], \\quad n \\ge 1\n\\tag{4.59}\\]\n矩生成函数的一个重要特性是：独立 随机变量 之和的矩生成函数是每个 随机变量 的矩生成函数的乘积。假设 \\(X\\) 和 \\(Y\\) 是独立 随机变量，其矩生成函数分别为 \\(\\phi_X(t)\\)、\\(\\phi_Y(t)\\)，则 \\(X+Y\\) 的矩生成函数为：\n\\(\\begin{align} \\phi_{X+Y}(t) &= E[e^{t(X+Y)}] \\\\ &= E[e^{tX}e^{tY}] \\\\ &= E[e^{tX}]E[e^{tY}] \\\\ &= \\phi_X(t)\\phi_Y(t) \\end{align}\\)\n如果 \\(X\\) 和 \\(Y\\) 是相互独立的，则 \\(e^{tX}\\) 和 \\(e^{tY}\\) 也是独立的，所以根据 定理 4.1 有 \\(E[e^{tX}e^{tY}] = E[e^{tX}]E[e^{tY}]\\)，所以上式得证。\n矩生成函数的另一个重要的特性是：矩生成函数唯一地确定了 随机变量 的概率分布。也就是说，矩生成函数和 随机变量 的分布函数之间存在一一对应的关系。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#切比雪夫不等式和弱大数定律",
    "href": "chapter_4/4.html#切比雪夫不等式和弱大数定律",
    "title": "4  随机变量和期望",
    "section": "4.9 切比雪夫不等式和弱大数定律",
    "text": "4.9 切比雪夫不等式和弱大数定律\n我们从证明马尔可夫不等式（Markov’s inequality）开始本节的内容。\n\n命题 4.3 马尔可夫不等式：如果 \\(X\\) 是一个取值为非负数的 随机变量，则对于任意的 \\(a \\gt 0\\) 有：\n\\(P\\{X \\ge a\\} \\le \\frac{E[X]}{a}\\)\n\n论证. 我们给出了概率密度函数为 \\(f\\) 的连续 随机变量 \\(X\\) 的证明。\n\\[\n\\begin{align}\nE[X] &= \\int_{0}^{\\infty}{xf(x) \\mathrm{d} x} \\\\\n&= \\int_{0}^{a}{xf(x) \\mathrm{d} x} + \\int_{a}^{\\infty}{xf(x) \\mathrm{d} x} \\\\\n& \\ge \\int_{a}^{\\infty}{xf(x) \\mathrm{d} x} \\\\\n& \\ge \\int_{a}^{\\infty}{af(x) \\mathrm{d} x} \\\\\n&= a\\int_{a}^{\\infty}{f(x) \\mathrm{d} x} \\\\\n&= aP\\{X \\ge a\\} \\quad \\blacksquare\n\\end{align}\n\\]\n\n\n作为推论，我们得到 命题 4.4。\n\n命题 4.4 契比雪夫不等式：如果\\(X\\) 是一个均值为 \\(\\mu\\) 方差为 \\(\\sigma^2\\) 的随机变量，则对于任意的 \\(k \\gt 0\\) 有：\n\\(P\\{|X - \\mu| \\ge k\\} \\le \\frac{\\sigma^2}{k^2}\\)\n\n论证. 因为 \\((X-\\mu)^2\\) 是一个非负的随机变量，因此，令 \\(a=k^2\\)，然后根据 命题 4.3 所示的马尔科夫不等式有：\n\\[\nP\\{(X-\\mu)^2 \\ge k^2\\} \\le \\frac{E[(X-\\mu)^2]}{k^2}\n\\tag{4.60}\\]\n\\((X-\\mu)^2 \\ge k^2\\) 当且仅当 \\(|X-\\mu| \\ge k\\)，所以 方程式 4.60 等价于：\n\\[\nP\\{|X-\\mu| \\ge k\\} \\le \\frac{E[(X-\\mu)^2]}{k^2} = \\frac{\\sigma^2}{k^2}\n\\tag{4.61}\\]\n证毕。\\(\\blacksquare\\)\n\n\n马尔可夫不等式和切比雪夫不等式的重要性在于：在只知道概率分布的均值或均值和方差的情况下，我们可以利用马尔可夫不等式和切比雪夫不等式推导出概率的界限。当然，如果实际的概率分布是已知的，那么就可以精确的计算出待计算的概率，我们也就不需要计算概率的界限。\n\n练习 4.18 已知工厂一周的产量是一个 随机变量，其平均值为 50。\n\n本周的产量超过 75 的概率可以说是多少？\n如果已知一周的产量的方差等于 25，那么本周产量在 40 和 60 之间的概率是多少？\n\n\n\n答案 4.18. 令 \\(X\\) 为工厂一周的产量。\n\n利用马尔科夫不等式可知：\n\\(P\\{X \\gt 75\\} \\le \\frac{E[X]}{75} = \\frac{50}{75} = \\frac{2}{3}\\)\n利用切比雪夫不等式可知：\n\\(P\\{|X-50| \\ge 10\\} \\le \\frac{\\sigma^2}{10^2} = \\frac{1}{4}\\)，所以：\n$\\(P\\{|X-50| \\lt 10\\} \\ge 1 - \\frac{1}{4} = \\frac{3}{4}\\)。\n因此，本周产量在 40 和 60 之间的概率最小是 0.75。\\(\\blacksquare\\)\n\n\n在 方程式 4.61 中，令 \\(k = k\\sigma\\)，我们可以将切比雪夫不等式改写为：\n\\[\nP\\{|X - \\mu| \\ge k\\sigma\\} \\le \\frac{1}{k^2}\n\\tag{4.62}\\]\n因此，随机变量 与其 均值 相差超过 \\(k\\) 个 标准差 的概率最大为 \\(\\frac{1}{k^2}\\)。\n在本节的最后，我们将用切比雪夫不等式来证明弱大数定律（weak law of large numbers）。弱大数定律指出：在一个独立同分布的 随机变量 序列中，当 \\(n\\) 趋向于无穷大时，前 \\(n\\) 个 随机变量 的平均数（average）和该随机变量的均值（mean）的差值超过 \\(\\varepsilon\\) 的概率为 0。\n\n定理 4.2 弱大数定律：令 \\(X_1, X_2,...\\) 是一个独立同分布的 随机变量 序列，每个 随机变量 的均值都为 \\(\\mu\\)（\\(E[X_i] = \\mu\\)）。则，对于任意的 \\(\\varepsilon \\gt 0\\)，有：\n\\(P\\bigg\\{ \\big| \\frac{X_1 + X_2 + ... + X_n}{n} - \\mu \\big| \\gt \\varepsilon \\bigg\\} \\rightarrow 0, \\quad n \\rightarrow \\infty\\)\n\n论证. 我们只能在 随机变量 的方差 \\(\\sigma^2\\) 为有限数的附加假设下证明 定理 4.2。因为：\n\\(E\\bigg[\\frac{X_1 + X_2 + ... + X_n}{n}\\bigg] = \\mu\\)，\\(\\textup{Var}\\bigg(\\frac{X_1 + X_2 + ... + X_n}{n}\\bigg) = \\frac{\\sigma^2}{n}\\)\n所以，根据 命题 4.4 的切比雪夫不等式有：\n\\(P\\bigg\\{ \\big| \\frac{X_1 + X_2 + ... + X_n}{n} - \\mu \\big| \\gt \\varepsilon \\bigg\\} \\le \\frac{\\sigma^2}{n \\varepsilon^2}\\)\n证毕。\\(\\blacksquare\\)\n\n\n假设我们独立执行某个试验多次，令 \\(E\\) 为某个固定 事件，用 \\(P(E)\\) 表示 \\(E\\) 在给定试验中发生的概率。令\n\\(X_i = \\begin{cases} 1, \\quad & 第 i 次试验中 E 发生\\\\ 0, \\quad & 第 i 次试验中 E 不发生 \\end{cases}\\)\n则 \\(X_1+X_2+...+X_n\\) 表示在 \\(n\\) 次试验中，\\(E\\) 发生的次数。因为 \\(E[X_i]=P(E)\\)，所以根据弱大数定律，对于任意的 \\(\\varepsilon \\gt 0\\)，无论 \\(\\varepsilon\\) 有多小，随着 \\(n\\) 的增加，前 \\(n\\) 次试验中 \\(E\\) 发生的比例与 \\(P(E)\\) 的差值超过 \\(\\varepsilon\\) 的概率会变为 0。",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#problems",
    "href": "chapter_4/4.html#problems",
    "title": "4  随机变量和期望",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#footnotes",
    "href": "chapter_4/4.html#footnotes",
    "title": "4  随机变量和期望",
    "section": "",
    "text": "为了证明这一点，我们必须证明这根杆绕点 \\(E[X]\\) 转动的力矩之和等于 0。也就是说，我们必须证明 \\(0=\\sum_{i}{(x_i−E[X])p(x_i)}\\)。↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>随机变量和期望</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html",
    "href": "chapter_5/5.html",
    "title": "5  Special random variables",
    "section": "",
    "text": "5.1 The Bernoulli and binomial random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-poisson-random-variable",
    "href": "chapter_5/5.html#the-poisson-random-variable",
    "title": "5  Special random variables",
    "section": "5.2 The Poisson random variable",
    "text": "5.2 The Poisson random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-hypergeometric-random-variable",
    "href": "chapter_5/5.html#the-hypergeometric-random-variable",
    "title": "5  Special random variables",
    "section": "5.3 The hypergeometric random variable",
    "text": "5.3 The hypergeometric random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-uniform-random-variable",
    "href": "chapter_5/5.html#the-uniform-random-variable",
    "title": "5  Special random variables",
    "section": "5.4 The uniform random variable",
    "text": "5.4 The uniform random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#normal-random-variables",
    "href": "chapter_5/5.html#normal-random-variables",
    "title": "5  Special random variables",
    "section": "5.5 Normal random variables",
    "text": "5.5 Normal random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#exponential-random-variables",
    "href": "chapter_5/5.html#exponential-random-variables",
    "title": "5  Special random variables",
    "section": "5.6 Exponential random variables",
    "text": "5.6 Exponential random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-gamma-distribution",
    "href": "chapter_5/5.html#the-gamma-distribution",
    "title": "5  Special random variables",
    "section": "5.7 The gamma distribution",
    "text": "5.7 The gamma distribution",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#distributions-arising-from-the-normal",
    "href": "chapter_5/5.html#distributions-arising-from-the-normal",
    "title": "5  Special random variables",
    "section": "5.8 Distributions arising from the normal",
    "text": "5.8 Distributions arising from the normal",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-logistics-distribution",
    "href": "chapter_5/5.html#the-logistics-distribution",
    "title": "5  Special random variables",
    "section": "5.9 The logistics distribution",
    "text": "5.9 The logistics distribution",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#distributions-in-r",
    "href": "chapter_5/5.html#distributions-in-r",
    "title": "5  Special random variables",
    "section": "5.10 Distributions in R",
    "text": "5.10 Distributions in R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#problems",
    "href": "chapter_5/5.html#problems",
    "title": "5  Special random variables",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html",
    "href": "chapter_6/6.html",
    "title": "6  Distributions of sampling statistics",
    "section": "",
    "text": "6.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-sample-mean",
    "href": "chapter_6/6.html#the-sample-mean",
    "title": "6  Distributions of sampling statistics",
    "section": "6.2 The sample mean",
    "text": "6.2 The sample mean",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-central-limit-theorem",
    "href": "chapter_6/6.html#the-central-limit-theorem",
    "title": "6  Distributions of sampling statistics",
    "section": "6.3 The central limit theorem",
    "text": "6.3 The central limit theorem",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-sample-variance",
    "href": "chapter_6/6.html#the-sample-variance",
    "title": "6  Distributions of sampling statistics",
    "section": "6.4 The sample variance",
    "text": "6.4 The sample variance",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#sampling-distributions-from-a-normal-population",
    "href": "chapter_6/6.html#sampling-distributions-from-a-normal-population",
    "title": "6  Distributions of sampling statistics",
    "section": "6.5 Sampling distributions from a normal population",
    "text": "6.5 Sampling distributions from a normal population",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#sampling-from-a-finite-population",
    "href": "chapter_6/6.html#sampling-from-a-finite-population",
    "title": "6  Distributions of sampling statistics",
    "section": "6.6 Sampling from a finite population",
    "text": "6.6 Sampling from a finite population",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#problems",
    "href": "chapter_6/6.html#problems",
    "title": "6  Distributions of sampling statistics",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html",
    "href": "chapter_7/7.html",
    "title": "7  Parameter estimation",
    "section": "",
    "text": "7.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#maximum-likelihood-estimators",
    "href": "chapter_7/7.html#maximum-likelihood-estimators",
    "title": "7  Parameter estimation",
    "section": "7.2 Maximum likelihood estimators",
    "text": "7.2 Maximum likelihood estimators",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#interval-estimates",
    "href": "chapter_7/7.html#interval-estimates",
    "title": "7  Parameter estimation",
    "section": "7.3 Interval estimates",
    "text": "7.3 Interval estimates",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#estimating-the-difference-in-means-of-two-normal-populations",
    "href": "chapter_7/7.html#estimating-the-difference-in-means-of-two-normal-populations",
    "title": "7  Parameter estimation",
    "section": "7.4 Estimating the difference in means of two normal populations",
    "text": "7.4 Estimating the difference in means of two normal populations",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#approximate-confidence-interval-for-the-mean-of-a-bernoulli-random-variable",
    "href": "chapter_7/7.html#approximate-confidence-interval-for-the-mean-of-a-bernoulli-random-variable",
    "title": "7  Parameter estimation",
    "section": "7.5 Approximate confidence interval for the mean of a Bernoulli random variable",
    "text": "7.5 Approximate confidence interval for the mean of a Bernoulli random variable",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#confidence-interval-of-the-mean-of-the-exponential-distribution",
    "href": "chapter_7/7.html#confidence-interval-of-the-mean-of-the-exponential-distribution",
    "title": "7  Parameter estimation",
    "section": "7.6 Confidence interval of the mean of the exponential distribution",
    "text": "7.6 Confidence interval of the mean of the exponential distribution",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#evaluating-a-point-estimator",
    "href": "chapter_7/7.html#evaluating-a-point-estimator",
    "title": "7  Parameter estimation",
    "section": "7.7 Evaluating a point estimator",
    "text": "7.7 Evaluating a point estimator",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#the-bayes-estimator",
    "href": "chapter_7/7.html#the-bayes-estimator",
    "title": "7  Parameter estimation",
    "section": "7.8 The Bayes estimator",
    "text": "7.8 The Bayes estimator",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#problems",
    "href": "chapter_7/7.html#problems",
    "title": "7  Parameter estimation",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html",
    "href": "chapter_8/8.html",
    "title": "8  Hypothesis testing",
    "section": "",
    "text": "8.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#significance-levels",
    "href": "chapter_8/8.html#significance-levels",
    "title": "8  Hypothesis testing",
    "section": "8.2 Significance levels",
    "text": "8.2 Significance levels",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#tests-concerning-the-mean-of-a-normal-population",
    "href": "chapter_8/8.html#tests-concerning-the-mean-of-a-normal-population",
    "title": "8  Hypothesis testing",
    "section": "8.3 Tests concerning the mean of a normal population",
    "text": "8.3 Tests concerning the mean of a normal population",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#testing-the-equality-of-means-of-two-normal-populations",
    "href": "chapter_8/8.html#testing-the-equality-of-means-of-two-normal-populations",
    "title": "8  Hypothesis testing",
    "section": "8.4 Testing the equality of means of two normal populations",
    "text": "8.4 Testing the equality of means of two normal populations",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#hypothesis-tests-concerning-the-variance-of-a-normal-population",
    "href": "chapter_8/8.html#hypothesis-tests-concerning-the-variance-of-a-normal-population",
    "title": "8  Hypothesis testing",
    "section": "8.5 Hypothesis tests concerning the variance of a normal population",
    "text": "8.5 Hypothesis tests concerning the variance of a normal population",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#hypothesis-tests-in-bernoulli-populations",
    "href": "chapter_8/8.html#hypothesis-tests-in-bernoulli-populations",
    "title": "8  Hypothesis testing",
    "section": "8.6 Hypothesis tests in Bernoulli populations",
    "text": "8.6 Hypothesis tests in Bernoulli populations",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#tests-concerning-the-mean-of-a-poisson-distribution",
    "href": "chapter_8/8.html#tests-concerning-the-mean-of-a-poisson-distribution",
    "title": "8  Hypothesis testing",
    "section": "8.7 Tests concerning the mean of a Poisson distribution",
    "text": "8.7 Tests concerning the mean of a Poisson distribution",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#problems",
    "href": "chapter_8/8.html#problems",
    "title": "8  Hypothesis testing",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html",
    "href": "chapter_9/9.html",
    "title": "9  Regression",
    "section": "",
    "text": "9.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#least-squares-estimators-of-the-regression-parameters",
    "href": "chapter_9/9.html#least-squares-estimators-of-the-regression-parameters",
    "title": "9  Regression",
    "section": "9.2 Least squares estimators of the regression parameters",
    "text": "9.2 Least squares estimators of the regression parameters",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#distribution-of-the-estimators",
    "href": "chapter_9/9.html#distribution-of-the-estimators",
    "title": "9  Regression",
    "section": "9.3 Distribution of the estimators",
    "text": "9.3 Distribution of the estimators",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#statistical-inferences-about-the-regression-parameters",
    "href": "chapter_9/9.html#statistical-inferences-about-the-regression-parameters",
    "title": "9  Regression",
    "section": "9.4 Statistical inferences about the regression parameters",
    "text": "9.4 Statistical inferences about the regression parameters",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#the-coefficient-of-determination-and-the-sample-correlation-coefficient",
    "href": "chapter_9/9.html#the-coefficient-of-determination-and-the-sample-correlation-coefficient",
    "title": "9  Regression",
    "section": "9.5 The coefficient of determination and the sample correlation coefficient",
    "text": "9.5 The coefficient of determination and the sample correlation coefficient",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#analysis-of-residuals-assessing-the-model",
    "href": "chapter_9/9.html#analysis-of-residuals-assessing-the-model",
    "title": "9  Regression",
    "section": "9.6 Analysis of residuals: assessing the model",
    "text": "9.6 Analysis of residuals: assessing the model",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#transforming-to-linearity",
    "href": "chapter_9/9.html#transforming-to-linearity",
    "title": "9  Regression",
    "section": "9.7 Transforming to linearity",
    "text": "9.7 Transforming to linearity",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#weighted-least-squares",
    "href": "chapter_9/9.html#weighted-least-squares",
    "title": "9  Regression",
    "section": "9.8 Weighted least squares",
    "text": "9.8 Weighted least squares",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#polynomial-regression",
    "href": "chapter_9/9.html#polynomial-regression",
    "title": "9  Regression",
    "section": "9.9 Polynomial regression",
    "text": "9.9 Polynomial regression",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#multiple-linear-regression",
    "href": "chapter_9/9.html#multiple-linear-regression",
    "title": "9  Regression",
    "section": "9.10 Multiple linear regression",
    "text": "9.10 Multiple linear regression",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#logistic-regression-models-for-binary-output-data",
    "href": "chapter_9/9.html#logistic-regression-models-for-binary-output-data",
    "title": "9  Regression",
    "section": "9.11 Logistic regression models for binary output data",
    "text": "9.11 Logistic regression models for binary output data",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#problems",
    "href": "chapter_9/9.html#problems",
    "title": "9  Regression",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html",
    "href": "chapter_10/10.html",
    "title": "10  Analysis of variance",
    "section": "",
    "text": "10.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#an-overview",
    "href": "chapter_10/10.html#an-overview",
    "title": "10  Analysis of variance",
    "section": "10.2 An overview",
    "text": "10.2 An overview",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#one-way-analysis-of-variance",
    "href": "chapter_10/10.html#one-way-analysis-of-variance",
    "title": "10  Analysis of variance",
    "section": "10.3 One-way analysis of variance",
    "text": "10.3 One-way analysis of variance",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-factor-analysis-of-variance-introduction-and-parameter-estimation",
    "href": "chapter_10/10.html#two-factor-analysis-of-variance-introduction-and-parameter-estimation",
    "title": "10  Analysis of variance",
    "section": "10.4 Two-factor analysis of variance: introduction and parameter estimation",
    "text": "10.4 Two-factor analysis of variance: introduction and parameter estimation",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-factor-analysis-of-variance-testing-hypotheses",
    "href": "chapter_10/10.html#two-factor-analysis-of-variance-testing-hypotheses",
    "title": "10  Analysis of variance",
    "section": "10.5 Two-factor analysis of variance: testing hypotheses",
    "text": "10.5 Two-factor analysis of variance: testing hypotheses",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-way-analysis-of-variance-with-interaction",
    "href": "chapter_10/10.html#two-way-analysis-of-variance-with-interaction",
    "title": "10  Analysis of variance",
    "section": "10.6 Two-way analysis of variance with interaction",
    "text": "10.6 Two-way analysis of variance with interaction",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#problems",
    "href": "chapter_10/10.html#problems",
    "title": "10  Analysis of variance",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html",
    "href": "chapter_11/11.html",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "",
    "text": "11.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#goodness-of-fit-tests-when-all-parameters-are-specified",
    "href": "chapter_11/11.html#goodness-of-fit-tests-when-all-parameters-are-specified",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.2 Goodness of fit tests when all parameters are specified",
    "text": "11.2 Goodness of fit tests when all parameters are specified",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#goodness-of-fit-tests-when-some-parameters-are-unspecified",
    "href": "chapter_11/11.html#goodness-of-fit-tests-when-some-parameters-are-unspecified",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.3 Goodness of fit tests when some parameters are unspecified",
    "text": "11.3 Goodness of fit tests when some parameters are unspecified",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#tests-of-independence-in-contingency-tables",
    "href": "chapter_11/11.html#tests-of-independence-in-contingency-tables",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.4 Tests of independence in contingency tables",
    "text": "11.4 Tests of independence in contingency tables",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#tests-of-independence-in-contingency-tables-having-fixed-marginal-totals",
    "href": "chapter_11/11.html#tests-of-independence-in-contingency-tables-having-fixed-marginal-totals",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.5 Tests of independence in contingency tables having fixed marginal totals",
    "text": "11.5 Tests of independence in contingency tables having fixed marginal totals",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#the-kolmogorovsmirnov-goodness-of-fit-test-for-continuous-data",
    "href": "chapter_11/11.html#the-kolmogorovsmirnov-goodness-of-fit-test-for-continuous-data",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.6 The Kolmogorov–Smirnov goodness of fit test for continuous data",
    "text": "11.6 The Kolmogorov–Smirnov goodness of fit test for continuous data",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#problems",
    "href": "chapter_11/11.html#problems",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html",
    "href": "chapter_12/12.html",
    "title": "12  Nonparametric hypothesis tests",
    "section": "",
    "text": "12.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-sign-test",
    "href": "chapter_12/12.html#the-sign-test",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.2 The sign test",
    "text": "12.2 The sign test",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-signed-rank-test",
    "href": "chapter_12/12.html#the-signed-rank-test",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.3 The signed rank test",
    "text": "12.3 The signed rank test",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-two-sample-problem",
    "href": "chapter_12/12.html#the-two-sample-problem",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.4 The two-sample problem",
    "text": "12.4 The two-sample problem",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-runs-test-for-randomness",
    "href": "chapter_12/12.html#the-runs-test-for-randomness",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.5 The runs test for randomness",
    "text": "12.5 The runs test for randomness",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#problems",
    "href": "chapter_12/12.html#problems",
    "title": "12  Nonparametric hypothesis tests",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html",
    "href": "chapter_13/13.html",
    "title": "13  Quality control",
    "section": "",
    "text": "13.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-average-valuesthe-overlinex-control-chart",
    "href": "chapter_13/13.html#control-charts-for-average-valuesthe-overlinex-control-chart",
    "title": "13  Quality control",
    "section": "13.2 Control charts for average values:the \\(\\overline{x}\\) control chart",
    "text": "13.2 Control charts for average values:the \\(\\overline{x}\\) control chart",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#mathbfs-control-charts",
    "href": "chapter_13/13.html#mathbfs-control-charts",
    "title": "13  Quality control",
    "section": "13.3 \\(\\mathbf{S}\\)-control charts",
    "text": "13.3 \\(\\mathbf{S}\\)-control charts",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-the-fraction-defective",
    "href": "chapter_13/13.html#control-charts-for-the-fraction-defective",
    "title": "13  Quality control",
    "section": "13.4 Control charts for the fraction defective",
    "text": "13.4 Control charts for the fraction defective",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-number-of-defects",
    "href": "chapter_13/13.html#control-charts-for-number-of-defects",
    "title": "13  Quality control",
    "section": "13.5 Control charts for number of defects",
    "text": "13.5 Control charts for number of defects",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#other-control-charts-for-detecting-changes-in-the-population-mean",
    "href": "chapter_13/13.html#other-control-charts-for-detecting-changes-in-the-population-mean",
    "title": "13  Quality control",
    "section": "13.6 Other control charts for detecting changes in the population mean",
    "text": "13.6 Other control charts for detecting changes in the population mean",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#problems",
    "href": "chapter_13/13.html#problems",
    "title": "13  Quality control",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html",
    "href": "chapter_14/14.html",
    "title": "14  Life testing",
    "section": "",
    "text": "14.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#hazardrate-functions",
    "href": "chapter_14/14.html#hazardrate-functions",
    "title": "14  Life testing",
    "section": "14.2 Hazardrate functions",
    "text": "14.2 Hazardrate functions",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#the-exponential-distribution-in-life-testing.",
    "href": "chapter_14/14.html#the-exponential-distribution-in-life-testing.",
    "title": "14  Life testing",
    "section": "14.3 The exponential distribution in life testing.",
    "text": "14.3 The exponential distribution in life testing.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#a-two-sample-problem",
    "href": "chapter_14/14.html#a-two-sample-problem",
    "title": "14  Life testing",
    "section": "14.4 A two-sample problem",
    "text": "14.4 A two-sample problem",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#the-weibull-distribution-in-life-testing",
    "href": "chapter_14/14.html#the-weibull-distribution-in-life-testing",
    "title": "14  Life testing",
    "section": "14.5 The Weibull distribution in life testing",
    "text": "14.5 The Weibull distribution in life testing",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#problems",
    "href": "chapter_14/14.html#problems",
    "title": "14  Life testing",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html",
    "href": "chapter_15/15.html",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "",
    "text": "15.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#random-numbers",
    "href": "chapter_15/15.html#random-numbers",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.2 Random numbers",
    "text": "15.2 Random numbers",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#the-bootstrap-method",
    "href": "chapter_15/15.html#the-bootstrap-method",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.3 The bootstrap method",
    "text": "15.3 The bootstrap method",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#permutation-tests",
    "href": "chapter_15/15.html#permutation-tests",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.4 Permutation tests",
    "text": "15.4 Permutation tests",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#generating-discrete-random-variables",
    "href": "chapter_15/15.html#generating-discrete-random-variables",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.5 Generating discrete random variables",
    "text": "15.5 Generating discrete random variables",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#generating-continuous-random-variables",
    "href": "chapter_15/15.html#generating-continuous-random-variables",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.6 Generating continuous random variables",
    "text": "15.6 Generating continuous random variables",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#determining-the-number-of-simulation-runs-in-a-monte-carlo-study",
    "href": "chapter_15/15.html#determining-the-number-of-simulation-runs-in-a-monte-carlo-study",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.7 Determining the number of simulation runs in a Monte Carlo study",
    "text": "15.7 Determining the number of simulation runs in a Monte Carlo study",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#problems",
    "href": "chapter_15/15.html#problems",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html",
    "href": "chapter_16/16.html",
    "title": "16  Machine learning and big data",
    "section": "",
    "text": "16.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#late-flight-probabilities",
    "href": "chapter_16/16.html#late-flight-probabilities",
    "title": "16  Machine learning and big data",
    "section": "16.2 Late flight probabilities",
    "text": "16.2 Late flight probabilities",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#the-naive-bayes-approach",
    "href": "chapter_16/16.html#the-naive-bayes-approach",
    "title": "16  Machine learning and big data",
    "section": "16.3 The naive Bayes approach",
    "text": "16.3 The naive Bayes approach",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#distance-based-estimators.the-k-nearest-neighbors-rule",
    "href": "chapter_16/16.html#distance-based-estimators.the-k-nearest-neighbors-rule",
    "title": "16  Machine learning and big data",
    "section": "16.4 Distance-based estimators.The \\(k\\)-nearest neighbors rule",
    "text": "16.4 Distance-based estimators.The \\(k\\)-nearest neighbors rule",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#assessing-the-approaches",
    "href": "chapter_16/16.html#assessing-the-approaches",
    "title": "16  Machine learning and big data",
    "section": "16.5 Assessing the approaches",
    "text": "16.5 Assessing the approaches",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#when-characterizing-vectors-are-quantitative",
    "href": "chapter_16/16.html#when-characterizing-vectors-are-quantitative",
    "title": "16  Machine learning and big data",
    "section": "16.6 When characterizing vectors are quantitative",
    "text": "16.6 When characterizing vectors are quantitative",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#choosing-the-best-probability-a-bandit-problem",
    "href": "chapter_16/16.html#choosing-the-best-probability-a-bandit-problem",
    "title": "16  Machine learning and big data",
    "section": "16.7 Choosing the best probability: a bandit problem",
    "text": "16.7 Choosing the best probability: a bandit problem",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#problems",
    "href": "chapter_16/16.html#problems",
    "title": "16  Machine learning and big data",
    "section": "16.8 Problems",
    "text": "16.8 Problems",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "17  测试脚本",
    "section": "",
    "text": "图 17.1 展示了对温度和臭氧水平之间的进一步研究.\n\n\n代码\nlibrary(ggplot2)\n\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n\n\n\n\n\n\n\n图 17.1: 温度和臭氧水平\n\n\n\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- data.frame(Name = c(\"Alice\", \"Bob\", \"Charlie\"), Age = c(25, 30, 35))  \nkable(df)\n\n\n\n\n表格 17.1: 年龄分布\n\n\n\n\n\n\nName\nAge\n\n\n\n\nAlice\n25\n\n\nBob\n30\n\n\nCharlie\n35",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>测试脚本</span>"
    ]
  }
]