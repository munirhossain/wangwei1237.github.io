[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "",
    "text": "欢迎阅读\nIntroduction to Probability and Statistics for Engineers and Scientists (Sixth Edition) 是一本为工程师和科学家而作的有关概率论和数理统计方面的书籍。\n本书的第六版继续展示了如何应用概率论来洞察现实生活中的统计问题。与之前的版本一样，本书精心设计的概率论相关的内容将真实现象的概率模型和其统计程序关联起来，以便读者能够更直观的理解实践工程师和科学家最常用的统计程序和策略。\n本书是为工程学、计算机科学、数学、统计学和自然科学专业的学生编写的统计学和概率统计入门课程。当然，科学家、工程师和其他专业人员也可以从本书中找到灵感。",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "index.html#翻译进度",
    "href": "index.html#翻译进度",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "翻译进度",
    "text": "翻译进度\n2/16..............",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "index.html#版权声明",
    "href": "index.html#版权声明",
    "title": "Introduction to Probability and Statistics for Engineers and Scientists（中文版）",
    "section": "版权声明",
    "text": "版权声明\n本翻译稿是笔者在阅读原书过程中的笔记，采用“保持署名—非商用”创意共享 4.0 许可证。只要保持署名和非商用，您可以自由地阅读、分享本书。\n您可以：\n\n下载、保存以及打印本翻译稿\n网络链接、转载本翻译稿的部分或者全部内容，但是必须在明显处提供读者访问本翻译稿发布网站的链接\n\n您不可以：\n\n以任何形式出售本翻译稿的电子版或者打印版\n擅自印刷、出版本翻译稿\n以纸媒出版为目的，改写、改编以及摘抄本翻译稿的内容",
    "crumbs": [
      "欢迎阅读"
    ]
  },
  {
    "objectID": "preface_17.html",
    "href": "preface_17.html",
    "title": "译者序",
    "section": "",
    "text": "翻译稿中的样式惯例\n在翻译稿中，遵循以下的排版约定：",
    "crumbs": [
      "译者序"
    ]
  },
  {
    "objectID": "preface_17.html#翻译稿中的样式惯例",
    "href": "preface_17.html#翻译稿中的样式惯例",
    "title": "译者序",
    "section": "",
    "text": "斜体：表示英文术语、URL、电子邮件地址、文件名、文件扩展名。\n固定宽度：用于程序列表、段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。\n粗体：突出显示重要文本和中文术语。\n\n\n\n\n\n\n笔记\n\n\n\n该部分内容是原书中没有的内容，是笔者在阅读过程中补充的相关资料和笔者的个人理解。",
    "crumbs": [
      "译者序"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "序言",
    "section": "",
    "text": "本书的组织结构和内容范围\n1  统计学简介 对 统计学 进行了简要介绍，介绍了 统计学 的两大分支：描述统计、推论统计，然后介绍了 统计学 的一小段历史和为当今统计学的发展奠定基础的先驱人物。\n2  描述统计 的主要内容是 描述统计。本章介绍了描述数据集的图表，以及用于总结数据集某些关键属性的统计量（quantities）。\n3  Elements of probability 的内容主要是概率实验，事件概率的基本概念，概率的相关公理。我们必须了解数据的来源，以从数据中得出结论。例如，我们通常假设，数据是从某个群体中抽取的 “随机样本”。为了准确理解这样的假设意味着什么，也为了准确理解将样本数据的属性与总体的属性联系起来会产生什么结果，我们有必要了解一些概率知识。\n4  Random variables and expectation 将继续研究概率，本章会进一步介绍随机变量（random variables）和期望（expectation）等重要概念。\n5  Special random variables 会介绍应用中经常出现的一些特殊类型的随机变量，包括：二项分布、泊松分布、超几何分布、正态分布、均匀分布、伽马分布、卡方分布、\\(t\\) 分布和 \\(F\\) 分布……\n6  Distributions of sampling statistics 会研究样本均值（mean）和样本方差（variance）等抽样统计数据的概率分布。本章将介绍如何使用显著概率理论结果（中心极限定理）来近似样本均值的概率分布。此外，在某些重要的特殊场景下，当抽样的数据来自符合正态分布的总体时，本章也给出了样本均值和样本方差的联合概率分布。\n7  Parameter estimation 介绍了如何使用数据来估计感兴趣的参数。例如，科学家可能想要确定受到酸雨影响的中西部湖泊的比例。本章会研究两种参数估计方法。第一种估计方法用一个数字来估计感兴趣的统计量（例如，中西部湖泊中有 47% 的湖泊受到了酸雨的影响）。第二种则是以一个数值区间的形式来估计总体参数的范围（例如，中西部湖泊中有 45% ~ 49% 的湖泊受到了酸雨的影响）。第二种估计方法还告诉我们对其估计结果的 “置信水平”（level of confidence）。例如，尽管我们并不能肯定 47% 就是受影响的湖泊的确切比例，但我们很可能有 95% 的信心认为实际受影响的湖泊比例在 45% ~ 49% 之间。\n8  Hypothesis testing 介绍了统计假设检验这一重要内容，该部分关注的是利用数据来检验特定假设的合理性。例如，假设检验可能会拒绝 “中西部受酸雨影响的湖泊少于 44%” 这样的假设。本章引入了 \\(p\\) 值的概念来衡量在观察到数据后假设的合理性程度。本章还会介绍关于一个和两个正态总体参数的各种假设检验方法，以及关于伯努利分布和泊松分布的参数的假设检验。\n9  Regression 会涉及 回归（regression） 这个重要的课题。简单线性回归（包括平均数回归、残差分析、加权最小二乘法等）和多元线性回归的内容都将在本章中进行介绍。\n10  Analysis of variance 介绍了方差分析。本章具体介绍了一维方差分析（one-way analysis of variance）和二维方差分析（two-way analysis of variance）。\n11  Goodness of fit tests and categorical data analysis 关注的是拟合优度检验（goodness of fit tests）。拟合优度检验可以用来检验所提出的模型是否与观察到的数据一致。在本章中，我们介绍了经典的卡方拟合优度检验（Chi-squared goodness of fit test），并将其应用于检验列联表（contingency tables）中变量的独立性。本章的最后一节介绍了可用于检验数据是否来自特定连续概率分布的 Kolmogorov-Smirnov 检验方法。\n12  Nonparametric hypothesis tests 涉及到非参数假设检验，当我们无法假设潜在的数据分布具有某种特定的参数形式（如正态分布）时，可以使用非参数假设检验。\n13  Quality control 主要考虑质量控制（quality control）这一主题。质量控制是制造和生产过程中的一项关键统计技术。本章会介绍多种控制图，不仅包括 Shewhart 控制图，还包括基于 移动平均（Moving Averages） 和 累积和（Cumulative Sums）的更复杂的控制图。\n14  Life testing 介绍了与寿命测试相关的问题。在寿命测试中，起关键作用的不是正态分布，而是指数分布。\n15  Simulation, bootstrap statistical methods, and permutation tests 介绍了 bootstrap 统计方法和排列检验（permutation tests）的统计推断技术。本章首先介绍了如何通过模拟（simulation）获得概率，然后介绍了如何在这些统计推断方法中使用模拟。\n16  Machine learning and big data 是本书第 6 版中新增的内容，本章介绍了机器学习和大数据的相关技术。当拥有较大的数据量时，我们可以使用机器学习和大数据技术在无需假设任何特定概率模型下来估计概率。例如，我们想要估计一个由向量 \\((x_1, ..., x_n)\\) 表示的实验成功的概率。当该特征向量是对自然属性（qualitative in nature）（例如，动物的分类）的描述时，可以使用朴素贝叶斯方法和最近邻规则等技术。当特征向量的是量化数据（quantitative）（例如身高、体重）时，我们还研究了逻辑回归模型。\n本书的第六版不但新增了 16  Machine learning and big data ，最重要的变化是引入了统计软件 R。我们会在书中介绍 R 的使用方法，因此没有 R 使用经验的读者也无需担心。除此之外，我们还新增了 2.7 洛伦兹曲线和基尼系数 来讨论 洛伦兹曲线（Lorenz Curves）和 基尼指数（Gini Index）。第六版还增加了很多新的示例和问题。为了进一步提高本书文本表述和论证的清晰度，该版本对书中很多内容作了些许调整。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "preface.html#补充材料",
    "href": "preface.html#补充材料",
    "title": "序言",
    "section": "补充材料",
    "text": "补充材料\n可以从 https://educate.elsevier.com/book/details/9780128243466 处获取教师解答手册。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "preface.html#致谢",
    "href": "preface.html#致谢",
    "title": "序言",
    "section": "致谢",
    "text": "致谢\n感谢对第六版的内容提出有益意见的人们：\n\nGideon Weiss, University of Haifa\nN. Balakrishnan, McMaster University\nMark Brown, Columbia University\nRohitha Goonatilake, Texas A and M University\nSteve From, University of Nebraska at Omaha\nSubhash Kochar, Portland State University\nSumona Mondal, Mathematics, Clarkson University\nKamel Belbahri, Mathematics and Statistics, Université de Montréal\nAnil Aswani, Industrial Engineering and Operations Research, University of California, Berkeley\n\n对于希望保持匿名的所有审稿人，也在此表示感谢。",
    "crumbs": [
      "序言"
    ]
  },
  {
    "objectID": "chapter_1/1.html",
    "href": "chapter_1/1.html",
    "title": "1  统计学简介",
    "section": "",
    "text": "1.1 引言\n如今，人们普遍接受了这样的事实：为了了解某个事物，我们必须首先收集和该事物相关的数据。统计学（Statistics）是一门从数据中学习的艺术，它包括数据的收集，也包括通过后续的数据描述和数据分析来获得结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_2",
    "href": "chapter_1/1.html#sec-1_2",
    "title": "1  统计学简介",
    "section": "1.2 数据收集和描述统计",
    "text": "1.2 数据收集和描述统计\n\n\n\n\n\n\n描述统计\n\n\n\n描述统计（descriptive statistics）是统计学的一个重要分支，另一个重要的分支是 章节 1.3 中介绍的 推断统计（Inferential statistics）。\n描述统计 主要关注于数据的收集、处理、汇总、图表描述、概括与分析，包括统计数据的收集方法、数据的加工处理方法、数据的显示方法、数据的分布特征与分析方法等。描述统计 的目的是将数据转化为有意义的信息，并帮助我们理解数据的特征和规律。常见的 描述统计 包括直方图、平均数、中位数、众数等。\n推断统计 主要关注如何利用样本数据来推断总体特征，包括参数估计（例如平均数、标准差的估计）和假设检验两种类型。推断统计 允许我们根据部分数据来推断总体特征，从而提高研究的效率和准确性。常用的 推断统计 包括置信区间、t 检验、方差分析等。\n描述统计 是统计学的基础，其主要处理样本数据；而 推断统计 则是描述统计的升华，其利用样本数据来推测总体特征。\n\n\n有时候，我们会从一个给定的数据集合为起点来启动统计分析：例如，政府会定期收集和公布相关年份的降水量、地震发生次数、失业率、国内生产总值以及通货膨胀率。我们可以使用 统计学 来描述、总结并分析如上的数据。\n在有些场景下，我们可能还没有可用于分析的数据，此时需要利用统计理论来设计合适的实验以生成分析所需的数据。实验方案的选择取决于我们如何使用这些数据。\n\n\n教学方式的实验\n\n对于计算机编程课而言，假设一名老师想要确定哪种教学方法对初学者更好。\n\n为了研究这个问题，该老师可以把学生分成两组，然后针对不同组的学生采用不同的教学方法。在课程结束时，对学生的学习效果进行测试，并比较不同分组的学生成绩。如果其中一组学生的成绩明显高于另一组，那么我们假定该组使用的教学方法更优越的想法就更为合理。\n\n然而，为了从数据中得出有效的结论，对学生进行分组的方式至关重要，分组时应确保两组学生的编程资质是一致的。这一点，我们我们需要特别关注。我们不应该将男生分为一组，而把女生分为另一组。如果按照性别分组，即使女生组的测试成绩明显高于男生组，我们也无法确定成绩差异是源自教学方法的不同，还是因为女性在学习编程技能方面可能更具天赋。为了避免这个陷阱，我们可以 随机 把学生分成两组。“随机” 这个词意味着分组的方式应确保每个学生有同等的机会被分配到不同的组。\n在实验的最后，我们应该对数据进行描述（例如，两个分组的测试成绩）。此外，我们还应呈现数据的汇总指标（例如，不同分组的平均成绩）。在 统计学 中，涉及数据描述和数据汇总的部分称之为 描述统计。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_3",
    "href": "chapter_1/1.html#sec-1_3",
    "title": "1  统计学简介",
    "section": "1.3 推断统计和概率模型",
    "text": "1.3 推断统计和概率模型\n当我们完成了 章节 1.2 中所述的、教学方式的实验，并对实验数据进行了描述和汇总后，我们希望可以得出哪种教学方法更好的结论。在 统计学 中，涉及到得出结论的这一部分称之为 推断统计。\n为了能够从数据中得出结论，我们必须考虑偶然事件发生的可能性。例如，对于 章节 1.2 中提到的教学方式的实验，假设第一组学生的平均成绩稍高于第二组，我们能断定成绩的增加是因为教学方法吗？或者是否存在这种可能：教学方法并不是成绩增加的原因，第一组学生的成绩较高只是偶然发生的？例如，抛 10 次硬币，其中有 7 次正面朝上，这并不意味着在以后的实验中，这枚硬币正面朝上的概率会高于反面朝上。实际上，这枚硬币可能只是一枚普通的硬币，只是碰巧在10 次抛掷中出现了 7 次正面朝上。（另一方面，如果在 50 次抛掷中出现了 47 次正面朝上，那么我们就可以非常确定这不是一枚普通硬币。）\n为了从数据中得到正确的结论，我们通常会对可以获取到的、不同数据的可能性（或概率）做某些假设。这些假设的总和称之为数据的 概率模型。\n有时，数据的性质（nature）暗含了我们所假设的 概率模型 的形式。例如，假设一名工程师想要了解使用新的生产方式生产的计算机芯片的缺陷率。该工程师可能会从新生产方式生产的芯片中选择一组芯片，然后可以得到所抽取的这组芯片中的缺陷芯片数量。只要这组芯片是 “随机” 选择而产生的，那么假设这组芯片中的每一个芯片存在缺陷的概率为 \\(p\\) 就是合理的，其中 \\(p\\) 是使用新方法生产的所有芯片的缺陷率。因为我们无法抽查所有芯片以获得 \\(p\\)，因此 \\(p\\) 是未知的，我们可以用“随机”抽取的芯片所得到的数据来推断 \\(p\\)。\n在其他情况下，概率模型 在给定数据集上的表现并不明显。然而，对数据的仔细描述和呈现有时能帮助我们推断出合理的 概率模型，然后我们可以使用其它的数据来验证推断的 概率模型。\n统计推断 的基础是通过构建 概率模型 来描述数据，因此需要具备一定的概率论基础才能理解 统计推断。换句话说，统计推断 源自这样的假设：我们可以用概率来描述研究对象，然后我们可以基于该假设通过数据来推断这些概率，从而得出结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#sec-1_4",
    "href": "chapter_1/1.html#sec-1_4",
    "title": "1  统计学简介",
    "section": "1.4 总体与样本",
    "text": "1.4 总体与样本\n在 统计学 中，我们对获取研究对象中的所有个体的集合的信息感兴趣。研究对象中所有个体的集合我们称之为 总体。总体 的规模往往太大，所以我们无法检查 总体 中的每个成员。例如，我们可能有某个州的所有居民数据，或者某个制造商去年生产的所有电视机数据，亦或者某个社区的所有家庭数据。在这些情况下，我们试图通过选择总体元素的一个子分组并对该子分组进行检查来了解 总体，这个子分组我们称其为 样本。\n如果 样本 需要提供有关 总体 的信息，那么，在某种意义上而言，样本 必须具有代表性。\n\n\n市民的平均年龄\n\n假设我们对某市居民的年龄分布感兴趣，并且我们获得了进入城镇图书馆（town library）的前 100 个市民的年龄。如果这 100 人的平均年龄为 46.2 岁，我们是否可以依次为依据得出结论：该市居民的平均年龄为 46.2 岁？\n\n可能并非如此。当然，我们可以认为，在这种情况下选择的 样本 可能并不能代表 总体，因为通常而言，年轻学生和老年市民去图书馆的可能性要大于上班族。\n\n\n\n\n\n\ntown library\n\n\n\n在美国，“town library” 是指位于城镇内的公共图书馆。这些图书馆由城镇或地方政府资助，为当地社区提供各种书籍、资料和服务。城镇图书馆通常提供免费的借阅服务，包括书籍、期刊、报纸、音像资料等，并提供学习空间、研究帮助、电脑和互联网接入等资源。它们也可能举办各种活动和课程，以满足社区居民的教育、文化和娱乐需求。\n\n\n在某些情况下，我们得到了一个 样本，然后我们必须判断该 样本 是否能够代表 总体，例如如上的市民平均年龄的示例。在实践中，如果样本不是以“随机“的方式进行选择，那么通常不能假定给定的 样本 可以代表 总体。任何特定的、非随机的抽样规则往往会导致 样本 对某些数据存在固有的偏好，这也意味着会天然的反对另外的数据。\n因此，对于待选择的个体而言，在没有任何先验知识的情况下，通过完全”随机“的方式来选择 样本，我们更有可能获得有代表性的 样本。尽管这听起来可能有些矛盾，但这确实如此。换句话说，我们不需要刻意选择样本，以便 样本 中的人的性别比例和职业比例与 总体 是一致的。相反，我们应该把 样本 的特性留给 “可能性” 或者 ”概率“，以获得大致正确的百分比。一旦选好了随机样本，我们就可以通过研究 样本 并使用 统计推断 来得出和 总体 有关的结论。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#统计学简史",
    "href": "chapter_1/1.html#统计学简史",
    "title": "1  统计学简介",
    "section": "1.5 统计学简史",
    "text": "1.5 统计学简史\n在文艺复兴时期，意大利的威尼斯和佛罗伦萨开始对人口和经济方面的数据进行系统化的收集。统计学（statistics） 一词来源于国家（state）这个单词，通常用来描述和国家有关的数据收集。这种收集数据的想法不断从意大利传播到西欧的其他国家。事实上，在 16 世纪上半叶，欧洲国家的政府普遍要求教区居民登记出生、婚姻和死亡情况。由于公共卫生条件差，政府尤其关注居民登记的死亡信息统计。\n\n\n\n\n\n\nstatistics 一词的来源\n\n\n\n在 Statistics, History of 这篇论文中，作者提到了 statistics 一词的来源。\n\nIt is widely believed that the term statistics originated from the Latin Status (situation, condition) of population and economics; in late Latin, the same term meant State. Another root of the term comes from the Italian word stato (state), and a statista (a person who deals with affairs of state).\nAccording to Kendall (1960:447) the first use of the word statistics “occurs in a work by an Italian historian Girolamo Ghilini, who in 1589 refers to an account of civile, politica, statistica e militare scienza.”\n\n\n\n19 世纪之前，欧洲的高死亡率主要源自流行病、战争和饥荒。对于流行病而言，最严重的是瘟疫。从 1348 年的黑死病开始，瘟疫在近 400 年的时间里频繁在欧洲发生。1562 年，为了让英国的王室成员意识到需要搬迁到乡下，伦敦市开始每周公布死亡人数。最初，这些死亡人数的清单中会列出死亡地点以及是否因瘟疫而死亡。从 1625 年开始，该清单中的信息扩展到所有的死亡原因。\n1662 年，英国商人 John Graunt 出版了一本名为 Natural and Political Observations Made upon the Bills of Mortality 的书。表格 1.1 摘录了该书中所列出的英格兰五个不同瘟疫年份的总死亡人数和因瘟疫死亡的人数。\n\n\n\n表格 1.1: 不同年份的英格兰死亡人数表\n\n\n\n\n\n年份\n死亡人数\n瘟疫致死人数\n\n\n\n\n1592\n25,886\n11,503\n\n\n1593\n17,844\n10,662\n\n\n1603\n37,294\n30,561\n\n\n1625\n51,758\n35,417\n\n\n1636\n23,359\n10,400\n\n\n\n\n\n\nGraunt 利用伦敦的死亡人数来估算该市的人口总数。例如，为了估算 1660 年伦敦的人口，Graunt 对伦敦某些教区 (或社区) 家庭进行了调查，并发现平均每 88 人中大约有 3 人死亡。这意味着平均每 88/3 个人就会有 1 个人死亡。伦敦的死亡人数清单显示 1660 年伦敦有 13200 人死亡，所以 Graunt 估计当年伦敦的人口大约为：\n\\[\n13200 × 88/3 = 387200\n\\]\nGraunt 利用这种估计方法来预测整个英格兰的人口数量。他在书中指出，政府会对这些数据感兴趣，因为这些数据可以作为应征入伍人数和应纳税人数的指标。\nGraunt 还利用伦敦的死亡人数清单，以及关于何种疾病会导致何人、在什么年龄死亡的一些合理猜测，来推断死亡年龄。(回想一下，前面提到的死亡人数清单只列出了死亡原因和地点，其并没有列出死者的年龄。) 然后，格兰特利用这些信息计算出不同年龄段的死亡人口比例。表格 1.2 是 Graunt 计算的死亡率表之一。例如，表格 1.2 指出，在 100 名新生儿中，有 36 人将在 6 岁之前死亡，24 人将在 6~15 岁之间死亡，……\n\n\n\n表格 1.2: John Graunt 的死亡率表\n\n\n\n\n\n死亡年龄\n每 100 新生儿中的死亡人数\n\n\n\n\n0-6\n36\n\n\n6-16\n24\n\n\n16-26\n15\n\n\n26-36\n9\n\n\n36-46\n6\n\n\n46-56\n4\n\n\n56-66\n3\n\n\n66-76\n2\n\n\n&gt;=76\n1\n\n\n\n\n\n\n从事 年金 行业的人对 Graunt 的死亡年龄表非常感兴趣。年金 与人寿保险不同，人们会一次性支付一笔款项作为投资，然后在有生之年定期从 年金 中获得收益。\n\n\n\n\n\n\n年金\n\n\n\n年金（annuity）是一种金融产品，通常由保险公司或金融机构提供。年金是一种长期投资工具，旨在为购买者提供一定期间内的收入。购买者通常向保险公司或金融机构支付一笔或多笔资金，而作为回报，购买者将在未来的一段时间内获得一定的收益。\n\n\n受到 Graunt 死亡率表的启发，1693 年，Edmund Halley 又做了更进一步的工作。Halley 是哈雷彗星的发现者（同时，Halley 也是对《自然哲学的数学原理》一书的出版贡献最大的人，他不但鼓励牛顿把自己的发现编写成书，更是为该书的出版提供了资金支持），他利用死亡率表来计算任何年龄段的人活到任何特定年龄的概率。Halley 说服了当时的保险公司，让他们相信年度人寿保险保费应该取决于被保险人的年龄。\n继 Graunt 和 Halley 之后，从 17 世纪末到 18 世纪，对数据的收集呈现稳步增长的趋势。例如，1667年，巴黎开始收集死亡人数清单；到 1730 年时，在欧洲，记录死亡年龄已成为一件非常普遍的事情。\n18 世纪之前，“statistics” 这个词被用作对国家或地区进行描述性分析的科学方法的简称。从 1800 年左右开始，西欧国家和美国政府开始系统地收集和公布类似的人口普查数据，这积累了大量的、可用的人口普查记录和相关的表格数据，这也导致了 “statistics” 一词在含义上发生了变化。19 世纪时，“statistics” 越来越多地与数字联系在一起，到 19 世纪 30 年代，在英国和法国，人们普遍将 “statistics” 一词与社会“数字科学”（numerical science）视为同等含义。\n贯穿整个 19 世纪，在 Jacob Bernoulli、Karl Friedrich Gauss 和 Pierre Simon Laplace 等数学家的推动下，尽管 概率论 已经发展起来，但在研究统计结果方面，概率论 几乎没有任何应用。此中的原因在于，当时的大多数社会统计学家都满足于让数据自己说话。特别是，当时的统计学家对个体推断并不感兴趣，他们更关心整个社会。因此，在当时，统计学家并不关心抽样，而是试图获得全部的人口普查数据。因此，在 19 世纪的社会统计学中，通过样本来推断总体概率的事情几乎没有发生过。\n直到 19 世纪末，统计学才开始关注如何从数值数据中推断结论。推断统计 这一运动始于 Francis Galton 关于 遗传天才 的分析工作，在这项分析中， Francis Galton 使用了我们现在所说的回归分析和相关性分析（章节 9）。Francis Galton 的工作极大的推动了 Karl Pearson 为统计学所做的贡献。Karl Pearson 是卡方检验（章节 11）的发明者，也是由 Francis Galton 于1904 年资助建立的高尔顿实验室的第一任负责人。在高尔顿实验室，Karl Pearson 发起了一个旨在发明一种用统计数据进行推断的新方法的研究项目。Pearson 邀请科学和工业领域的高年级学生到实验室来学习统计方法，然后将对应的方法应用于各自的领域。化学家 W.S. Gosset 是高尔顿实验室最早的访问学者之一，他以 “Student” 的名义出版了自己的研究发现，并以此表达了对皮尔逊的敬意。（有一个比较有名的故事是说，Gosset 害怕他所在的吉尼斯酿酒厂的老板在发现他们的一位化学家正在做统计学研究时会不高兴，因此不敢以自己的名义出版著作）。Gosset 因为他所发明的 t 检验而名声大振（章节 8）。\n20 世纪初，群体生物学（population biology）和农业是应用统计学的两个最重要的领域。统计学这这些领域的应用主要源自 Pearson 和他的实验室的其他人的研究，也源自英国科学家 Ronald A. Fisher 在统计学中的显著成就。在如上所介绍的先驱者以及其他研究者（例如， Karl Pearson 的儿子 Egon 和出生于波兰的数理统计学家 Jerzy Neyman 等）的推动下，他们所发明的推理理论已经通用到可以处理广泛的量化问题和实践问题。因此，在 20 世纪初之后的几年里，越来越多的科学家、商人和政界人士开始将统计学视为能够为科学问题和实践问题提供定量解决方案的工具（见 表格 1.3）。\n\n\n\n表格 1.3: Statistics 定义的变化\n\n\n\n\n\n\n\n\n\n时间\n定义\n\n\n\n\nQuetelet, 1849\nStatistics has then for its object that of presenting a faithful representation of a state at a determined epoch.\n\n\nGalton, 1889\nStatistics are the only tools by which an opening can be cut through the formidable thicket of difficulties that bars the path of those who pursue the Science of man.\n\n\nFisher, 1925\nStatistics may be regarded (i) as the study of populations, (ii) as the study of variation, and (iii) as the study of methods of the reduction of data.\n\n\nE. Pearson, 1936\nStatistics is a scientific discipline concerned with collection, analysis, and interpretation of data obtained from observation or experiment. The subject has a coherent structure based on the theory of Probability and includes many different procedures which contribute to research and development throughout the whole of Science and Technology.\n\n\nWeaver, 1952\nStatistics is the name for that science and art which deals with uncertain inferences — which uses numbers to find out something about nature and experience.\n\n\nPorter, 1986\nStatistics has become known in the 20th century as the mathematical tool for analyzing experimental and observational data.\n\n\nthis book, 2020\nStatistics is the art of learning from data.\n\n\n\n\n\n\n如今，统计学的思想无处不在。在每一份报纸和杂志上，描述统计学 的特点都有所体现。在公共卫生、医学研究、工程研究、科学研究、市场营销、质量控制、教育、会计、经济、气象预报、投票和调查、体育、保险、赌博以及所有声称是科学的研究领域，统计推断 都是不可或缺的。的确，统计学已经深深植根于人类的知识遗产（intellectual heritage）之中。\n\n\n\n\n\n\n知识遗产\n\n\n\n知识遗产（intellectual heritage）是指社会所拥有的知识、思想、传统、技能和价值观的集合，这些资源被传承下来并世代相传。知识遗产包括各种形式的人类智慧，如文学作品、艺术品、哲学理论、科学发现、宗教信仰、法律体系、技术创新等。知识遗产不仅仅是一种资产，更是一种社会、文化和历史的遗产，它反映了人类的智慧、经验和创造力，对于塑造社会的认同感、价值观和意识形态具有重要意义。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_1/1.html#问题",
    "href": "chapter_1/1.html#问题",
    "title": "1  统计学简介",
    "section": "问题",
    "text": "问题\n\n下周将举行选举，我们试图通过对总体选民进行抽样来预测共和党候选人或民主党候选人谁会获胜。以下哪种抽样方法可能产生有代表性的样本？\n\n\n对参加大学篮球比赛的所有达到投票年龄的人进行民意调查。\n\n\n对去市中心一家高档餐厅用餐的所有达到投票年龄的人进行民意调查。\n\n\n获取一份选民登记名单，随机选择100个名字，并对他们进行提问。\n\n\n使用电视台的电话投票民意调查结果，电视台会要求听众打电话进来并说出他们的选择。\n\n\n从电话簿中选择名字，并给这些人打电话。\n\n\n在1936年的美国总统竞选中，第 1 题的 (e) 选项使用的方法导致了及其糟糕的预测结果。在那次竞选中，富兰克林·罗斯福以压倒性优势击败了阿尔弗雷德·兰登。该杂志从汽车用户和电话用户名单中抽取选民样本，基于对这些选民的调研，Literary Digest 杂志预测兰登会获胜。\n\n\n你认为 Literary Digest 杂志的预测为何如此离谱？\n\n\n从 1936 年到现在，有没有什么变化让你相信 Literary Digest 杂志使用的方法在今天会更有效？\n\n\n一位研究人员正试图发现当今美国人死亡时的平均年龄。为了获得数据，研究人员阅读了 30 期的《纽约时报》的讣告专栏，并记录了美国人的死亡年龄。你认为这种方法会得到一个有代表性的样本吗？\n为了确定镇上吸烟者的比例，现决定在当地的以下地点之一进行民意调查。这些民意调查地点中，哪一个最有可能得出合理的结果？为什么？\n\n\n台球厅\n\n\n保龄球馆\n\n\n购物中心\n\n\n图书馆\n\n\n一所大学计划对其近期毕业的学生进行调查，以确定他们的年薪信息。该学校随机选择了 200 名近期要毕业的学生，并向他们发送了和他们目前工作有关的调查问卷。然而，在这 200 人中，只有 86 人返回了问卷。假设这返回的 86 份问卷显示的平均年薪为 75000 美元。\n\n\n该学校认为 75000 美元是所有毕业生平均工资水平的比较好的近似值，这种想法对吗？解释你的回答背后的理由。\n\n\n如果你对 (a) 的回答是否定的，你能想到，在什么条件下，返回的问卷所显示的工资水平将会是一个不错的毕业生平均工资水平的近似值？\n\n\n一篇文章报道称，对夜间交通事故中丧生的行人所穿衣服的调查显示，约 80% 的受害者穿着深色衣服，20% 的受害者穿着浅色衣服。文章得出的结论是，晚上穿浅色衣服更安全。\n\n\n这个结论合理吗？请解释下你的回答。\n\n\n如果你对 (a) 的回答是否定的，那么在得出最终结论之前，还需要什么其他信息？\n\n\n如何评判 Graunt 估算伦敦人口的方法？他的方法是有什么隐含的假设？\n1658 年，伦敦的死亡率清单记录了 12246 人死亡。假设对伦敦教区的调查显示，该年的人口死亡率大约为 2%，使用 Graunt 的方法来估算 1658 年伦敦的人口总数。\n1662 年，当 Graunt 的书出版时，假设你是一名年金销售员。解释一下，你将如何利用 Graunt 给出的关于人们死亡年龄的数据。\n基于 Graunt 的死亡率表（表格 1.2）：\n\n\n活到 6 岁的人的占比是多少？\n\n\n活到 46 岁的人的占比是多少？\n\n\n死于 6 岁到 36 岁之间的人的占比是多少？",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>统计学简介</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html",
    "href": "chapter_2/2.html",
    "title": "2  描述统计",
    "section": "",
    "text": "2.1 引言\n本章将介绍 描述统计 的相关内容，在介绍 描述统计 的过程中，我们将学习如何描述和总结数据。\n章节 2.2 会讨论如何描述数据集。如果一个数据集中的数据差异相对较小，章节 2.2.1 和 章节 2.2.2 介绍了如何使用 频率表（frequency tables）来描述这样的数据集，章节 2.2.3 则介绍如何将数据集划分到不同的分组。\n章节 2.3 讨论了如何使用统计指标来总结数据集，统计指标往往是由数据集确定的量化数值。章节 2.3.1 介绍了用于描述数据集中心（center）的三个统计指标：样本均值（sample mean）、样本中位数（sample median）和样本众数（sample mode）。章节 2.3.2 会介绍样本方差（sample variance）及样本标准差（sample standard deviation）。样本均值、样本中位数、样本众数、样本方差和标准差这些统计数据用于描述数据集中数值的分布。章节 2.3.3 会介绍样本的百分位数（sample percentiles），样本百分位数这个统计指标可以告诉我们数据集中哪个值大于所有数据的 95%。\n章节 2.4 节介绍了数据样本集中的切比雪夫不等式（Chebyshev’s inequality），切比雪夫不等式给出了与样本均值相差超过 \\(k\\) 倍样本标准差的数据比例的上限。虽然切比雪夫不等式适用于所有数据集，但在某些情况下（例如 章节 2.5 中讨论的正态分布数据集），我们可以获得更精准的数据比例。\n在 章节 2.5 中，我们注意到，当数据分布符合钟形（bell-shaped）时，我们认为该数据集是近似正态的，此时，位于样本均值 \\(k\\) 个样本标准差内的数据比例可以根据所谓的经验法则（empirical rule）给出更精确的估计。\n章节 2.6 中关注的是成对数据（paired data），并介绍了如何使用散点图（scatter diagram）来描述成对数据以及样本相关系数（sample correlation coefficient）。样本相关系数是一个统计量，该值表示成对数据中第一个值与第二个值之间相关联的程度。\n章节 2.7 介绍了国民收入分配，洛伦兹曲线（Lorenz curve）（ L(p)）和基尼系数（Gini index）。洛伦兹曲线给出了收入较低的百分之 \\(p\\) 的居民收入占总收入的比例，基尼系数则是用于衡量收入分配不平等程度的指标。\n章节 2.8 介绍了如何使用 R 来分析数据集。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_2",
    "href": "chapter_2/2.html#sec-2_2",
    "title": "2  描述统计",
    "section": "2.2 描述数据集",
    "text": "2.2 描述数据集\n应当用数据清晰、简洁的显示研究结果，以便研究者可以迅速把握数据的关键特征。多年来，人们发现，对于展示数据而言，表格和图是特别有用的方式。图表常常可以揭示数据的重要特征，如数据的范围、集中程度和对称性。本节将介绍一些常见的数据图表展示方式。\n\n2.2.1 频率表和图\n如果一个数据集中的数据差异较小，我们便可以以频率表（frequency table）的形式来方便的展现该数据集。例如，表格 2.1 就是一个数据集的频率表，该数据集由 42 名最近毕业的电子工程专业的大学生的起始年薪（以千美元为单位，四舍五入）构成。表格 2.1 告诉我们，最低起薪为 57000 美元，并且有四名毕业生的起薪为 57000 美元；最高起薪为 70000 美元，并且有一名学生的起薪为 70000 美元；最为普遍的起薪为 62000 美元，并且有 10 名学生拿到了 62000 美元的起薪。\n\n\n代码\nlibrary(knitr)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ndf &lt;- data.frame(\"Starting Salary\" = ss, \"Frequency\" = f)\nkable(df, align = \"l\")\n\n\n\n\n表格 2.1: 起薪分布\n\n\n\n\n\n\nStarting.Salary\nFrequency\n\n\n\n\n57\n4\n\n\n58\n1\n\n\n59\n3\n\n\n60\n5\n\n\n61\n8\n\n\n62\n10\n\n\n63\n0\n\n\n64\n5\n\n\n66\n2\n\n\n67\n3\n\n\n70\n1\n\n\n\n\n\n\n\n\n可以用线图（line graph）来直观地显示频率表中的数据。如 图 2.1，在线图中，水平坐标轴用于绘制不同的数据值，而垂直直线的高度用于表示对应数据值出现的频率。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value_end = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1),  \n  value_start = rep(0, 11) \n)  \n\n# 将类别转换为因子，以确保正确的顺序  \ndf$salary &lt;- factor(df$salary, levels = df$salary, ordered = TRUE)  \n \nggplot(df, aes(x = salary, y = value_start, yend = value_end, color = salary)) +  \n  geom_segment(size = 2) +                    # 绘制水平线表示每个“条形”  \n  geom_point(aes(y = value_end), size = 3) +  # 在每个“条形”的末端添加点  \n  theme_minimal() +  \n  labs(x = \"Starting Salary\", y = \"Frequency\") +  \n  scale_y_continuous(breaks = seq(1, 10, by = 1)) +  \n  theme(legend.position = \"none\")           # 调整图例位置\n\n\n\n\n\n\n\n\n图 2.1: 起薪线图\n\n\n\n\n\n当为 图 2.1 中的线条增加厚度时，图 2.1 就变成了 图 2.2 所示的条形图（bar graph）。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\n)  \n\n# 将类别转换为因子，以确保正确的顺序  \ndf$salary &lt;- factor(df$salary, levels = df$salary, ordered = TRUE)  \n \nggplot(df, aes(x = salary, y = value)) +  \n  geom_bar(stat = \"identity\", fill = \"steelblue\") +  \n  theme_minimal() +  \n  xlab(\"Starting Salary\") +  \n  ylab(\"Frequency\") +\n  scale_y_continuous(breaks = seq(1, 10, by = 2))\n\n\n\n\n\n\n\n\n图 2.2: 起薪条形图\n\n\n\n\n\n另一种用于表示频数表的图形是折线图（frequency polygon），在折线图中，对于在数据集中出现的不同的数据值，其出现的次数为纵坐标，以此画出对应的点，然后用直线将这些点依次连接起来。图 2.3 给出了 表格 2.1 对应的折线图。\n\n\n代码\nlibrary(ggplot2)  \n\ndf &lt;- data.frame(  \n  salary = c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70),  \n  value = c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\n)  \n\nggplot(df, aes(x=salary, y=value)) +   \n  geom_line() +  \n  labs(x=\"Starting Salary\", y=\"Frequency\") + \n  scale_y_continuous(breaks = seq(1, 10, by = 2)) + \n  theme_minimal()\n\n\n\n\n\n\n\n\n图 2.3: 起薪折线图\n\n\n\n\n\n\n\n2.2.2 相对频率表和图\n一个数据集中有 \\(n\\) 个值，如果 \\(f\\) 是某个特定值的频率，那么\\(\\frac{f}{n}\\) 为该特定值的相对频率（relative frequency）。也就是说，一个值的相对频率是数据集中具有该值的数据所占的比例。可以用线图、条形图、折线图来表示相对频率。事实上，在相对频率图中，除了纵坐标的值是绝对频率图中的值除以数据点总数外，相对频率图看起来和绝对频率图没什么不同。\n\n例子 2.1 表格 2.2 是 表格 2.1 的相对频率表。将 表格 2.1 中相应的频率除以数据集的大小（42） 得到其对应的相对频率表。\n\n\n\n代码\nlibrary(knitr)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ncnt = sum(f)\nf &lt;- f / cnt\n\ndf &lt;- data.frame(\"Starting Salary\" = ss, \"Relative Frequency\" = f)\nkable(df, align = \"l\")\n\n\n\n\n表格 2.2: 起薪分布相对频率表\n\n\n\n\n\n\nStarting.Salary\nRelative.Frequency\n\n\n\n\n57\n0.0952381\n\n\n58\n0.0238095\n\n\n59\n0.0714286\n\n\n60\n0.1190476\n\n\n61\n0.1904762\n\n\n62\n0.2380952\n\n\n63\n0.0000000\n\n\n64\n0.1190476\n\n\n66\n0.0476190\n\n\n67\n0.0714286\n\n\n70\n0.0238095\n\n\n\n\n\n\n\n\n当数据集中的数据不是数值型数据时，通常使用饼图（pie chart）来表示相对频率。首先画一个圆，然后将其切分成不同的扇形区域，每一个扇区对应数据集中的一种数据类型。在饼图中，扇区的面积表示数据值的相对频率，其面积等于圆的总面积乘以数据值的相对频率。\n\n例子 2.2 根据一家肿瘤专科诊所登记的最近 200 名患者的数据，得到了一个关于不同类型肿瘤患者数的数据集。图 2.4 使用饼图的形式来显示如上的数据集。\n\n\n代码\nlibrary(knitr)\n\ntype &lt;- c(\"Melanoma\", \"Bladder\", \"Colon\", \"Lung\", \"Breast\", \"Prostate\")\nnum &lt;- c(9, 12, 32, 42, 50, 55)  \nvalue &lt;- num / sum(num)\n\ndf &lt;- data.frame(\"Type of Cancer\" = type, \"Number of New Cases\" = num, \"Relative Frequency\" = value)\n\nkable(df, align = \"l\")\n\n\n\n\n\nType.of.Cancer\nNumber.of.New.Cases\nRelative.Frequency\n\n\n\n\nMelanoma\n9\n0.045\n\n\nBladder\n12\n0.060\n\n\nColon\n32\n0.160\n\n\nLung\n42\n0.210\n\n\nBreast\n50\n0.250\n\n\nProstate\n55\n0.275\n\n\n\n\n\n\n\n\n代码\nlibrary(ggplot2)\n  \n# 提供的数据  \ntype &lt;- c(\"Melanoma\", \"Bladder\", \"Colon\", \"Lung\", \"Breast\", \"Prostate\")\nnum &lt;- c(9, 12, 32, 42, 50, 55)  \nvalue &lt;- num / sum(num)\n\ndf &lt;- data.frame(type = type, num = num, value = value)\ndf$label &lt;- paste(df$type, \"\\n\", round(df$value * 100, 1), \"%\", sep=\"\") \n\n# 绘制饼图  \nggplot(df, aes(x = \"\", y = value, fill = type)) +  \n  geom_bar(width = 1, stat = \"identity\") +  \n  coord_polar(\"y\", start = 0) +  \n  theme_void() +  \n  theme(legend.title = element_blank()) +  \n  scale_fill_brewer(palette = \"Pastel1\") +  \n  labs(fill = \"type\") +  \n  geom_text(aes(label = label),   \n            position = position_stack(vjust = 0.5)) + # 添加百分比标签\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n图 2.4: 诊所数据饼图\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n虽然我们经常使用饼图，尤其是在商业分析中，饼图更是得到了广泛的使用，但是统计学家则一直很排斥使用饼图。因为人们对长度的判断比面积更为精确，因此统计学家更倾向于使用条形图。在 R 中，对饼图的支持要比其他的工具差很多。\n\n\n\n\n2.2.3 分组数据，直方图，肩形图和茎叶图\n如 章节 2.2.2 所述，使用线图或条形图绘制数据值的频率通常是描述数据集的有效方法。然而，对于那些不同数值数量太多的数据集而言，就无法使用线图或条形图的方法来对数据进行描述。在这种情况下，我们可以先将数值分组或按类别进行分类，然后绘制落在每个分组中的数据值的数量。分组数量的选取需要在以下两者之间进行取舍：\n\n较少的分组，但是将会丢失实际数据值中的很多信息；\n较多多的分组，但是将导致每个分组中的数值频率太小，以至于无法从图中辨别出数据模型。\n\n尽管典型的分组数为 5 ~ 10 个，但是适当的分组数量来自主观选择。当然，我们可以尝试不同的分组数，并对比看看哪张图表的效果最好。尽管不是必须的，但是在选择分组数时，通常会让不同分组之间的间隔长度保持一致。\n分组的端点（endpoint）称之为分组边界（class boundaries）。我们将会采用左端包含原则，该原则规定分组中的数据包含其左端点，但不包含其右端。因此，例如，20–30 这个分组包含所有 \\(\\ge\\) 20 且 \\(&lt;\\) 30 的值。\n表格 2.3 给出了 200 只白炽灯的使用寿命。表格 2.4 为 表格 2.3 数据的分组频率表，其分组的间隔长度为 100，第一个分组从 500 开始。\n\n\n代码\nlibrary(knitr)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\nkable(matrix(data, nrow = 20, ncol = 10, byrow = TRUE))\n\n\n\n\n表格 2.3: 200 个 白炽灯的寿命（Hour）\n\n\n\n\n\n\n1067\n919\n855\n1092\n1157\n1195\n1022\n978\n923\n1333\n\n\n521\n933\n930\n807\n999\n932\n901\n1324\n996\n780\n\n\n1187\n1067\n824\n653\n844\n814\n1037\n1151\n1026\n1147\n\n\n1039\n1083\n1023\n984\n1134\n932\n998\n996\n610\n916\n\n\n1196\n785\n1162\n1170\n1195\n1340\n832\n1009\n811\n1217\n\n\n928\n1153\n954\n1063\n1035\n944\n818\n1250\n900\n1106\n\n\n1118\n1037\n980\n935\n1103\n1000\n863\n990\n883\n867\n\n\n1040\n1289\n856\n924\n938\n1078\n1133\n765\n1001\n895\n\n\n1126\n936\n929\n950\n1122\n938\n1157\n1151\n1085\n896\n\n\n946\n858\n1002\n909\n1049\n940\n1203\n1078\n704\n621\n\n\n958\n760\n878\n934\n788\n1143\n1035\n1112\n990\n1258\n\n\n699\n1083\n801\n1122\n1180\n1106\n775\n1105\n709\n860\n\n\n918\n1156\n920\n948\n905\n972\n1035\n1045\n970\n1237\n\n\n956\n1102\n1009\n765\n958\n902\n958\n1311\n1037\n702\n\n\n1071\n1069\n830\n1063\n1077\n1021\n1062\n1157\n1122\n1115\n\n\n833\n1320\n890\n1303\n1011\n1102\n854\n1178\n1138\n951\n\n\n1101\n949\n992\n966\n910\n1058\n730\n980\n935\n1069\n\n\n1170\n1067\n931\n970\n932\n904\n1192\n922\n1150\n1091\n\n\n880\n1029\n658\n912\n1292\n1116\n880\n1173\n1184\n954\n\n\n824\n529\n1081\n1171\n705\n1425\n1110\n1149\n972\n1002\n\n\n\n\n\n\n\n\n\n\n代码\nlibrary(knitr)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\nintervals &lt;- seq(500, 1500, by = 100)\ngroup &lt;- cut(data, intervals, right=FALSE)\nkable(table(\"Class Interval\" = group))\n\n\n\n\n表格 2.4: 200 个 白炽灯的寿命（Hour）分布表\n\n\n\n\n\n\nClass.Interval\nFreq\n\n\n\n\n[500,600)\n2\n\n\n[600,700)\n5\n\n\n[700,800)\n12\n\n\n[800,900)\n25\n\n\n[900,1e+03)\n58\n\n\n[1e+03,1.1e+03)\n41\n\n\n[1.1e+03,1.2e+03)\n43\n\n\n[1.2e+03,1.3e+03)\n7\n\n\n[1.3e+03,1.4e+03)\n6\n\n\n[1.4e+03,1.5e+03)\n1\n\n\n\n\n\n\n\n\n分组数据的条形图中，其不同的分组彼此相邻，我们称之为直方图（histogram）。直方图的纵坐标可以表示分组的频率或相对频率，当表示分组频率时该图为频率直方图，当表示分组相对频率时为相对频率直方图。图 2.5 给出了 表格 2.4 中数据的频率直方图。\n\n\n代码\nlibrary(ggplot2)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\ndf &lt;- data.frame(value = data)\nbreaks_vector &lt;- seq(from = 500, to = 1500, by = 100)\n\nggplot(df, aes(x = value)) +  \n  geom_histogram(breaks = breaks_vector, fill = \"lightblue\", color = \"black\") +  \n  xlab(\"incandescent lamps lifetime(Hour)\") +  \n  ylab(\"Frequency\")\n\n\n\n\n\n\n\n\n图 2.5: 200 个 白炽灯的寿命（Hour）分布直方图\n\n\n\n\n\n很多时候，我们需要绘制累积频率图（cumulative frequency graph）或者累积相对频率图（cumulative relative frequency graph）。在累积频率（相对频率）图的横坐标上，一个点代表一个可能的数据值，其对应的纵坐标为值小于或等于该数据值的数据数量（或比例）。图 2.6 给出了 表格 2.3 中所示数据的累积相对频率图。从这个图中我们可以发现，使用寿命小于 1500（小时） 的白炽灯占比为 100%，使用寿命 \\(\\le\\) 900 的占比大约为 40% ，使用寿命 \\(\\le\\) 1100 的占比大约为 80%，……我们通常又把累积频率图称为肩形图（ogive）。\n\n\n代码\nlibrary(ggplot2)\n\ndata &lt;- c(1067, 919, 855, 1092, 1157, 1195, 1022, 978, 923, 1333, 521, 933, 930, 807, 999, 932, 901, 1324, 996, 780, 1187, 1067, 824, 653, 844, 814, 1037, 1151, 1026, 1147, 1039, 1083, 1023, 984, 1134, 932, 998, 996, 610, 916, 1196, 785, 1162, 1170, 1195, 1340, 832, 1009, 811, 1217, 928, 1153, 954, 1063, 1035, 944, 818, 1250, 900, 1106, 1118, 1037, 980, 935, 1103, 1000, 863, 990, 883, 867, 1040, 1289, 856, 924, 938, 1078, 1133, 765, 1001, 895, 1126, 936, 929, 950, 1122, 938, 1157, 1151, 1085, 896, 946, 858, 1002, 909, 1049, 940, 1203, 1078, 704, 621, 958, 760, 878, 934, 788, 1143, 1035, 1112, 990, 1258, 699, 1083, 801, 1122, 1180, 1106, 775, 1105, 709, 860, 918, 1156, 920, 948, 905, 972, 1035, 1045, 970, 1237, 956, 1102, 1009, 765, 958, 902, 958, 1311, 1037, 702, 1071, 1069, 830, 1063, 1077, 1021, 1062, 1157, 1122, 1115, 833, 1320, 890, 1303, 1011, 1102, 854, 1178, 1138, 951, 1101, 949, 992, 966, 910, 1058, 730, 980, 935, 1069, 1170, 1067, 931, 970, 932, 904, 1192, 922, 1150, 1091, 880, 1029, 658, 912, 1292, 1116, 880, 1173, 1184, 954, 824, 529, 1081, 1171, 705, 1425, 1110, 1149, 972, 1002)\n\ndf &lt;- data.frame(value = data)\ndf$value &lt;- df$value[order(df$value)]\ndf$cumulative_freq &lt;- cumsum(rep(1/nrow(df), nrow(df))) \n\nggplot(df, aes(x = value, y = cumulative_freq)) +  \n  geom_step(direction = \"vh\", color = \"blue\") +  \n  xlab(\"incandescent lamps lifetime\") +  \n  ylab(\"Cumulative Relative Frequency\") +   \n  theme_minimal()\n\n\n\n\n\n\n\n\n图 2.6: 200 个 白炽灯的寿命（Hour）累积频率图\n\n\n\n\n\n对于中小型数据集而言，茎叶图（stem-leaf plot）是一种有效的数据组织方式。可以把每个数据值分为茎和叶两部分来获得茎叶图。例如，如果数据都是两位整数值，那么我们可以把十位数作为茎，个位数作为叶。例如，值 62 的茎叶图表示为：\n\n\n62 的茎叶图\n\nStem Leaf\n  6   2\n\n62，67 两个数据的茎叶图表示为：\n\n\n62，67 的茎叶图\n\nStem Leaf\n  6  2,7\n\n\n例子 2.3 表格 2.5 给出了美国 35 个城市的每日最低气温的月平均值和年平均值。表格 2.5 中的每日最低温度的年平均值可以用下面的茎叶图表示。\n\n\n代码\ndf &lt;- read.table(\"../misc/US_minimum_temperature.csv\", header=TRUE, sep=\",\")\nstem(df$Annual.avg.)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  2 | 9\n  3 | 034\n  3 | 56699\n  4 | 0001244\n  4 | 55567899\n  5 | 112\n  5 | 677899\n  6 | \n  6 | 9\n  7 | 0\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n由于 R 中的 stem() 并不支持小数，因此对于 表格 2.5 中所示的年平均值会先进行四舍五入转成整数，然后再画茎叶图。因此，这里给的茎叶图和原书中的不一致。\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_minimum_temperature.csv\", header=TRUE, sep=\",\")\nkable(df)\n\n\n\n\n表格 2.5: 1961年~1990年，美国指定城市的每日最低气温表。数据来源：Source: U.S. National Oceanic and Atmospheric Administration, Climatography of the United States, No. 81。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nState\nStation\nJan.\nFeb.\nMar.\nApr.\nMay\nJune\nJuly\nAug.\nSept.\nOct.\nNov.\nDec.\nAnnual.avg.\n\n\n\n\nAL\nMobile\n40.0\n42.7\n50.1\n57.1\n64.4\n70.7\n73.2\n72.9\n68.7\n57.3\n49.1\n43.1\n57.4\n\n\nAK\nJuneau\n19.0\n22.7\n26.7\n32.1\n38.9\n45.0\n48.1\n47.3\n42.9\n37.2\n27.2\n22.6\n34.1\n\n\nAZ\nPhoenix\n41.2\n44.7\n48.8\n55.3\n63.9\n72.9\n81.0\n79.2\n72.8\n60.8\n48.9\n41.8\n59.3\n\n\nAR\nLittle Rock\n29.1\n33.2\n42.2\n50.7\n59.0\n67.4\n71.5\n69.8\n63.5\n50.9\n41.5\n33.1\n51.0\n\n\nCA\nLos Angeles\n47.8\n49.3\n50.5\n52.8\n56.3\n59.5\n62.8\n64.2\n63.2\n59.2\n52.8\n47.9\n55.5\n\n\nCA\nSacramento\n37.7\n41.4\n43.2\n45.5\n50.3\n55.3\n58.1\n58.0\n55.7\n50.4\n43.4\n37.8\n48.1\n\n\nCA\nSan Diego\n48.9\n50.7\n52.8\n55.6\n59.1\n61.9\n65.7\n67.3\n65.6\n60.9\n53.9\n48.8\n57.6\n\n\nCA\nSan Francisco\n41.8\n45.0\n45.8\n47.2\n49.7\n52.6\n53.9\n55.0\n55.2\n51.8\n47.1\n42.7\n49.0\n\n\nCO\nDenver\n16.1\n20.2\n25.8\n34.5\n43.6\n52.4\n58.6\n56.9\n47.6\n36.4\n25.4\n17.4\n36.2\n\n\nCT\nHartford\n15.8\n18.6\n28.1\n37.5\n47.6\n56.9\n62.2\n60.4\n51.8\n40.7\n32.8\n21.3\n39.5\n\n\nDE\nWilmington\n22.4\n24.8\n33.1\n41.8\n52.2\n61.6\n67.1\n65.9\n58.2\n45.7\n37.0\n27.6\n44.8\n\n\nDC\nWashington\n26.8\n29.1\n37.7\n46.4\n56.6\n66.5\n71.4\n70.0\n62.5\n50.3\n41.1\n31.7\n49.2\n\n\nFL\nJacksonville\n40.5\n43.3\n49.2\n54.9\n62.1\n69.1\n71.9\n71.8\n69.0\n59.3\n50.2\n43.4\n57.1\n\n\nFL\nMiami\n59.2\n60.4\n64.2\n67.8\n72.1\n75.1\n76.2\n76.7\n75.9\n72.1\n66.7\n61.5\n69.0\n\n\nGA\nAtlanta\n31.5\n34.5\n42.5\n50.2\n58.7\n66.2\n69.5\n69.0\n63.5\n51.9\n42.8\n35.0\n51.3\n\n\nHI\nHonolulu\n65.6\n65.4\n67.2\n68.7\n70.3\n72.2\n73.5\n74.2\n73.5\n72.3\n70.3\n67.0\n70.0\n\n\nID\nBoise\n21.6\n27.5\n31.9\n36.7\n43.9\n52.1\n57.7\n56.8\n48.2\n39.0\n31.1\n22.5\n39.1\n\n\nIL\nChicago\n12.9\n17.2\n28.5\n38.6\n47.7\n57.5\n62.6\n61.6\n53.9\n42.2\n31.6\n19.1\n39.5\n\n\nIL\nPeoria\n13.2\n17.7\n29.8\n40.8\n50.9\n60.7\n65.4\n63.1\n55.2\n43.1\n32.5\n19.3\n41.0\n\n\nIN\nIndianapolis\n17.2\n20.9\n31.9\n41.5\n51.7\n61.0\n65.2\n62.8\n55.6\n43.5\n34.1\n23.2\n42.4\n\n\nIA\nDes Moines\n10.7\n15.6\n27.6\n40.0\n51.5\n61.2\n66.5\n63.6\n54.5\n42.7\n29.9\n16.1\n40.0\n\n\nKS\nWichita\n19.2\n23.7\n33.6\n44.5\n54.3\n64.6\n69.9\n67.9\n59.2\n46.6\n33.9\n23.0\n45.0\n\n\nKY\nLouisville\n23.2\n26.5\n36.2\n45.4\n54.7\n62.9\n67.3\n65.8\n58.7\n45.8\n37.3\n28.6\n46.0\n\n\nLA\nNew Orleans\n41.8\n44.4\n51.6\n58.4\n65.2\n70.8\n73.1\n72.8\n69.5\n58.7\n51.0\n44.8\n58.5\n\n\nME\nPortland\n11.4\n13.5\n24.5\n34.1\n43.4\n52.1\n58.3\n57.1\n48.9\n38.3\n30.4\n17.8\n35.8\n\n\nMD\nBaltimore\n23.4\n25.9\n34.1\n42.5\n52.6\n61.8\n66.8\n65.7\n58.4\n45.9\n37.1\n28.2\n45.2\n\n\nMA\nBoston\n21.6\n23.0\n31.3\n40.2\n49.8\n59.1\n65.1\n64.0\n56.8\n46.9\n38.3\n26.7\n43.6\n\n\nMI\nDetroit\n15.6\n17.6\n27.0\n36.8\n47.1\n56.3\n61.3\n59.6\n52.5\n40.9\n32.2\n21.4\n39.0\n\n\nMI\nSault Ste. Marie\n4.6\n4.8\n15.3\n28.4\n38.4\n45.5\n51.3\n51.3\n44.3\n36.2\n25.9\n11.8\n29.8\n\n\nMN\nDuluth\n-2.2\n2.8\n15.7\n28.9\n39.6\n48.5\n55.1\n53.3\n44.5\n35.1\n21.5\n4.9\n29.0\n\n\nMN\nMinneapolis-St. Paul\n2.8\n9.2\n22.7\n36.2\n47.6\n57.6\n63.1\n60.3\n50.3\n38.8\n25.2\n10.2\n35.3\n\n\nMS\nJackson\n32.7\n35.7\n44.1\n51.9\n60.0\n67.1\n70.5\n69.7\n63.7\n50.3\n42.3\n36.1\n52.0\n\n\nMO\nKansas City\n16.7\n21.8\n32.6\n43.8\n53.9\n63.1\n68.2\n65.7\n56.9\n45.7\n33.6\n21.9\n43.7\n\n\nMO\nSt. Louis\n20.8\n25.1\n35.5\n46.4\n56.0\n65.7\n70.4\n67.9\n60.5\n48.3\n37.7\n26.0\n46.7\n\n\nMT\nGreat Falls\n11.6\n17.2\n22.8\n31.9\n40.9\n48.6\n53.2\n52.2\n43.5\n35.8\n24.3\n14.6\n33.1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_3",
    "href": "chapter_2/2.html#sec-2_3",
    "title": "2  描述统计",
    "section": "2.3 对数据集进行汇总",
    "text": "2.3 对数据集进行汇总\n如今的实验涉及到的数据规模通常比较大。例如，为了了解某些行为习惯对健康的影响，1951 年，医学统计学家 R. Doll 和 A. B. Hill 向英国的所有医生发起了一项调查问卷，并且回收到了大约 40,000 份问卷。问卷的问题涉及年龄、饮食习惯和吸烟习惯。随后，Doll 和 Hill 对问卷回复者进行了为期 10 年的跟踪调查，并对其中的死亡人员的死因进行了监测。为了感知如此大量的数据，需要选择适当的方法对数据进行总结。在本节中，我们将介绍一些汇总数据的统计指标，其中统计指标是一个数值，数据集决定了其统计指标的具体数值。\n\n\n\n\n\n\nThe British Doctors’ Study (1951–2001)\n\n\n\n1951 年，R. Doll 和 A. B. Hill 向英国的 6 万名医生发出调查问卷，并跟踪他们的吸烟情况和健康情况。根据跟踪情况，Doll 和 Hill 提交了两份报告（统称为英国医生研究）：1954 年提交的 The Mortality of Doctors in Relation to Their Smoking Habits 和 1956 年提交的 Lung Cancer and Other Causes of Death in Relation to Smoking。报告中公布了吸烟与疾病发病率的确凿科学证据，报告一经发布就震惊了世界，就连 Doll 本人也吓得戒掉了自己的重度烟瘾。\n针对英国医生的跟踪调查一直持续到 2001 年，当时参与问卷的大多数参与者已经故去，并且还在世的最年轻的参与者也已经七十多岁了。在近 50 年的研究中，研究人员公布了多项报告，这些报告强化了公众对吸烟会导致呼吸道疾病和心血管疾病的认知。\n关于这项研究的内容可以参阅：The British Doctors’ Study (1951–2001)。\n\n\n\n2.3.1 样本均值，样本中位数和样本众数\n在这一节中，我们将介绍一些用于描述数据集中心（center）的统计指标。首先，假设我们有一个由 \\(n\\) 个数据构成的数据集：\\(x_1，x_2，...，x_n\\) 。这 \\(n\\) 个数的算术平均数（arithmetic average）就是样本均值（sample mean）。\n\n定义 2.1 样本均值（sample mean） \\(\\overline{x}\\) 的定义如下：\n\\[\n\\overline{x} = \\frac{\\sum_{i=1}^{n}{x_i}}{n}\n\\tag{2.1}\\]\n\n如果 \\(a\\)，\\(b\\) 为常数，并且\n\\(y_i = ax_i+b, i\\in[1,n]\\)\n那么，数据集 \\(y_1,...,y_n\\) 的样本均值为：\n\\[\n\\begin{align}\n\\overline{y}&=\\frac{\\sum_{i=1}^{n}{ax_i+b}}{n} \\\\\n&= \\frac{\\sum_{i=1}^{n}{ax_i}}{n} + \\frac{\\sum_{i=1}^{n}{b}}{n} \\\\\n&= a\\overline{x}+b\n\\end{align}\n\\tag{2.2}\\]\n\n练习 2.1 2004 年至 2013 年，美国高尔夫球大师赛的获胜分数如下：\n\\(280, 278, 272, 276, 281, 279, 276, 281, 289, 280\\)\n请计算如上分数的 样本均值。\n\n\n答案 2.1. 比起直接将这些分数相加，对于每个分数而言，先减去 280 以获得新值 \\(y_i = x_i - 280\\) 会更容易计算其样本均值：\n\\(0, −2, −8, −4, 1, −1, −4, 1, 9, 0\\)\n\n\\(y_i\\) 的算术平均数为 \\(-\\frac{8}{10}\\)，因此 \\(\\overline{y}=-\\frac{8}{10}\\)，所以 \\(\\overline{x}=\\overline{y}+280=279.2\\)。\n有时，我们想要确定一个用频率表来描述的数据集的样本均值，在频率表中存在 \\(k\\) 个不同的值 \\(v_1,...,v_k\\)，以及它们对应的频率 \\(f_1,...,f_k\\)。该数据集由 \\(n=\\sum_{i=1}^{k}{f_i}\\) 个值组成，其中值 \\(v_i\\) 出现 \\(f_i\\) 次，因此这 \\(n\\) 个数据的样本均值为：\n\\[\n\\overline{x}=\\sum_{i=1}^{k}{\\frac{v_if_i}{n}}\n\\tag{2.3}\\]\n对上述计算进行展开，得到：\n\\(\\overline{x}=\\frac{f_1}{n}{v_1} + \\frac{f_2}{n}{v_2} + ... + \\frac{f_k}{n}{v_k}\\)\n因此，样本均值是数据集中不同值的加权平均数，其中 \\(v_i\\) 的权重等于 \\(n\\) 个数据中值等于 \\(v_i\\) 的数据的占比。\n\n练习 2.2 如下的频率表给出了青少年交响乐团的成员年龄分布。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;-data.frame(\n  Age = c(15, 16, 17, 18, 19, 20),\n  Frequency = c(2, 5, 11, 9, 14, 13)\n)\n\nkable(df, align = \"l\")\n\n\n\n\n\nAge\nFrequency\n\n\n\n\n15\n2\n\n\n16\n5\n\n\n17\n11\n\n\n18\n9\n\n\n19\n14\n\n\n20\n13\n\n\n\n\n\n计算该交响乐团中 54 位成员的年龄的样本均值。\n\n\n答案 2.2. \\(\\overline{x} = (15·2 + 16·5 + 17·11 + 18·9 + 19·14 + 20·13) / 54 ≈ 18.24\\)\n\n另一个用于表示数据集中心的统计指标是样本中位数（sample median），简单来说，中位数就是当数据集中的数据按递增顺序排列后，位于数据集中间的数。\n\n定义 2.2 把大小为 \\(n\\) 的数据集中的数据从小到大排序。如果 \\(n\\) 是奇数，则 样本中位数 就是第 \\(\\frac{(n + 1)}{2}\\) 个数；如果 \\(n\\) 是偶数，则 样本中位数 就是第 \\(\\frac{n}{2}\\) 个数和第 \\(\\frac{n}{2} + 1\\) 个数的平均值。\n\n因此，3 个数的样本中位数是其第 2 小的数；4 个数的样本中位数是第 2 小和第 3 小的数的平均值。\n\n练习 2.3 找出 练习 2.2 中的样本中位数。\n\n\n答案 2.3. 由于有 54 个数，因此当数据按递增顺序排列后，样本中位数是第 27 个数和第 28 个数的平均值。因此，样本中位数是 18.5。\n\n样本均值和样本中位数都是描述数据集中心趋势的、非常有用的统计指标。样本均值的计算会用到数据集中的所有数据，并且容易受到数据集中极端值（远远大于或小于数据集中大多数数据的数据）的影响。样本中位数的计算只会到数据集中的一个或两个数据，因此样本中位数不受数据集中的极端值的影响。样本均值更好还是样本中位数更好，取决于我们试图从数据中学习什么。\n\n如果政府有统一的个人所得税税率，并试图估计税收总额，那么可以使用居民收入的样本均值作为统计量指标。\n如果政府正在考虑建造保障房，并希望确定能够负担得起这种住房的居民人口比例，那么更好的方式则是使用样本中位数。\n\n\n练习 2.4 1972 年，Hoel, D. G. 发表了一篇论文 A representation of mor- tality data by competing risks。在这篇论文中，Hoel 首先让一组 5 周大的小白鼠接受 300rad 的辐射剂量，然后把这些小白鼠分成两组：第一组置于无菌环境中，第二组则置于常规的实验室环境。随后，Hoel 观察并记录这些小白鼠的生存天数。以下的茎叶图（茎以百天为单位）记录了因胸腺淋巴瘤死亡的小白鼠的数据：第一张图是生活在无菌条件下的小白鼠，第二张图是生活在普通实验室条件下的小白鼠。\n\n\n\n表格 2.6: 不同环境下的小白鼠实验\n\n\n\n\n\n无菌环境下的小白鼠\n\n\nStem\nLeaf\n\n\n\n\n1\n58, 92, 93, 94, 95\n\n\n2\n02, 12, 15, 29, 30, 37, 40, 44, 47, 59\n\n\n3\n01, 01, 21, 37\n\n\n4\n15, 34, 44, 85, 96\n\n\n5\n29,37\n\n\n6\n24\n\n\n7\n07\n\n\n8\n00\n\n\n\n\n\n\n正常实验室环境下的小白鼠\n\n\nStem\nLeaf\n\n\n\n\n1\n59, 89, 91, 98\n\n\n2\n35, 45, 50, 56, 61, 65, 66, 80\n\n\n3\n43, 56, 83\n\n\n4\n03, 14, 28, 32\n\n\n\n\n\n\n\n\n计算两组小白鼠的生存时间的样本均值和样本中位数。\n\n\n答案 2.4. 从茎叶图中可以清晰地看出，无菌环境下小白鼠的样本均值（344.07）大于常规实验室环境下小白鼠的样本均值（292.32）。另一方面，由于无菌环境下的小白鼠有 29 个数据值，所以其样本中位数是第 15-最大 的数据值，即 259。另一组小白鼠的样本中位数是第 10-最大 的数据值，即 265。因此，尽管第一组数据的样本均值大于第二组，但这两组数据的样本中位数却大致基本一致。其中的原因在于，第一组数据中大于 500 的 5 个数据对其样本均值的影响较大，但对其样本中位数的影响要小得多。事实上，如果把大于 500 的 5 个数据替换为任何其他五个大于或等于 259 的数据，其样本中位数将保持不变。从茎叶图来看，无菌环境可能延长了五只寿命最长的小白鼠的寿命，但无法确定无菌环境是否对其他小白鼠的寿命产生了什么别的影响。\n\n另一个用于表示数据集中心趋势的统计指标是 样本众数（sample mode）。在数据集中，出现频率最高的值为 样本众数。如果出现频率最高的值有多个，那么所有出现频率最高的这些数值都是 样本众数。\n\n练习 2.5 以下的频率表为抛 40 次骰子获得的结果。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;- data.frame(\n    Value = c(1, 2, 3, 4, 5, 6),\n    Frequency = c(9, 8, 5, 5, 6, 7)\n)\nkable(df, align = \"l\")\n\n\n\n\n\nValue\nFrequency\n\n\n\n\n1\n9\n\n\n2\n8\n\n\n3\n5\n\n\n4\n5\n\n\n5\n6\n\n\n6\n7\n\n\n\n\n\n\n计算其样本均值\n计算其样本中位数\n计算器样本众数\n\n\n\n答案 2.5. \n\n样本均值为 \\(\\overline{x}=(9 + 16 + 15 + 20 + 30 + 42) / 40 = 3.05\\)\n样本中位数为 第 20-最小 和 第 21-最小 的平均数 3\n样本众数为 1\n\n\n\n\n2.3.2 样本方差和样本标准差\n虽然我们已经介绍了用于描述数据集中心趋势的统计指标，但我们也对描述数据波动的统计量感兴趣。可以通过计算数据值与样本均值之间距离的平方的平均值来描述数据集中数据的波动，这就是样本方差（sample variance）。出于技术原因，在计算样本方差时，需要除以 \\(n-1\\) 而不是 \\(n\\)（\\(n\\) 是数据集的大小）。\n\n定义 2.3 对于数据集 \\({x_1,...,x_n}\\)，其 样本方差 \\(s^2\\) 的定义如下：\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}{n - 1}\n\\tag{2.4}\\]\n\n\n练习 2.6 计算如下两个数据集的样本方差：\n\nA: 3, 4, 6, 7, 10\nB: -20, 5, 15, 24\n\n\n\n答案 2.6. 对于 A 而言，其样本均值 \\(\\overline{x} = (3 + 4 + 6 + 7 + 10) / 5 = 6\\)，因此，其样本方差为： \\(s^2 = [(−3)^2 + (−2)^2 + 0^2 + 1^2 + 4^2] / 4 = 7.5\\)\n对于 B 而言，其样本均值也是 6，因此，其样本方差为： \\(s^2 = [(−26)^2 + (−1)^2 + 9^2 + (18)^2] / 3 ≈ 360.67\\)\n\n通过 Solution 2.6 可发现，虽然 A 和 B 的样本均值是一样的，但是 B 的样本方差远大于 A。\n在计算样本方差时，会经常用到如下的数学等式：\n\\[\n\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} = \\sum_{i=1}^{n}{x_i^2} - n\\overline{x}^2\n\\tag{2.5}\\]\n方程式 2.5 的证明过程如下：\n\\[\n\\begin{align}  \n\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} &= \\sum_{i=1}^{n}{(x_i^2 - 2x_i\\overline{x} + \\overline{x}^2)} \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - 2\\overline{x}\\sum_{i=1}^{n}{x_i} + \\sum_{i=1}^{n}{\\overline{x}^2} \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - 2n\\overline{x}^2 + n\\overline{x}^2 \\\\\n&=\\sum_{i=1}^{n}{x_i^2} - n\\overline{x}^2\n\\end{align}\n\\]\n如果 \\(y_i = ax_i + b\\)，\\(i = 1,...,n\\)，则 \\(\\overline{y} = a\\overline{x} + b\\)，因此：\n\\(\\sum_{i=1}^{n}{(y_i - \\overline{y})^2} = a^2\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}\\)\n所以：\n\\[\ns_y^2 = a^2s_x^2\n\\tag{2.6}\\]\n换句话说，为数据集中的每个数据增加一个常数不会改变其样本方差；而让数据集中的每个数据乘以一个常数则会得到一个新的样本方差，新的样本方差等于原来的样本方差乘以该常数的平方。\n\n练习 2.7 下表给出了 1997 年至 2005 年间全球商业航空运输中导致人员死亡的事故数量。\n\n\n代码\nlibrary(knitr)\n\ndf &lt;- data.frame(\n    Year=seq(1997, 2005, by=1),\n    Accidents = c(25, 20, 21, 18, 13, 13, 7, 9, 18))\n\nkable(df, align=\"l\")\n\n\n\n\n\nYear\nAccidents\n\n\n\n\n1997\n25\n\n\n1998\n20\n\n\n1999\n21\n\n\n2000\n18\n\n\n2001\n13\n\n\n2002\n13\n\n\n2003\n7\n\n\n2004\n9\n\n\n2005\n18\n\n\n\n\n\n根据如上的数据，计算航工事故的样本方差。\n\n\n答案 2.7. 将数据集中的数据都减去 18，我们得到一个新的数据集：\n\\(y = \\{7,2,3,0,−5,−5,−11,−9,0\\}\\)\n\\(\\overline{y} = \\sum_{i=1}^{9}{y_i} / 9 = -2\\)\n\\(\\sum_{i=1}^{9}{y_i^2} = 49 + 4 + 9 + 25 + 25 + 121 + 81 = 314\\)\n因为新的数据集的方差和原数据集是一样的，因此根据 方程式 2.5：\n\\(s^2 = \\frac{\\sum_{i=1}^{9}{y_i^2} - n\\overline{x}^2}{n - 1} = \\frac{314 - 9·4}{8} = 34.75\\)\n\n\n\n\n\n\n\n注释\n\n\n\n因为 \\(y_i = x_i - 20\\)，因此，根据 方程式 2.6， \\(y\\) 和 \\(x\\) 的方差是一样的。\n\n\n样本方差的平方根称之为 样本标准差（sample standard deviation）。\n\n定义 2.4 样本标准差 \\(s\\)的定义如下所示：\n\\[\ns = \\sqrt{\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2}}{n - 1}}\n\\tag{2.7}\\]\n\n\n\n2.3.3 样本百分位数和箱线图\n简单来说，数据集的 样本\\(100p\\)-百分位数 是指小于或等于数据集中 \\(100p\\%\\) 的数据所对应的数据值，其中 \\(0 \\le p \\le 1\\)。\n\n定义 2.5 样本\\(100p\\)-百分位数 是数据集中的一个数据值，这个值满足至少 \\(100p\\%\\) 的数据小于或等于它，并且至少 \\(100(1-p)\\%\\) 的数据大于或等于它。如果存在两个数据值满足这个条件，那么该数据集的 样本\\(100p\\)-百分位数 是这两个值的算术平均数。\n\n为了确定大小为 \\(n\\) 的数据集的样本\\(100p\\)-百分位数，我们需要确定这样的数据值，以使得该值满足如下的条件：\n\n至少有 \\(np\\) 个数据小于或等于该值\n至少有 \\(n(1-p)\\) 个数据大于或等于该值\n\n为了计算样本\\(100p\\)-百分位数，首先要对数据集进行升序排列。\n\n如果 \\(np\\) 不是整数，那么唯一满足前述条件的数据值是数据从小到大排序后，位置大于 \\(np\\) 的最小整数所对应的值。例如，如果 \\(n=22\\)，\\(p=0.8\\)，那么我们需要一个数据值，使得至少有 17.6 个数据小于或等于它，并且至少有 4.4 个数据大于或等于它。显然，只有第 18 小的值同时满足这两个条件，这就是 样本80-百分位数。\n如果 \\(np\\) 是整数，那么很容易发现 \\(np\\) 和 \\(np+1\\) 这两个位置的数据都满足前述条件，因此样本 \\(100p\\)-百分位数就是这两个数据值的算术平均数。例如，如果我们想计算大小为 20 的数据集的 90-百分位数，那么第 18-小 和第 19-小 的值都会使得至少有 90% 的数据小于或等于它们，并且至少有 10% 的数据大于或等于它们。因此，90-百分位数是这两个值的平均数。\n\n\n练习 2.8 表格 2.7 列出了 2006 年美国人口最多的 25 个城市的人口数。对于这组数据，找出：\n\n样本10-百分位数\n样本80-百分位数。\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_population.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.7: 2006 年 7 月，美国 25 个最大城市的人口数据\n\n\n\n\n\n\nRank\nCity\nPopulation\n\n\n\n\n1\nNew York, NY\n8250567\n\n\n2\nLos Angeles, CA\n3849378\n\n\n3\nChicago, IL\n2833321\n\n\n4\nHouston, TX\n2144491\n\n\n5\nPhoenix, AR\n1512986\n\n\n6\nPhiladelphia, PA\n1448394\n\n\n7\nSan Antonio, TX\n1296682\n\n\n8\nSan Diego, CA\n1256951\n\n\n9\nDallas, TX\n1232940\n\n\n10\nSan Jose, CA\n929936\n\n\n11\nDetroit, MI\n918849\n\n\n12\nJacksonville, FL\n794555\n\n\n13\nIndianapolis, IN\n785597\n\n\n14\nSan Francisco, CA\n744041\n\n\n15\nColumbus, OH\n733203\n\n\n16\nAustin, TX\n709893\n\n\n17\nMemphis, TN\n670902\n\n\n18\nFort Worth, TX\n653320\n\n\n19\nBaltimore, MD\n640961\n\n\n20\nCharlotte, NC\n630478\n\n\n21\nEl Paso, TX\n609415\n\n\n22\nMilwaukee, WI\n602782\n\n\n23\nBoston, MA\n590763\n\n\n24\nSeattle, WA\n582454\n\n\n25\nWashington, DC\n581530\n\n\n\n\n\n\n\n\n\n答案 2.8. \n\n因为样本的大小是 25，25·0.1 = 2.5，因此，样本10-百分位数就是样本第 3-小的数据，也就是 590763。\n因为 25·0.8 = 20，因此，样本80-百分位数是第 20-小和第 21-小的算术平均数，\\(\\frac{1512986 + 1448394}{2}\\)，也就是 1480690。\n\n\n样本50-百分位数，就是样本中位数。样本25-百分位数、样本50-百分位数、样本75-百分位数一起构成了样本四分位数（sample quartiles）。\n\n定义 2.6 样本25-百分位数称之为 第一四分位数（the first quartile），样本50-百分位数称之为 样本中位数 或 第二四分位数（the second quartile），样本75-百分位数称之为 第三四分位数（the third quartile）\n\n\n\n\n\n\n\n注释\n\n\n\n有时，也会把样本四分位数称为下四分位数和上四分位数：下四分位数（25-百分位数），中位数（50-百分位数），上四分位数（75-百分位数）。\n\n\n四分位数把数据集分为四个部分，大约 25% 的数据小于第一四分位数，25% 的数据位于第一四分位数和第二四分位数之间，25% 的数据位于第二四分位数和第三四分位数之间，剩余的 25% 的数据大于第三四分位数。\n\n练习 2.9 我们使用分贝（dB）来测量噪音。听力正常的人在安静环境下能听到的最弱的声音大约是 1dB，窃窃私语时的声音大约是 30dB，人们正常交谈时的声音大约是 70dB，收音机的音量大约是 100dB。当声音超过 120 dB 时，耳朵就开始感知到不适了。\n曼哈顿中央车站外测量到的 36 个不同时间点的噪音水平如下所示：\n\n\n曼哈顿中央车站噪音水平\n\n82, 89, 94, 110, 74, 122, 112, 95, 100, 78, 65, 60, 90, 83, 87, 75, 114, 85 69, 94, 124, 115, 107, 88, 97, 74, 72, 68, 83, 91, 90, 102, 77, 125, 108, 65\n\n计算如上数据的四分位数。\n\n\n答案 2.9. 因为 \\(n = 36\\)，所以四分位数对应的 \\(np\\) 均为整数，因此其对应的四分位数值为第 \\(np\\)-小和第 \\((np+1)\\)-小的平均数。\n\n第一四分位数（\\(p=0.25\\)）：第 9-小和第 10-小的平均值，也就是 74.5。\n第二四分位数（\\(p=0.5\\)）：第 18-小和第 19-小的平均值，也就是 89.5。\n第三四分位数（\\(p=0.75\\)）：第 27-小和第 28-小的平均值，也就是 104.5。\n\n\n我们经常用箱线图（box plot）绘制数据集的汇总统计指标。\n\n在横坐标轴上绘制一条从最小值到最大值的直线段。\n在这条直线上叠加一个 “箱子”，该箱子从第一四分位数开始一直延伸到第三四分位数，并用垂直线表示第二四分位数。\n\n例如，表格 2.1 中给出的 42 个起薪数据覆盖了从最低值 57000$ 到最高值 70000$ 之间的数。第一四分位数（第 11-小的值）是 60000\\(，第二四分位数（第 21-小和第 22-小的平均值）是 61500\\)，第三四分位数（第 32-小的值）是 64000$。该数据集的箱线图如 图 2.7 所示。\n\n\n代码\nlibrary(ggplot2)\nss &lt;- c(57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 70)\nf &lt;- c(4, 1, 3, 5, 8, 10, 0, 5, 2, 3, 1)\ndf &lt;- data.frame(value=rep(ss, f))\nggplot(df, aes(x=value, y=\"\")) +\n  geom_boxplot() + \n  labs(x=\"Starting Salary\", y=\"\")\n\n\n\n\n\n\n\n\n图 2.7: 起薪线图\n\n\n\n\n\n\n\n\n\n\n\n注释\n\n\n\n图 2.7 中的箱线图和文中对各四分位数的计算并不一致，这主要是因为该图使用 R 的 ggplot2 包绘制，对于该包而言，在绘制箱线图时，会剔除数据中可能的离群点（\\(\\pm 1.5IQR\\)），离群点在图中显示为一个点。\n\n\n箱线图上直线的长度等于数据集中的最大值减去数据集中的最小值，称为数据范围。箱线图中箱子的长度等于第三四分位数减去第一四分位数，称为四分位距（IQR: inter quaritle range）。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_4",
    "href": "chapter_2/2.html#sec-2_4",
    "title": "2  描述统计",
    "section": "2.4 切比雪夫不等式",
    "text": "2.4 切比雪夫不等式\n设 \\(\\overline {x}\\) 和 \\(s\\) 分别是数据集的样本均值和样本标准差。假设 \\(s &gt; 0\\)，切比雪夫不等式表明，对于 \\(\\forall k \\ge 1\\) ，至少有 \\((100 \\cdot (1−\\frac {1}{k^2})) \\%\\) 的数据位于 \\([ \\overline {x} − ks, \\overline {x} + ks]\\) 的区间内。\n\n令 \\(k = \\frac {3}{2}\\)，根据切比雪夫不等式，至少有 \\(55.56\\%\\) 的数据会位于 \\(\\overline {x} \\pm 1.5s\\) 的范围内。\n令 \\(k=2\\)，则至少有 \\(75\\%\\) 的数据位于 \\(\\overline {x} \\pm 2s\\) 的范围内。\n令 \\(k=3\\)，则至少有 \\(88.9\\%\\) 的数据位于 \\(\\overline {x} \\pm 3s\\) 的范围内。\n\n\n2.4.1 切比雪夫不等式\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。\n令 \\(S_k=\\{|x_i - \\overline{x}| \\lt ks, i \\in [1, n]\\}\\)，即 \\(S_k\\) 为距离 \\(\\overline{x}\\) \\(k\\) 个标准差以内的数据构成的集合。\n令 \\(|S_k|\\) 为集合 \\(S_k\\) 中的元素个数。\n则有：\n\\[\n\\frac{|S_k|}{n} \\ge {1 - \\frac{n-1}{nk^2}} \\gt {1 - \\frac{1}{k^2}}, \\ \\ \\forall k \\ge 1\n\\tag{2.8}\\]\n方程式 2.8 就是切比雪夫不等式，其证明过程如下：\n\\[\n\\begin{align}\n(n-1)s^2 &= \\sum_{i=1}^{n}{(x_i-\\overline{x})^2} \\\\\n&= \\sum_{i \\in S_k}{{(x_i-\\overline{x})^2}} + \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}} \\\\\n& \\ge \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}}\n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\because \\forall i \\in S_k, \\ \\ |x_i - \\overline{x}| \\lt ks, \\\\\n&\\therefore \\forall i \\notin S_k, \\ \\ |x_i - \\overline{x}| \\ge ks, \\\\\n&\\therefore \\sum_{i \\notin S_k}{{(x_i-\\overline{x})^2}} \\ge \\sum_{i \\notin S_k}{k^2s^2} \\\\\n&=k^2s^2(n-|S_k|)\n\\end{align}\n\\]\n\\[\n\\therefore (n-1)s^2 \\ge k^2s^2(n-|S_k|)\n\\tag{2.9}\\]\n当 \\(s^2 \\ne 0\\) 时，对于 方程式 2.9 的等式两边都除以 \\(nk^2s^2\\)，得到：\n\\[\n\\begin{align}\n&\\frac{n-1}{nk^2} \\ge \\frac{n-|S_k|}{n}, \\\\\n&\\therefore \\frac{n-1}{nk^2} \\ge 1-\\frac{|S_k|}{n} \\\\\n&\\therefore \\frac{|S_k|}{n} \\ge 1-\\frac{n}{nk^2}+\\frac{1}{nk^2} \\\\\n&\\therefore \\frac{|S_k|}{n} \\ge 1-\\frac{1}{k^2}\n\\end{align}\n\\]\n由于切比雪夫不等式的通用性，对于给定的数据集，实际位于 \\([\\overline{x}-ks, \\overline{x}+ks]\\) 区间内的数据的百分比可能比切比雪夫不等式给出的下限要大一点。\n\n例子 2.4 表格 2.8 给出了 2013 年 6 月美国最畅销的 10 款汽车。根据数据可知：\\(\\overline{x}=35.33\\)，\\(s=11.86\\)，当 \\(k=\\frac{3}{2}\\) 时，至少有 55.55%（\\(100(1-\\frac{1}{k^2})\\%\\)）的数据位于 [17.54, 53.12]（\\([\\overline{x}-ks, \\overline{x}+ks]\\)）区间内。而实际上，对于表中的数据而言，有 \\(90\\%\\) 的数据落在了这个区间。\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_cars.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.8: 2013 年 6 月美国最畅销的 10 款汽车\n\n\n\n\n\n\nRank\nModel\nSales.Volume.in.thousands.of.vehicles.\n\n\n\n\n1\nFord F Series\n68.0\n\n\n2\nChevrolet Silverado\n43.3\n\n\n3\nToyota Camry\n35.9\n\n\n4\nChevrolet Cruze\n32.9\n\n\n5\nHonda Accord\n31.7\n\n\n6\nHonda Civic\n29.7\n\n\n7\nDodge Ram\n29.6\n\n\n8\nFord Escape\n28.7\n\n\n9\nNissan Altima\n26.9\n\n\n10\nHonda CR-V\n26.6\n\n\n\n\n\n\n\n\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。那么，\\(\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\) 的数据占比是多少呢？\n假设令 \\(N_k=\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\)，我们是否可以计算出 \\(\\frac{|N_k|}{n}\\)？\n当然！！！\n根据 方程式 2.8，我们可以得到：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{k^2}\n\\tag{2.10}\\]\n不过，利用接下来要介绍的单边切比雪夫不等式，我们可以得到一个更为精准的数据。\n\n\n2.4.2 单边切比雪夫不等式\n对于数据集 \\(\\{x_1,...,x_n\\}\\) 而言，令 \\(\\overline{x}\\) 和 \\(s\\) 分别是其样本均值和样本标准差，其中 \\(s \\gt 0\\)。\n令 \\(N_k=\\{x_i - \\overline{x} \\ge ks, i \\in [1, n]\\}\\)， \\(|N_k|\\) 为集合 \\(N_k\\) 中的元素个数，则有：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{1+k^2}\n\\tag{2.11}\\]\n我们称 方程式 2.11 为单边切比雪夫不等式（one-sided Chebyshev inequality），其证明过程如下：\n令 \\(y_i=x_i-\\overline{x}\\)，\\(i \\in [1,n]\\)，对于 \\(\\forall b \\gt 0\\)，有：\n\\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &\\ge \\sum_{i:y_i \\ge ks}{(y_i+b)^2} \\\\\n& \\ge \\sum_{i:y_i \\ge ks}{(ks+b)^2} \\\\\n& = |N_k| \\cdot (ks+b)^2\n\\end{align}\n\\tag{2.12}\\]\n因为 \\(|N_k|\\) 为 \\(y_i \\ge ks\\) 的元素个数，\\(ks\\) 和 \\(b\\) 都是正数，因此有： \\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &= \\sum_{i=1}^{n}{(y_i^2 + 2by_i + b^2)} \\\\\n&= \\sum_{i=1}^{n}{y_i^2} + 2b\\sum_{i=1}^{n}{y_i} + nb^2\n\\end{align}\n\\]\n\\[\n\\begin{align}\n&\\because y_i = x_i - \\overline{x} \\\\\n&\\therefore \\sum_{i=1}^{n}{y_i} = \\sum_{i=1}^{n}{(x_i - \\overline{x})} = \\sum_{i=1}^{n}{x_i} - n\\overline{x} = 0\n\\end{align}\n\\]\n所以有：\n\\[\n\\begin{align}\n\\sum_{i=1}^{n}{(y_i+b)^2} &= \\sum_{i=1}^{n}{y_i^2} + nb^2 \\\\\n&=(n-1)s^2 + nb^2\n\\end{align}\n\\tag{2.13}\\]\n根据 方程式 2.12 和 方程式 2.13，有：\n\\[\n(n-1)s^2 + nb^2 \\ge |N_k| \\cdot (ks+b)^2\n\\]\n进而得到：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{s^2 + b^2}{(ks + b)^2}\n\\tag{2.14}\\]\n因为 \\(b\\) 是任意大于 0 的数，因此我们可以令：\n\\[\nb=\\frac{s}{k}\n\\tag{2.15}\\]\n把 方程式 2.15 代入 方程式 2.14 得到 方程式 2.11：\n\\[\n\\frac{|N_k|}{n} \\le \\frac{1}{k^2 + 1}\n\\]\n根据 方程式 2.10，我们可以发现，在一个数据集中，超过样本均值的 2 倍标准差的数据最多占比 25%。但是利用 方程式 2.11 所示的单边切比雪夫不等式，我们可以将这个比例精确到最多占比 20%。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_5",
    "href": "chapter_2/2.html#sec-2_5",
    "title": "2  描述统计",
    "section": "2.5 正态分布数据集",
    "text": "2.5 正态分布数据集\n我们在实践中观察到的许多大数据集都具有形状相似的直方图。通常，这些直方图在样本中位数处达到峰值，然后在中位数的两侧以钟形对称的形式下降。我们称这样的数据集为正态数据集，称其直方图为正态直方图。图 2.8 (a) 展示了一个正态数据集的直方图。\n如果一个数据集的直方图接近正态直方图，我们说该数据集近似正态分布。例如，我们会说图 图 2.8 (b) 给出的直方图来自一个近似正态的数据集，而图 图 2.8 (c) 和图 图 2.8 (d) 给出的直方图则不是近似正态的数据集（因为每个直方图都太不对称）。与样本中位数不是近似对称的任何数据集都是偏态（skewed）分布。如果数据集的长尾在中位数右侧，则称为 “右偏”；如果数据集的长尾在中位数左侧，则称为 “左偏”。因此，图 图 2.8 (c) 中的数据集为左偏分布，而 图 2.8 (d) 中的数据集为右偏分布。\n\n代码\nlibrary(ggplot2)\n\nx &lt;- seq(1, 19)\ny &lt;- 100 - 10 * abs(x - mean(x))\ndf &lt;- data.frame(value=rep(x, y))\n\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\n\nx &lt;- seq(1, 19)\ny &lt;- 100 - 10 * abs(x - mean(x))\nvalue &lt;- rep(x, y)\nvalue &lt;- value[value != 17]\ndf &lt;- data.frame(value=value)\n\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\ndf &lt;- data.frame(value=rbeta(10000, 5, 2))\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\ndf &lt;- data.frame(value=rbeta(10000, 1, 5))\nggplot(df, aes(x=value)) +\n  geom_histogram(bins=19)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) 正态分布\n\n\n\n\n\n\n\n\n\n\n\n(b) 近似正态分布\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) 左偏分布\n\n\n\n\n\n\n\n\n\n\n\n(d) 右偏分布\n\n\n\n\n\n\n\n图 2.8: 不同数据集的直方图\n\n\n\n从正态直方图的对称性可以看出，一个近似正态分布的数据集，其样本均值和样本中位数大致相等。\n假设 \\(\\overline{x}\\) 和 \\(s\\) 分别是近似正态分布数据集的样本均值和样本标准差。经验法则（empirical rule）指定了观察到的数据位于 \\(s\\)、\\(2s\\)、\\(3s\\) 个样本均值 \\(x\\overline{x}\\) 内的大致比例。\n\n2.5.1 经验法则\n如果一个数据集是一个近似正态分布的数据集，其样本均值和样本标准差分别是 \\(\\overline{x}\\) 和 \\(s\\)，那么有如下的正确结论：\n\n大约有 68% 的观察数据会位于 \\(\\overline{x} \\pm s\\) 区间内\n大约有 95% 的观察数据会位于 \\(\\overline{x} \\pm 2s\\) 区间内\n大约有 99% 的观察数据会位于 \\(\\overline{x} \\pm 3s\\) 区间内\n\n\n如下的数据是工业工程专业的学生在统计学考试中的分数：\n43, 46, 52, 55, 55, 56, 58, 60, 62, 63, 64, 66, 66, 72, 74, 74, 75, 77, 77, 78, 83, 85, 85, 87, 88, 90, 91, 94\n通过其茎叶图，我们会发现如上数据的直方图近似正态分布。接下来我们用这份数据来评估一下经验法则。\n\n\n代码\nscores &lt;- c(43, 46, 52, 55, 55, 56, 58, 60, 62, 63, 64, 66, 66, 72, 74, 74, 75, 77, 77, 78, 83, 85, 85, 87, 88, 90, 91, 94)\nstem(scores)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  4 | 36\n  5 | 25568\n  6 | 023466\n  7 | 2445778\n  8 | 35578\n  9 | 014\n\n\n\n\n答案 2.10. 计算得到数据集的样本均值和样本方差：\\(\\overline{x} \\thickapprox 70.571\\)，\\(s \\thickapprox 14.354\\)。因此，根据经验法则：\n\n有 68% 的数据会位于 56.2~84.9 之间，但是实际上，数据集中只有 \\(\\frac{15}{28} \\%\\) 也就是 53.6% 的数据位于56.2~84.9 之间。\n有 95% 的数据会位于 41.68~99.28 之间，但是实际上，数据集中所有的数据都位于 41.68~99.28 之间。\n\n\n如果一个总体是由多个不同类型的子总体而构成，那么从这个总体中抽样得到的数据集通常不是正态分布。这种数据集的直方图通常看起来像是多个正态直方图的组合或叠加，因此在这种直方图上通常会有多个局部峰值。由于这些局部峰值处的直方图比其邻近值更高，因此这些峰值类似于众数。如 图 2.9 所示，在直方图中，具有两个局部峰值的数据集称之为双峰分布。\n\n\n代码\nsamples1 &lt;- rnorm(10000, mean=1, sd=1)  \nsamples2 &lt;- rnorm(10000, mean=5, sd=1)\ndf &lt;- data.frame(value=c(samples1, samples2))\n\nggplot(df, aes(x=value)) +\n    geom_histogram()\n\n\n\n\n\n\n\n\n图 2.9: 双峰分布直方图",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_6",
    "href": "chapter_2/2.html#sec-2_6",
    "title": "2  描述统计",
    "section": "2.6 成对数据集和样本相关系数",
    "text": "2.6 成对数据集和样本相关系数\n我们经常关注由成对数据值构成的数据集，这些数据集中的成对数据之间存在着某种关系。在这样的数据集中，如果每个成对数据都有一个 \\(x\\) 值和一个 \\(y\\) 值，那么我们就用 \\((x_i, y_i)\\) 表示第 \\(i\\) 个数据。例如，为了确定每天中午的温度（以摄氏度为单位）与当天生产的不合格零件数量之间的关系，一家公司记录了 表格 2.9 中的数据。对于这个数据集，\\(x_i\\) 代表第 \\(i\\) 天中午的摄氏温度，\\(y_i\\) 代表第 \\(i\\) 天生产的不合格零件数量。\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.9: 天气温度和产品缺陷量数据\n\n\n\n\n\n\nDay\nTemperature\nNumber.of.Defects\n\n\n\n\n1\n24.2\n25\n\n\n2\n22.7\n31\n\n\n3\n30.5\n36\n\n\n4\n28.6\n33\n\n\n5\n25.5\n19\n\n\n6\n32.0\n24\n\n\n7\n28.6\n27\n\n\n8\n26.5\n25\n\n\n9\n25.3\n16\n\n\n10\n26.0\n14\n\n\n11\n24.4\n22\n\n\n12\n24.8\n23\n\n\n13\n20.6\n20\n\n\n14\n25.1\n25\n\n\n15\n21.4\n25\n\n\n16\n23.7\n23\n\n\n17\n23.9\n27\n\n\n18\n25.2\n30\n\n\n19\n27.4\n33\n\n\n20\n28.3\n32\n\n\n21\n28.8\n35\n\n\n22\n26.6\n24\n\n\n\n\n\n\n\n\n在二维图上绘制成对数据集中的数据是一种表示成对数据集的有效方法，其中 \\(x\\) 轴代表成对数据的 \\(x\\) 值，\\(y\\) 轴代表成对数据的 \\(y\\) 值，这样的图称之为散点图（scatter diagram）。图 2.10 为 表格 2.9 中数据的散点图。\n\n\n代码\nlibrary(ggplot2)\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nggplot(df, aes(x=Temperature, y=Number.of.Defects)) + \n    geom_point()\n\n\n\n\n\n\n\n\n图 2.10: 天气温度和产品缺陷量散点图\n\n\n\n\n\n对于成对数据集而言，一个有趣问题是，比较大的 \\(x\\) 值是否倾向于与比较大的 \\(y\\) 值配对，小的 \\(x\\) 值是否与小的 \\(y\\) 值配对？如果情况并非如此，那么我们可能会质疑其中一个变量的较大的值是否倾向于与另一个变量的较小的值配对。通常，可以通过散点图来大致回答这些问题。例如，图 2.10 表明，高温和缺陷产品数量高之间似乎存在某种联系。为了对成对数据之间的这种关系进行定量度量，我们需要开发一个新的统计指标，以衡量 \\(x\\) 值与 \\(y\\) 值之间的配对程度。\n假设数据集由 \\(\\{(x_i, y_i)\\}\\) 组成，其中 \\(i = 1,...,n\\)，\\(\\overline{x}\\) 和 \\(\\overline{y}\\) 分别是 \\(x\\) 和 \\(y\\) 的样本均值。对于第 \\(i\\) 对数据，使用 \\(x_i - \\overline{x}\\) 作为 \\(x_i\\) 与其样本均值的偏差，使用 \\(y_i - \\overline{y}\\) 作为 \\(y_i\\) 与其样本均值的偏差。如果 \\(x_i\\) 的值比较大，那么 \\(x_i \\gt \\overline{x}\\)，所以 \\(x_i - \\overline{x} \\gt 0\\)。类似地， 如果 \\(x_i\\) 的值比较小，那么 \\(x_i \\lt \\overline{x}\\)，所以 \\(x_i - \\overline{x} \\lt 0\\)。对于 \\(y_i\\) 而言，同样如此。于是，我们可以得出以下结论：\n\n\n\n\n\n\n重要\n\n\n\n当 \\(x\\) 的较大值趋向于和 \\(y\\) 的较大值相关联，\\(x\\) 的较小值趋向于和 \\(y\\) 的较小值相关联时，则 \\(x_i - \\overline{x}\\) 和 \\(y_i- \\overline{y}\\) 的符号（无论正负）都将趋于相同。\n\n\n如果 \\(x_i - \\overline{x}\\) 和 \\(y_i - \\overline{y}\\) 的符号相同（无论正负），那么它们的乘积 \\((x_i - \\overline{x})(\\)y_i - )$ 是正数。因此，当 \\(x\\) 的较大值趋向于和 \\(y\\) 的较大值相关联，\\(x\\) 的较小值趋向于和 \\(y\\) 的较小值相关联时，\\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将趋向于一个较大的正数。事实上，当较大（小）的 \\(x\\) 与较大（小）的 \\(y\\) 配对时，不但所有的 \\((x_i - \\overline{x})(y_i - \\overline{y})\\) 的符号都是正的，而且当 \\((x_i - \\overline{x})\\) 的最大值与 \\((y_i - \\overline{y})\\) 的最大值配对、其对应的次大值配对、依次类推对 \\((x_i - \\overline{x})\\) 和 \\((y_i - \\overline{y})\\) 配对时，\\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将获得最大值。同理，当 \\(x_i\\) 的较大值倾向于和 \\(y_i\\) 的较小值配对时，\\(x_i - \\overline{x}\\) 和 \\(y_i - \\overline{y}\\) 的符号相反，所以 \\(\\sum_{i=1}^{n}{(x_i - \\overline{x})(y_i - \\overline{y})}\\) 将是一个较大的负数。\n\n定义 2.7 对于成对数据集 \\(\\{(x_i, y_i), i = 1,...,n\\}\\)，\\(s_x\\) 和 \\(s_y\\) 分别表示 \\(x\\) 和 \\(y\\) 的样本标准差，则 \\((x_i, y_i)\\) 的样本相关系数（sample correlation coefficient）\\(r\\) 的定义如下：\n\\[\n\\begin{align}\nr&=\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(y_i-\\overline{y})}}{(n-1)s_xs_y} \\\\\n&=\\frac{\\sum_{i=1}^{n}{(x_i-\\overline{x})(y_i-\\overline{y})}}{\\sqrt{\\sum_{i=1}^{n}{(x_i-\\overline{x})^2} \\cdot \\sum_{i=1}^{n}{(y_i-\\overline{y})^2}}}\n\\end{align}\n\\tag{2.16}\\]\n\n当 \\(r \\gt 0\\) 时，成对数据集中的样本成正相关（positively correlated），当 \\(r \\lt 0\\) 时，样本成负相关（negatively correlated）。\n成对数据集的样本相关系数 \\(r\\) 具备如下的特性：\n\n\\(-1 \\le r \\le 1\\)\n\\(\\forall a&gt;0\\)， 如果 \\(y_i = ax_i + b\\)，则 \\(r=1\\)\n\\(\\forall a&lt;0\\)， 如果 \\(y_i = ax_i + b\\)，则 \\(r=-1\\)\n\\(\\forall a\\) 和 \\(\\forall c\\)，且 \\(a \\cdot c \\gt 0\\)，如果 \\(r\\) 是 \\(\\{(x_i, y_i)\\}\\) 的相关系数，则 \\(r\\) 也是 \\(\\{(ax_i + b, cy_i + d)\\}\\) 的相关系数\n\n\n特性 1 说明样本相关系数 \\(r\\) 总是介于 -1 和 +1 之间。\n特性 2 说明当成对数据之间存在线性关系并且 \\(x\\) 的较大（小）值趋向于和 \\(y\\) 的较大（小）值相关联时，\\(r\\) 等于 +1。\n特性 3 说明当成对数据之间存在线性关系并且 \\(x\\) 的较大（小）值趋向于和 \\(y\\) 的较小（大）值相关联时，\\(r\\) 等于 -1。\n特性 4 指出，当给每个 \\(x\\)（或 \\(y\\)） 变量加上一个常数，或将每个 \\(x\\)（或 \\(y\\)） 变量都乘以一个正数时，\\(r\\) 的值保持不变。特性 4 意味着 \\(r\\) 不依赖于测量数据的单位。例如，无论身高数据的测量单位是英尺还是英寸，也无论体重数据的测量单位是磅还是千克，一个人的身高和体重之间的样本相关系数都是一致的。此外，如果成对数据中的一个值是温度，那么无论该值是华氏温度还是摄氏温度，样本相关系数都是相同的。\n\n样本相关系数 \\(r\\) 的绝对值 \\(|r|\\) 用于表示 \\(x\\) 和 \\(y\\) 之间线性关系的强度。\\(|r| = 1\\) 意味着完美的线性关系，也就是说，可以用一条直线穿过 \\(\\{(xi,yi), i = 1, ..., n\\}\\) 中的所有数据点 。\\(|r| \\thickapprox 0.8\\) 意味着相对较强的线性关系，此时虽然没有任何一条直线可以穿过所有的数据点，但存在一条直线 “接近” 穿过所有的数据点。\\(|r| \\thickapprox 0.3\\) 意味着成对数据之间的线性关系相对较弱。\n\\(r\\) 的符号给定了相关性的方向。当较小的 \\(y\\) 倾向于和较小的 \\(x\\) 配对，而较大的 \\(y\\) 倾向于和较大的 \\(x\\) 配对时，对于这样的线性关系，\\(r \\gt 0\\)。而当较小的 \\(y\\) 倾向于和较大的 \\(x\\) 配对，而较大的 \\(y\\) 倾向于和较小的 \\(x\\) 配对时，对于这样的线性关系，\\(r \\lt 0\\)。图 2.11 显示了具有不同 \\(r\\) 值的数据集的散点图。\n\n代码\nlibrary(MASS)  \nlibrary(ggplot2)\n\n# 设置你想要的相关系数  \nrho &lt;- -0.5  # 例如，我们想要的相关系数是0.5  \n\n# 创建一个协方差矩阵。假设两个变量的方差都是1（对于标准化数据）  \n# 协方差矩阵的对角线元素是方差，非对角线元素是协方差（与相关系数相关）  \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf1 &lt;- as.data.frame(data)\ncolnames(df1) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 0   \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf2 &lt;- as.data.frame(data)\ncolnames(df2) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 0.9   \nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf3 &lt;- as.data.frame(data)\ncolnames(df3) &lt;- c(\"X\", \"Y\")\n\nrho &lt;- 1\nSigma &lt;- matrix(c(1, rho, rho, 1), nrow = 2)  \ndata &lt;- mvrnorm(n = 100, mu = c(0, 0), Sigma = Sigma)\ndf4 &lt;- as.data.frame(data)\ncolnames(df4) &lt;- c(\"X\", \"Y\")\n\nggplot(df1, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df2, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df3, aes(x=X, y=Y)) +\n    geom_point()\n\nggplot(df4, aes(x=X, y=Y)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) r = -0.5\n\n\n\n\n\n\n\n\n\n\n\n(b) r = 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) r = 0.9\n\n\n\n\n\n\n\n\n\n\n\n(d) r = 1\n\n\n\n\n\n\n\n图 2.11: 不同样本相关系数的数据散点图\n\n\n\n\n练习 2.10 计算 表格 2.9 所示的样本相关系数。\n\n\n答案 2.11. \n\n\n代码\ndf &lt;- read.table(\"../misc/temp_defect.csv\", header=TRUE, sep=\",\")\nr &lt;- cor(df$Temperature, df$Number.of.Defects)\nprint(r)\n\n\n[1] 0.418944\n\n\n这意味着气温和当天的缺陷产品数量之间存在着弱正相关性。\n\n\n例子 2.5 以下数据表给出了 10 个学生的静息心率（每分钟心跳次数）和其对应的受教育年限。图 2.12 展现了这些数据的散点图。这些数据的样本相关系数 \\(r=−0.7638\\)。负相关系数表明，对于这个数据集来说，高静息心率与低受教育年限紧密相关，而低静息心率则与高受教育年限紧密相关。\n\n\n代码\nlibrary(knitr)\nperson &lt;- seq(1:10)\nYears &lt;- c(12, 16, 13, 18, 19, 12, 18, 19, 12, 14)\nBPM &lt;- c(73, 67, 74, 63, 73, 84, 60, 62, 76, 71)\ndf &lt;- data.frame(Person=person, Years.of.School=Years, BPM=BPM)\n\nkable(df, align=\"l\")\n\n\n\n\n\nPerson\nYears.of.School\nBPM\n\n\n\n\n1\n12\n73\n\n\n2\n16\n67\n\n\n3\n13\n74\n\n\n4\n18\n63\n\n\n5\n19\n73\n\n\n6\n12\n84\n\n\n7\n18\n60\n\n\n8\n19\n62\n\n\n9\n12\n76\n\n\n10\n14\n71\n\n\n\n\n\n\n\n代码\nlibrary(ggplot2)\nperson &lt;- seq(1:10)\nYears &lt;- c(12, 16, 13, 18, 19, 12, 18, 19, 12, 14)\nBPM &lt;- c(73, 67, 74, 63, 73, 84, 60, 62, 76, 71)\ndf &lt;- data.frame(Person=person, Years.of.School=Years, BPM=BPM)\n\nggplot(df, aes(x=Years.of.School, y=BPM)) +\n    geom_point()\n\n\n\n\n\n\n\n\n图 2.12: 不同数据集的直方图\n\n\n\n\n\n\n\n\n\n\n\n\n相关性衡量的是变量之间的关联关系，而不是因果关系\n\n\n\n例子 2.5 中的数据集仅考虑了 10 名学生，因此不足以让人对受教育年限和心率之间的关系得出任何确凿的结论。此外，即使有更大规模的数据集，并且受教育年限高低与其静息心率之间同样存在着较强的负相关性，我们也没有理由得出 多接受几年教育会直接降低一个人的心率 的结论。也就是说，尽管高受教育年限往往与较低的静息心率有关联，但这并不意味着多受几年教育是导致较低心率的直接原因。通常，对这种关联性的解释在于，存在一个与所考虑的这两个变量都有相关性的隐藏因素。\n在 例子 2.5 中，可能是受教育年限高的人更了解健康领域的最新发现，因此可能更了解锻炼和良好营养的重要性。亦或者，可能不是知识在起作用，而是受过更多教育的人所从事的工作会让他们有更多时间进行锻炼，同时也可以获取更多薪水以补充良好的营养。受教育年限和静息心率之间的强烈负相关性可能是由受教育年限以及其他潜在因素的综合结果。\n\n\n接下来，我们将证明样本相关系数 \\(r\\) 的第一个特性：\\(|r| \\le 1\\)，当且仅当所有的数据点都在一条直线上时，\\(=\\) 成立。\n\\[\n\\begin{align}\n\\because &\\sum{(\\frac{x_i - \\overline{x}}{s_x} - \\frac{y_i - \\overline{y}}{s_y})^2} \\ge 0 \\\\\n\\therefore & \\sum{\\frac{(x_i - \\overline{x})^2}{s_x}} + \\sum{\\frac{(x_i - \\overline{x})^2}{s_x}} - 2 \\sum{\\frac{(x_i - \\overline{x})(y_i - \\overline{y})}{s_xs_y}} \\\\\n\\therefore & (n - 1) + (n - 1) -2(n - 1)r \\ge 0 \\\\\n\\therefore & 2(n - 1)(1 - r) \\ge 0 \\\\\n\\therefore & r \\le 1\n\\end{align}\n\\tag{2.17}\\]\n假设所有的数据点 \\({(x_i, y_i), i=1,...,n}\\) 都位于直线 \\(y_i = ax_i + b;\\ i=1,...n \\ \\& \\ a&gt;0\\) 上，则：\n\\[\n\\begin{align}\n& s_y^2=a^2s_x^2 \\\\\n& \\overline{y}=a\\overline{x} + b \\\\\n\\therefore & a = \\frac{s_y}{s_x}, \\ b = \\overline{y} - \\frac{s_y}{s_x}\\overline{x}\n\\end{align}\n\\tag{2.18}\\]\n根据 方程式 2.17， 当且仅当 \\(r = 1\\) 时，\\(\\sum{(\\frac{x_i - \\overline{x}}{s_x} - \\frac{y_i - \\overline{y}}{s_y})^2} = 0\\)。\n也即当且仅当 \\(r = 1\\) 时，\\(\\frac{y_i - \\overline{y}}{s_y} = \\frac{x_i - \\overline{x}}{s_x}\\)。\n所以，当且仅当 \\(r = 1\\) 时，\\(y_i = \\overline{y} - \\frac{s_y}{s_x}\\overline{x} + \\frac{s_y}{s_x}x_i\\)，把 方程式 2.18 代入得到 \\(y_i=ax_i + b\\)。\n因此，当且仅当 \\(r = 1\\) 时，\\((x_i, y_i)\\) 的所有的点都位于直线 \\(y_i = ax_i + b, a&gt;0\\)。\n同理，我们可以证明，当且仅当 \\(r = -1\\) 时，\\((x_i, y_i)\\) 的所有的点都位于直线 \\(y_i = ax_i + b, a&lt;0\\)。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_7",
    "href": "chapter_2/2.html#sec-2_7",
    "title": "2  描述统计",
    "section": "2.7 洛伦兹曲线和基尼系数",
    "text": "2.7 洛伦兹曲线和基尼系数\n洛伦兹曲线（Lorenz Curve）\\(L(p), 0 \\le p \\le 1\\)，是与群体中成员的收入相关的图表。\\(L(p)\\) 表示群体中，收入最低的 \\(100p\\%\\) 的人的总收入在群体总收入中的收入占比。例如，\\(L(0.3)\\) 是收入最低的 30% 的人的总收入在群体中的收入占比。一般来说，假设群体中有 \\(n\\) 个人，其个体收入按升序排列为 \\(x_1 \\le x_2 \\le x_3 ... \\le x_n\\)。因为 \\(x_1 + ... + x_j\\) 是收入最低的 \\(j\\) 个人的总收入，而 \\(x_1 + ... + x_n\\) 是该群体所有人的总收入。因此，收入最低的 \\(100\\frac{j}{n}\\%\\) 的人的收入占比就是：\n\\[\nL(\\frac{j}{n}) = \\frac{x_1 + ... + x_j}{x_1 + ... + x_n},\\ j = 1, ..., n\n\\]\n一般而言，令 \\(L(0) = 0\\)，并通过直线连接 \\(\\frac{j}{n}\\) 和 \\(\\frac{j + 1}{n}\\) 来绘制洛伦兹曲线。\n\n例子 2.6 假设我们想绘制 \\(n=5\\) 的洛伦兹曲线，其中该群体的收入分别是：9，7，22，5，17。该群体的收入按照升序排序后是：5，7，9，17，22。因为群体的总收入是 60，因此：\n\nL(0.2) = 5 / 60\nL(0.4) = 12 / 60\nL(0.6) = 21 / 60\nL(0.8) = 38 / 60\nL(1) = 60 /60\n\n将如上的点用直线连接起来就形成了洛伦兹曲线，如 图 2.13。\n\n\n\n代码\nlibrary(ggplot2)\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.13: 例子 2.6 的洛伦兹曲线\n\n\n\n\n\n也可以用洛伦茨曲线来展现群体中的个体财富，其中 \\(L(p)\\) 代表最贫穷的 \\(100p%\\) 的人所拥有的全部财富的比例。例如，如果全部人口由 1000 人组成，那么 \\(L(0.22)\\) 就是 220 个最贫穷的人所拥有的财富比例。\n现在，当向集合中添加一个大于之前所有值的新值时，集合的平均值总是会增加。因此，如果群体成员的收入递增排序后是 \\(x_1 \\le x_2 \\le x_3... \\le x_n\\)，那么 \\(\\forall j = 1,...,n\\)，有：\n\\[\n\\begin{align}\n& \\frac{x_1 + ... + x_j}{j} \\le \\frac{x_1 + ... + x_{j+1}}{j + 1} \\le \\frac{x_1 + ... + x_n}{n} \\\\\n\\therefore & \\frac{x_1 + ... + x_j}{x_1 + ... + x_n} \\le \\frac{j}{n} \\\\\n\\therefore & L{(\\frac{j}{n}}) \\le \\frac{j}{n}\n\\end{align}\n\\]\n此外，可以验证，当且仅当所有人的收入都相等时，\\(L(\\frac{j}{n}) = \\frac{j}{n}, j=1,...,n\\)。因此，除非所有人的收入都相等，否则洛伦茨曲线总是位于 \\((0,0)\\) 和 \\((1,1)\\) 构成的直线之下。对于 例子 2.6，图 2.14 正说明了这一点。\n\n\n代码\nlibrary(ggplot2)\n\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.14: 例子 2.6 的包含直线的洛伦兹曲线\n\n\n\n\n\n因此，当所有人的收入都相等时，洛伦茨曲线与从 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线重合；而当群体中不同个体收入不相等时，洛伦茨曲线则位于该直线的下方。当群体成员的收入越不平等，\\((0, 0)\\) 到 \\((1, 1)\\) 的直线和洛伦茨曲线之间的区域则越大（如 图 2.15 中的阴影区域所示）。\n\n\n代码\nlibrary(ggplot2)\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  annotate(\"text\", x = 0.75, y = 0.25, label = \"B\", hjust = 1, vjust = 0, size = 6) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.15: 直线[(0, 0), (1, 1)]和洛伦兹曲线之间的面积\n\n\n\n\n\n可以用基尼系数（Gini Index）衡量 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线和洛伦茨曲线之间的区域大小，进而衡量群体中成员的收入不平等性。基尼系数等于 图 2.15 中阴影区域面积与直线下方区域的面积之比。由于三角形的面积是底乘以高的一半，所以从 \\((0, 0)\\) 到 \\((1, 1)\\) 的直线下方的面积等于 \\(\\frac{1}{2}\\)。\n因此，基尼系数 \\(G\\) 的定义如下：\n\\[\nG = \\frac{L(p) 曲线和直线围成的区域面积}{\\frac{1}{2}}\n\\]\n令洛伦兹曲线下方的区域为 \\(B\\)，则洛伦兹曲线和直线围成的面积就是直线下方的面积减去洛伦兹曲线下方的面积。因此，基尼系数\n\\[\nG=\\frac{\\frac{1}{2} - B}{\\frac{1}{2}} = 1 - 2B\n\\tag{2.19}\\]\n\n练习 2.11 计算 例子 2.6 中的数据的基尼系数。\n\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[4], y=df$yf[4], xend=df$x[4], yend=0) +\n  geom_segment(x=df$x[5], y=df$yf[5], xend=df$x[5], yend=0) +\n  geom_segment(x=df$x[6], y=df$yf[6], xend=df$x[6], yend=0) +\n  annotate(\"text\", x = 0.15, y = 0.02, label = \"B1\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.3, y = 0.1, label = \"B2\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.5, y = 0.2, label = \"B3\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.7, y = 0.4, label = \"B4\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.9, y = 0.6, label = \"B5\", hjust = 1, vjust = 0, size = 3) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n图 2.16: 求解 B 的面积\n\n\n\n\n\n\n答案 2.12. 为了计算 \\(B\\) 的面积（即洛伦兹曲线下的面积），如 图 2.16 所示，我们令 \\(B = B1 + B2 + B3 + B4 + B5\\)，其中 \\(B1\\) 是0~0.2 的洛伦兹曲线下的区域面积，\\(B2\\) 是 0.2~0.4 之间的区域面积，\\(B3\\) 是 0.4~0.6 之间的区域面积，\\(B4\\) 是 0.6~0.8 之间的区域面积；\\(B5\\) 是 0.8~1 之间的区域面积。现在，\\(B1\\) 是一个三角形的面积，其底为 0.2，高为 5/60，因此：\n\\[\nB1 = \\frac{1}{2} \\cdot 0.2 \\cdot \\frac{5}{60} = \\frac{5}{600}\n\\]\n对于 \\(B2, B3, B4, B5\\) 而言，这些区域的面积由两部区域构成：顶部的三角形的面积和底部的矩形面积。如下图所示，以 \\(B2\\) 为例，其面积由 \\(B2-1\\) 和 \\(B2-2\\) 两部分构成：\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 5, 7, 9, 17, 22)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  scale_x_continuous(limits=c(0, 0.6), breaks=seq(0, 0.6, 0.2)) +\n  scale_y_continuous(limits=c(0, 0.25), breaks=seq(0, 0.25, 0.05)) +\n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[3], yend=df$yf[3]) + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[3], yend=df$yf[2], linetype=\"dashed\") +\n  annotate(\"text\", x = 0.3, y = 0.1, label = \"B2-1\", hjust = 1, vjust = 0, size = 3) +\n  annotate(\"text\", x = 0.3, y = 0.03, label = \"B2-2\", hjust = 1, vjust = 0, size = 3) +\n  labs(x=\"people proportion\", y=\"incomes proportion\")\n\n\n\n\n\n\n\n\n\n因此，所有的三角形的底的长度都是 0.2，其对应的高分别为 \\(\\frac{5}{60}, \\frac{7}{60}, \\frac{9}{60}, \\frac{17}{60}, \\frac{22}{60}\\)。因此，所有的三角形的面积为：\n\\[\nS_\\triangle = \\frac{1}{2} \\cdot 0.2 \\cdot \\frac{5+7+9+17+22}{60} = 0.1\n\\]\n四个矩形的长均是 0.2，其对应的高分别是 \\(\\frac{5}{60}, \\frac{12}{60}, \\frac{21}{60}, \\frac{38}{60}\\)。因此，所有的矩形的面积为：\n\\[\nS_\\square = 0.2 \\cdot \\frac{5 + 12 + 21 + 38}{60} \\thickapprox 0.25333\n\\]\n所以 \\(B = S_\\triangle + S_\\square =\\) \\(0.1 + 0.25333 = 0.35333\\)，故而 \\(G = 1 - 2B =\\) \\(1 - 2 \\cdot 0.35333 =\\) \\(0.29334\\)。\n\n一般而言，收入数据以升序进行排列，\\(x_1 \\le x_2 \\le x_3 \\le ... \\le x_n\\)，令 \\(s_j = x_1 + ... + x_j, j=1,...,n\\)，则洛伦兹曲线下方的所有三角形的底均是 \\(\\frac{1}{n}\\)，且其对应的高分别为 \\(\\frac{x_1}{s_n}\\)，\\(\\frac{x_2}{s_n}\\)，……，\\(\\frac{x_n}{s_n}\\)。\n因此，所有三角形的面积为：\n\\[\nS_\\triangle=\\frac{1}{2n}\\frac{(x_1 + ... + x_n)}{s_n}=\\frac{1}{2n}\n\\]\n所有的矩形的长均为 \\(\\frac{1}{n}\\)，且其对应的高分别为 \\(\\frac{s_1}{s_n}\\)，\\(\\frac{s_2}{s_n}\\)，……，\\(\\frac{s_{n-1}}{s_n}\\)。\n因此，所有矩形的面积为：\n\\[\nS_\\square = \\frac{s_1 + s_2 + ... + s_{n-1}}{ns_n}\n\\]\n所以：\n\\[\nB = \\frac{1}{2n} +  \\frac{s_1 + s_2 + ... + s_{n-1}}{ns_n}\n\\tag{2.20}\\]\n当所有人的收入都相等时，基尼系数为 0，因此直线与洛伦兹曲线之间的面积为 0。另一个极端的情况就是，当群体的 \\(n\\) 个人中，只有一个人有收入，那么此时基尼系数达到最大值。对于第二种场景，洛伦兹曲线下的面积是一个三角形的面积，其底边长度为 \\(\\frac{1}{n}\\)，高度为 1（如 图 2.17）。此时 \\(B=\\frac{1}{2n}\\)，因此 \\(G=1-\\frac{1}{n}\\)。\n\n\n代码\nx &lt;- seq(0, 1, 0.2)\ny &lt;- c(0, 0, 0, 0, 0, 60)\ny &lt;- cumsum(y)\ndf &lt;- data.frame(x=x, y=y, yf=(y / 60))\nggplot(df, aes(x=x, y=yf)) +\n  geom_line() + \n  scale_x_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  scale_y_continuous(limits=c(0, 1), breaks=seq(0, 1, 0.2)) +\n  geom_point(color = \"black\", size = 1) + \n  geom_polygon(aes(x=x, y=yf), fill=\"grey\", alpha=0.7) +\n  geom_segment(x=df$x[1], y=df$yf[1], xend=df$x[length(df$x)], yend=df$yf[length(df$yf)], color=\"red\") + \n  geom_segment(x=df$x[2], y=df$yf[2], xend=df$x[2], yend=0) +\n  geom_segment(x=df$x[3], y=df$yf[3], xend=df$x[3], yend=0) +\n  geom_segment(x=df$x[4], y=df$yf[4], xend=df$x[4], yend=0) +\n  geom_segment(x=df$x[5], y=df$yf[5], xend=df$x[5], yend=0) +\n  geom_segment(x=df$x[6], y=df$yf[6], xend=df$x[6], yend=0) +\n  labs(x=\"people proportion\", y=\"incomes proportion\") +\n  theme(  \n    axis.text.x = element_blank(),   \n    axis.text.y = element_blank(), \n  ) + \n  annotate(\"text\", x = 0.9, y = 0.25, label = \"B\", hjust = 1, vjust = 0, size = 6) +\n  annotate(\"text\", x = 0.8, y = 0, label = \"1-(1/n)\", hjust = 1, vjust = 0, size = 3) + \n  annotate(\"text\", x = 1, y = 0, label = \"1\", hjust = 1, vjust = 0, size = 3) + \n  annotate(\"text\", x = 0, y = 1, label = \"1\", hjust = 1, vjust = 0, size = 3)\n\n\n\n\n\n\n\n\n图 2.17: 最大基尼系数",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#sec-2_8",
    "href": "chapter_2/2.html#sec-2_8",
    "title": "2  描述统计",
    "section": "2.8 R",
    "text": "2.8 R\n如果我们要计算 \\(x_1,...,x_n\\) 的样本均值和样本方差，我们可以在 R 中输入：\nx &lt;- c(x_1,...,x_n)\n然后可以按下 回车 键，并输入 mean(x)，然后当再次按下 回车 时，就会打印出样本均值。当输入 var(x)，然后按下 回车 时，就会打印出样本方差。\n例如，我们要计算：4，6，12，9，21，14 的样本均值和样本方差，我们可以用 R 按照如下方式获取：\n&gt; x &lt;- c(4,6,12,9,21,14)\n&gt; mean(x)\n[1] 11\n&gt; var(x)\n[1] 37.6\n&gt; \n在 R 中，我们不需要输入行首的 &gt;，R 会自动为每一行补充提示符 &gt;，以提示我们输入代码。R 中的命令还有：\n\nsum(x)：返回向量 x 中所有数据的和。\nmedian(x)：返回向量 x 中的所有数据的中位数。\nsd(x)：返回向量 x 中所有数据的标准差。\n\n如果 \\(x=c(x_1,...,x_n)\\)，\\(y=c(y_1,...,y_n)\\)，则：\n\n\\(x+y=c(x_1+y_1,...,x_n+y_n)\\)\n\\(x-y=c(x_1-y_1,...,x_n-y_n)\\)\n\\(x^2=c(x_1^2,...,x_n^2)\\)\n\\(\\frac{x}{y}=c(\\frac{x_1}{y_1},...,\\frac{x_n}{y_n}), \\ \\forall y_i \\ne 0\\)\n\n如果 \\(a\\) 是一个实数，则：\n\n\\(a + x = c(a+x_1,...,a+x_n)\\)\n\\(ax = c(ax_1,...,ax_n)\\)\n\\(\\frac{x}{a}=c(\\frac{x_1}{a},...,\\frac{x_n}{a}), \\ \\forall a \\ne 0\\)\n\\(\\frac{a}{x}=c(\\frac{a}{x_1},...,\\frac{a}{x_n}), \\ \\forall x_i \\ne 0\\)\n\n对于成对数据 \\(\\{(x_i,y_i)\\}, \\ i=1,...,n\\)，我们可以使用如下命令获取其相关系数：\n&gt; x &lt;- c(x1,...,xn) \n&gt; y &lt;- c(y1,...,yn) \n&gt; cor(x, y)\n可以用 plot(x, y) 获取 \\(\\{(x_i,y_i)\\}\\) 的散点图：\n&gt; plot(x, y)\n假设我们有如下的数据：(4,10), (6,13), (12,22), (9,15), (21,30), (14,15)，我们可以使用如下的 R 命令获取其样本相关系数和散点图：\n\n\n代码\nx &lt;- c(4, 6, 12, 9, 21, 14)\ny &lt;- c(10, 13, 22, 15, 30, 15) \ncor(x, y)\n\n\n[1] 0.9041494\n\n\n代码\nplot(x, y)\n\n\n\n\n\n\n\n\n\nR 还可以用于数学计算，例如我们可以使用如下命令计算 \\(\\frac{18\\sqrt{177}}{677}\\)：\n\n\n代码\n18*sqrt(177)/677 \n\n\n[1] 0.3537288\n\n\n\n如果我们从向量 x &lt;- c(x1, ..., xn) 中选择第 \\(i\\) 个位置的元素 \\(x_i\\)，我们可以使用命令 x[i]。\n如果希望从向量 x 中选择 \\(i\\) 到 \\(j\\) 的元素并构成一个新的向量，我们可以使用命令 x[i:j]。\n\n\n\n代码\nx &lt;- c(3, 18, 9, 7, 22, 5, 17)\nx[3]\n\n\n[1] 9\n\n\n代码\nx[2:5]\n\n\n[1] 18  9  7 22\n\n\n我们可以使用 R 计算基尼系数。对于向量 x &lt;- c(x1, ..., xn)，先利用 sort(x) 得到 关于向量 x 中数据的递增排序。\n\n\n代码\nx &lt;- c(9, 7, 22, 5, 17)\nsort(x)\n\n\n[1]  5  7  9 17 22\n\n\n如果我们想使用 方程式 2.19 和 方程式 2.20 来计算 练习 2.11 中的基尼系数，我们可以使用如下的代码：\n\n\n代码\ny &lt;- c(9, 7, 22, 5, 17)\nx &lt;- sort(y)\ns &lt;- cumsum(x)[1:4]\nB &lt;- 1/10 + sum(s) / (5 * sum(x))\nG &lt;- 1 - 2 * B\nG \n\n\n[1] 0.2933333\n\n\n我们也可以在 R 中定义 函数。例如，我们想在 R 中定义函数 \\(f\\) 以实现 \\(f(x) = x^2\\)，可以使用如下的代码：\n\n\n代码\nf = function(x){x * x}\nf(4)\n\n\n[1] 16\n\n\n如果我们想实现 \\(f(x) = e^x\\)，可以使用如下的代码：\n\n\n代码\nf = function(x){exp(x)}\nf(1)\n\n\n[1] 2.718282\n\n\n使用 函数 的概念，我们可以使用如下的代码以获取 9, 7, 22, 5, 17 的基尼系数：\n\n\n代码\ns = function(x, j){sum(x[1:j])}\n\ny &lt;- c(9, 7, 22, 5, 17)\nx &lt;- sort(y)\nB &lt;- 1/10 + (s(x, 1) + s(x, 2) + s(x, 3) + s(x, 4)) / (5 * s(x, 5))\nG &lt;- 1 - 2 * B\nG \n\n\n[1] 0.2933333",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_2/2.html#问题",
    "href": "chapter_2/2.html#问题",
    "title": "2  描述统计",
    "section": "问题",
    "text": "问题\n\n以下是 1997 年 6 月，旧金山湾区每加仑标准无铅汽油的价格的样本数据。\n3.88, 3.90, 3.93, 3.90, 3.93, 3.96, 3.88, 3.94, 3.96, 3.88, 3.94, 3.99, 3.98\n使用如下的方式对数据进行描述：\n\n频率表\n相对频率的线图\n\n解释一下如何构建一个饼图。如果数据集中的某个数据值的相对频率为 r，那么在饼图中，该扇区将会位于什么角度？\n以下是西半球四个地区的石油储量估计数据（以十亿桶为单位）：\n\nUnited States 38.7\nSouth America 22.6\nCanada 8.8\nMexico 60.0\n\n请使用饼图来描述如上的数据。\n选择一本书或一篇文章，计算前 100 个句子中每个句子的单词数，并使用茎叶图来展现这些数据。现在选择另一本由不同作者撰写的书或文章，并做同样的操作。这两个茎叶图看起来是否相似？你认为这种方法能否有效地判断不同的文章是否由不同的作者所写？\n以下是每日上班通勤时间（以分钟为单位）的频率表：\n\n\n\nTravel time\nFrequency\n\n\n\n\n15\n6\n\n\n18\n5\n\n\n22\n4\n\n\n23\n3\n\n\n24\n4\n\n\n25\n2\n\n\n26\n4\n\n\n32\n3\n\n\n36\n1\n\n\n48\n1\n\n\n\n\n频率表中的数据包含了几天的数据？\n频率表中的总的通勤时间是多少？\n\n表格 2.10 列出了 1985 年至 2006 年间，美国商业航空事故的次数以及由此造成的死亡总人数。\n\n绘制事故数的频率表\n绘制事故数的折线图\n绘制事故数的累积相对频率图\n计算事故数的样本均值\n计算事故数的样本中位数\n找出事故数的样本众数\n计算事故数的样本标准差\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- read.table(\"../misc/US_airline.csv\", header=TRUE, sep=\",\")\nkable(df, align=\"l\")\n\n\n\n\n表格 2.10: 美国商业航空公司 1985~2006 安全数据，数据来源： National Transportation Safety Board。\n\n\n\n\n\n\nYear\nDepartures..millions.\nAccidents\nFatalities\n\n\n\n\n1985\n6.1\n4\n197\n\n\n1986\n6.4\n2\n5\n\n\n1987\n6.6\n4\n231\n\n\n1988\n6.7\n3\n285\n\n\n1989\n6.6\n11\n278\n\n\n1990\n7.8\n6\n39\n\n\n1991\n7.5\n4\n62\n\n\n1992\n7.5\n4\n33\n\n\n1993\n7.7\n1\n1\n\n\n1994\n7.8\n4\n239\n\n\n1995\n8.1\n2\n166\n\n\n1996\n7.9\n3\n342\n\n\n1997\n9.9\n3\n3\n\n\n1998\n10.5\n1\n1\n\n\n1999\n10.9\n2\n12\n\n\n2000\n11.1\n2\n89\n\n\n2001\n10.6\n6\n531\n\n\n2002\n10.3\n0\n0\n\n\n2003\n10.2\n2\n22\n\n\n2004\n10.8\n1\n13\n\n\n2005\n10.9\n3\n22\n\n\n2006\n11.2\n2\n50\n\n\n\n\n\n\n\n\n\n根据 表格 2.10 的数据，\n\n绘制事故导致的死亡人数的直方图\n绘制事故导致的死亡人数的茎叶图\n计算事故导致的死亡人数的的样本均值\n计算事故导致的死亡人数的的样本中位数\n计算事故导致的死亡人数的的样本标准差\n\nA 镇成年女性的体重样本均值大于 B 镇成年女性的体重样本均值。此外，A 镇成年男性的体重样本均值也大于 B 镇成年男性的体重样本均值。我们是否可以得出结论：A 镇成年人的体重样本均值大于 B 镇成年人的体重样本均值？请给出你的解释。\n首位数定律（Benford’s law for first digits）指出：在许多现实生活中的数值数据集中，首位数字并不是以相等的比例出现，而是偏向于较小的数字。更具体地说，首位数定律指出，首位非零数字为 \\(i, i=1,...,9\\) 的数据比例大约为 \\(log_{10}{(i+1)}\\)。例如，\\(log_{10}{(2)}=0.301\\)，这表明大约 30.1% 的数据的首位数字是 1。表格 2.11 给出了首位数定律中以 1~9 作为首位数字的数据的比例。\n有趣的是，首位数定律已被证明可以适用于各种现实生活数据集，包括电费账单、街道地址、股票价格、人口数量、死亡率、河流长度、物理和数学常数，并且当数据值广泛分布时似乎最为准确。首位数定律最初是由美国天文学家西蒙・纽科姆（Simon Newcomb）在 1881 年发表的。1938 年，物理学家弗兰克・本福德（Frank Benford）在 20 个不同领域的数据集上测试了首位数定律，并表明在大多数情况下它都是一个很好的拟合。弗兰克・本福德测试的数据包括：河流的表面积、美国城市的人口规模、物理常数和分子量（molecular weights）等。\n物理考试中的一个多选题为：以下哪个是 20℃ 下，100% 过氧化氢溶液的密度（单位为 \\(g/{cm}^3\\)），(a) 7.3316、(b) 6.2421、(c) 1.4512、(d) 8.1818。如果你对过氧化氢一无所知，你会猜哪个答案是正确的？\n\n\n\n表格 2.11: 首位数定律\n\n\n\n\n\nFirst digit\nProportion of data having it as first digit\n\n\n\n\n1\n0.301\n\n\n2\n0.176\n\n\n3\n0.125\n\n\n4\n0.097\n\n\n5\n0.079\n\n\n6\n0.067\n\n\n7\n0.058\n\n\n8\n0.051\n\n\n9\n0.046\n\n\n\n\n\n\nA 公司总共有 100 名员工，而 B 公司总共有 110 名员工。假设 A 公司的所有员工的薪水总和比 B 公司高。\n\n对于 A 公司工资的中位数与 B 公司工资的中位数来说意味着什么？\n对于 A 公司工资的平均数与 B 公司工资的平均数来说意味着什么？\n\n一个包含 198 个数据的数据集中，前 99 个数据的样本均值等于 120，而后 99 个数据的样本均值等于 100。关于整个数据集的样本均值，你能得出什么结论？\n\n关于整个数据集的样本中位数，你能得出什么结论？\n关于整个数据集的样本众数，你能得出什么结论？\n\n下表给出了 1922 年英格兰的重大道路交通事故中，按照年龄、性别汇总的行人死亡人数数据。\n\n估算男性年龄的样本均值\n估算女性年龄的样本均值\n估算死亡男性的四分位数\n估算死亡女性的四分位数\n\n\n\n\nAge Range\nNumber of Males\nNumber of Females\n\n\n\n\n0-5\n120\n67\n\n\n5-10\n184\n120\n\n\n10-15\n44\n22\n\n\n15-20\n24\n15\n\n\n20-30\n23\n25\n\n\n30-40\n50\n22\n\n\n40-50\n60\n40\n\n\n50-60\n102\n76\n\n\n60-70\n167\n104\n\n\n70-80\n150\n90\n\n\n80-100\n49\n27\n\n\n\n以下是 12 个相邻位置发现的煤炭样本中的含灰量占比数据：\n9.2, 14.1, 9.8, 12.4, 16.0, 12.6, 22.7, 18.9, 21.0, 14.5, 20.4, 16.9\n\n计算如上数据的样本均值\n计算如上数据的样本标准差\n\n5 个数据的样本均值和样本方差分别是 \\(\\overline{x} = 104\\)，\\(s^2 = 16\\)，如果其中的 3 个数是 102， 100， 105，另外两个数是什么？\n假设你得到了美国 50 个州中每个州所有工人的平均工资。\n\n你认为这 50 个州的平均工资的样本均值会等于整个美国的工人平均工资吗？\n如果对（a）的回答是否定的，请解释除了这 50 个平均值之外，还需要什么其他信息来确定整个国家的样本平均薪资。同时，解释你将如何使用这些额外信息来计算这个整个美国的工人平均工资。\n\n如下是 40 个晶体管的使用寿命（单位为小时）：\n112, 121, 126, 108, 141, 104, 136, 134, \n121, 118, 143, 116, 108, 122, 127, 140,\n113, 117, 126, 130, 134, 120, 131, 133,\n118, 125, 151, 147, 137, 140, 132, 119,\n110, 124, 132, 152, 135, 130, 136, 128\n\n计算如上数据的样本均值、样本中位数、样本众数\n给出如上数据的累积相对频率图\n\n一个实验测量了 50 个粘土样本干燥后的收缩比率，并记录了以下数据：\n18.2 21.2 23.1 18.5 15.6 20.8 19.4 15.4 21.2 13.4 \n16.4 18.7 18.2 19.6 14.3 16.6 24.0 17.6 17.8 20.2 \n17.4 23.6 17.5 20.3 16.6 19.3 18.5 19.3 21.2 13.9 \n20.5 19.0 17.6 22.3 18.4 21.2 20.4 21.4 20.3 20.1 \n19.6 20.6 14.8 19.7 20.5 18.0 20.8 15.8 23.1 17.0\n\n\n画出如上数据的茎叶图\n\n\n计算样本均值，样本中位数，样本众数\n\n\n计算样本方差\n\n\n从 13% 开始，以 1% 为间隔将如上的数据进行分组，并绘制直方图\n\n\n对于分组数据而言，假设每个数据点实际上位于其所在区间的中点，计算样本均值和样本方差，并与 (b) 和 (c) 的结果进行比较。为什么它们会不同？\n\n\n如下是计算 \\(\\{x_i;\\ i=1,...,n\\}\\) 样本均值和样本方差的一种快速算法。首先计算前 \\(j(j \\ge 2)\\) 个数据的样本均值和方差：\\(\\overline{x}_j = \\frac{\\sum_{i=1}^{j}{x_i}}{j}\\)，\\(s_j^2=\\frac{\\sum_{i=1}^{j}{(x_i - \\overline{x})^2}}{j - 1}\\)。其中，\\(\\overline{x}_1 = x_1\\)，\\(s_1^2 = 0\\)。则：\n\\[\n\\begin{align}\n& \\overline{x}_{j+1} = \\overline{x}_j + \\frac{x_{j + 1} - \\overline{x}}{j + 1} \\\\\n& s_{j+1}^2 = (1 - \\frac{1}{j})s_j^2 + (j + 1)(\\overline{x}_{j+1} - \\overline{x}_j)^2\n\\end{align}\n\\]\n\n\n使用如上的算法计算 3, 4, 7, 2, 9, 6 的样本均值和样本方差\n\n\n使用普通的计算方式来校验 (a) 的结果\n\n\n验证如上算法中的 \\(\\overline{x}_{j+1}\\) 和 \\(\\overline{x}_{j}\\) 的关系\n\n\n对于 表格 2.5 的数据，\n\n计算 1 月的平均气温的 90-分位值\n计算 7 月的平均气温的 75-分位值\n\n根据 《纽约时报》在 2013 年 8 月 1 日两周前发布的讣告，找出如下的死亡年龄的四分位数。\n92, 90, 92, 74, 69, 80, 94, 98, 65, 96, \n84, 69, 86, 91, 88, 74, 97, 85, 88, 68, \n77, 94, 88, 65, 76, 75, 60, 69, 97, 92, \n85, 70, 80, 93, 91, 68, 82, 78, 89\n我们按照各个大学在谷歌上的月搜索量对大学进行月度排名，在截止到 2013 年 6 月的 114 个月中，获得过月榜单 TOP 10 的大学的上榜次数如下表所示。\n\n\n\n\n\n\n\nUniversity\nNumber of Months in Top 10\n\n\n\n\nHarvard University\n114\n\n\nUniversity of Texas, Austin\n114\n\n\nUniversity of Michigan\n114\n\n\nStanford University\n113\n\n\nUniversity of California Los Angeles (UCLA)\n111\n\n\nUniversity of California Berkeley\n97\n\n\nPenn State University\n94\n\n\nMassachusetts Institute of Technology (MIT)\n66\n\n\nUniversity of Southern California (USC)\n63\n\n\nOhio State University\n52\n\n\nYale University\n48\n\n\nUniversity of Washington\n33\n\n\n\n\n计算样本均值\n计算样本方差\n计算样本的四分位数\n\n填写缺失的单词或短语以完成以下句子：“如果向一组数字中增加一个新的数字，如果新的数字____，则该数组的样本均值将增加。”\n用箱线图表示第 20 题中的数据。\n在一个石油化工企业中，在 36 个随机选择的时间点测量了平均颗粒物浓度（单位为 \\(mg/m^3\\)），得到了如下的浓度数据：\n5, 18,  15, 7,  23, 220, 130, 85, 103, 25, \n80, 7,  24, 6,  13, 65,  37,  25, 24,  65, \n82, 95, 77, 15, 70, 110, 44,  28, 33,  81, \n29, 14, 45, 92, 17, 53\n\n使用直方图描述如上数据\n如上的直方图是近似正态直方图吗？\n\n一位化学工程师想要研究盐水蒸发池中水的蒸发率，他获得了 4 年中盐水蒸发池 7 月份每天蒸发英寸数的 55 个数据。这些数据以下面的茎叶图给出，其最小数据为 0.02 英寸，最大数据为 0.56 英寸。\n.0    2,6\n.1    1,4\n.2    1,1,1,3,3,4,5,5,5,6,9\n.3    0,0,2,2,2,3,3,3,3,4,4,5,5,5,6,6,7,8,9 \n.4    0,1,2,2,2,3,4,4,4,5,5,5,7,8,8,8,9,9 \n.5    2,5,6\n计算如上数据的：\n\n样本均值\n样本中位数\n样本标准差\n如上的数据看起来符合近似正态分布吗？\n位于样本均值 1 个标准差以内的数据占比是多少？\n\n以下是加利福尼亚大学伯克利分校工业工程与运筹学系录取的最近 30 名学生的 GPA（grade point averages）。\n3.46, 3.72, 3.95, 3.55, 3.62, 3.80, 3.86, 3.71, 3.56, 3.49, \n3.96, 3.90, 3.70, 3.61, 3.72, 3.65, 3.48, 3.87, 3.82, 3.91, \n3.69, 3.67, 3.72, 3.66, 3.79, 3.75, 3.93, 3.74, 3.50, 3.83\n\n\n使用茎叶图来绘制如上的数据\n\n\n计算样本均值 \\(\\overline{x}\\)\n\n\n计算样本标准差 \\(s\\)\n\n\n计算位于 \\([\\overline{x} - 1.5s, \\overline{x} + 1.5s]\\) 的数据比例，并和切比雪夫不等式给出的下限比例进行对比\n\n\n计算位于 \\([\\overline{x} - 2s, \\overline{x} + 2s]\\) 的数据比例，并和切比雪夫不等式给出的下限比例进行对比\n\n\n第 26 题中的数据是否近似于正态分布？对于第 26 题的 (d) 和 (e) ，请使用经验法则给出的近似占比与实际占比进行比较。\n你是否期望一个健身俱乐部所有会员的体重直方图会近似于正态分布？\n对于第 16 题中的数据：\n\n\n计算样本均值和样本中位数\n\n\n这些数据符合近似正态分布吗？\n\n\n计算样本标准差 \\(s\\)\n\n\n计算位于 \\([\\overline{x} - 1.5s, \\overline{x} + 1.5]\\) 区间的数据的占比\n\n\n对比 (d) 的结果和经验法则给出的结果\n\n\n对比 (d) 的结果和切比雪夫不等式给出的结果\n\n\n以下是 12 名考试成绩大致相同的法学院学生的身高和起薪数据：\n\n\n\nHeight (inches)\nSalary\n\n\n\n\n64\n91\n\n\n65\n94\n\n\n66\n88\n\n\n67\n103\n\n\n69\n77\n\n\n70\n96\n\n\n72\n105\n\n\n72\n88\n\n\n74\n122\n\n\n74\n102\n\n\n75\n90\n\n\n76\n114\n\n\n\n\n绘制数据的散点图\n计算样本相关系数\n\n根据人们的站立姿势数据形成一个随机样本。针对样本中的人，还额外记录了每个人在过去一年中经历背痛的天数。令研究人员惊讶的是，这些数据表明良好的站姿与背痛天数之间存在正相关关系。这是否意味着良好的站姿会导致背痛？\n如果我们把美国 50 个州中每个州的居民平均收入和居住在该州的外国出生的移民数量绘制为成对的数据图，那么这些成对数据将呈现正相关关系。我们能否得出结论，移民居民往往比土生土长的美国人的收入更高？如果不是，还能如何解释这个现象？\n随机抽取 12 名高中三年级学生，并要求他们估算自己每周平均学习的小时数。以下的数据给出了估算结果和学生的 GPA。\n\n\n\nHours\nGPA\n\n\n\n\n6\n2.8\n\n\n14\n3.2\n\n\n3\n3.1\n\n\n22\n3.6\n\n\n9\n3.0\n\n\n11\n3.3\n\n\n12\n3.4\n\n\n5\n2.7\n\n\n18\n3.1\n\n\n24\n3.8\n\n\n15\n3.0\n\n\n17\n3.9\n\n\n\n\n计算学习小时数和 GPA 之间的样本相关系数。\n\n验证样本相关系数的特性 3。\n验证样本相关系数的特性 4。\n在一项针对二至四年级的儿童研究中，研究人员针对每个学生都做了阅读测试。在研究结果数据时，研究人员注意到学生的阅读测试分数和身高之间存在正相关关系。研究人员得出结论，身高较高的孩子阅读能力更好，因为他们可以更容易地看到黑板。你认为呢？\n最近的一项研究发现，母乳喂养的婴儿与 6 岁时进行的词汇测试分数之间存在正相关关系。讨论在解释这项研究结果时可能遇到的困难。\n一个群体的收入分别为 25、32、60、40、38、50，绘制其洛伦茨曲线并计算其基尼系数。\n根据如下的年收入（以千美元为单位）频率表，绘制该群体的洛伦茨曲线并计算其基尼系数：\n\n\n\nValue\nFrequency\n\n\n\n\n30\n2\n\n\n50\n4\n\n\n60\n5\n\n\n90\n4\n\n\n100\n3\n\n\n120\n2\n\n\n\n如果样本中所有的数据都乘以一个大于 0 的常数 \\(c\\)，基尼系数将会发生什么变化？如果样本中所有的数据都加上一个大于 0 的常数 \\(c\\)，基尼系数又会发生什么变化？下降，保持不变，还是不好说？",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>描述统计</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html",
    "href": "chapter_3/3.html",
    "title": "3  Elements of probability",
    "section": "",
    "text": "3.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sample-space-and-events",
    "href": "chapter_3/3.html#sample-space-and-events",
    "title": "3  Elements of probability",
    "section": "3.2 Sample space and events",
    "text": "3.2 Sample space and events",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#venn-diagrams-and-the-algebra-of-events",
    "href": "chapter_3/3.html#venn-diagrams-and-the-algebra-of-events",
    "title": "3  Elements of probability",
    "section": "3.3 Venn diagrams and the algebra of events",
    "text": "3.3 Venn diagrams and the algebra of events",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#axioms-of-probability",
    "href": "chapter_3/3.html#axioms-of-probability",
    "title": "3  Elements of probability",
    "section": "3.4 Axioms of probability",
    "text": "3.4 Axioms of probability",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#sample-spaces-having-equally-likely-outcomes",
    "href": "chapter_3/3.html#sample-spaces-having-equally-likely-outcomes",
    "title": "3  Elements of probability",
    "section": "3.5 Sample spaces having equally likely outcomes",
    "text": "3.5 Sample spaces having equally likely outcomes",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#conditional-probability",
    "href": "chapter_3/3.html#conditional-probability",
    "title": "3  Elements of probability",
    "section": "3.6 Conditional probability",
    "text": "3.6 Conditional probability",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#bayes-formula",
    "href": "chapter_3/3.html#bayes-formula",
    "title": "3  Elements of probability",
    "section": "3.7 Bayes’ formula",
    "text": "3.7 Bayes’ formula",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#independent-events",
    "href": "chapter_3/3.html#independent-events",
    "title": "3  Elements of probability",
    "section": "3.8 Independent events",
    "text": "3.8 Independent events",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_3/3.html#problems",
    "href": "chapter_3/3.html#problems",
    "title": "3  Elements of probability",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Elements of probability</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html",
    "href": "chapter_4/4.html",
    "title": "4  Random variables and expectation",
    "section": "",
    "text": "4.1 Random variables",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#types-of-random-variables",
    "href": "chapter_4/4.html#types-of-random-variables",
    "title": "4  Random variables and expectation",
    "section": "4.2 Types of random variables",
    "text": "4.2 Types of random variables",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#jointly-distributed-random-variables",
    "href": "chapter_4/4.html#jointly-distributed-random-variables",
    "title": "4  Random variables and expectation",
    "section": "4.3 Jointly distributed random variables",
    "text": "4.3 Jointly distributed random variables",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#expectation",
    "href": "chapter_4/4.html#expectation",
    "title": "4  Random variables and expectation",
    "section": "4.4 Expectation",
    "text": "4.4 Expectation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#properties-of-the-expected-value",
    "href": "chapter_4/4.html#properties-of-the-expected-value",
    "title": "4  Random variables and expectation",
    "section": "4.5 Properties of the expected value",
    "text": "4.5 Properties of the expected value",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#variance",
    "href": "chapter_4/4.html#variance",
    "title": "4  Random variables and expectation",
    "section": "4.6 Variance",
    "text": "4.6 Variance",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#covariance-and-variance-of-sums-of-random-variables",
    "href": "chapter_4/4.html#covariance-and-variance-of-sums-of-random-variables",
    "title": "4  Random variables and expectation",
    "section": "4.7 Covariance and variance of sums of random variables",
    "text": "4.7 Covariance and variance of sums of random variables",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#moment-generating-functions",
    "href": "chapter_4/4.html#moment-generating-functions",
    "title": "4  Random variables and expectation",
    "section": "4.8 Moment generating functions",
    "text": "4.8 Moment generating functions",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#chebyshevs-inequality-and-the-weak-law-of-large-numbers",
    "href": "chapter_4/4.html#chebyshevs-inequality-and-the-weak-law-of-large-numbers",
    "title": "4  Random variables and expectation",
    "section": "4.9 Chebyshev’s inequality and the weak law of large numbers",
    "text": "4.9 Chebyshev’s inequality and the weak law of large numbers",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_4/4.html#problems",
    "href": "chapter_4/4.html#problems",
    "title": "4  Random variables and expectation",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Random variables and expectation</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html",
    "href": "chapter_5/5.html",
    "title": "5  Special random variables",
    "section": "",
    "text": "5.1 The Bernoulli and binomial random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-poisson-random-variable",
    "href": "chapter_5/5.html#the-poisson-random-variable",
    "title": "5  Special random variables",
    "section": "5.2 The Poisson random variable",
    "text": "5.2 The Poisson random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-hypergeometric-random-variable",
    "href": "chapter_5/5.html#the-hypergeometric-random-variable",
    "title": "5  Special random variables",
    "section": "5.3 The hypergeometric random variable",
    "text": "5.3 The hypergeometric random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-uniform-random-variable",
    "href": "chapter_5/5.html#the-uniform-random-variable",
    "title": "5  Special random variables",
    "section": "5.4 The uniform random variable",
    "text": "5.4 The uniform random variable",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#normal-random-variables",
    "href": "chapter_5/5.html#normal-random-variables",
    "title": "5  Special random variables",
    "section": "5.5 Normal random variables",
    "text": "5.5 Normal random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#exponential-random-variables",
    "href": "chapter_5/5.html#exponential-random-variables",
    "title": "5  Special random variables",
    "section": "5.6 Exponential random variables",
    "text": "5.6 Exponential random variables",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-gamma-distribution",
    "href": "chapter_5/5.html#the-gamma-distribution",
    "title": "5  Special random variables",
    "section": "5.7 The gamma distribution",
    "text": "5.7 The gamma distribution",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#distributions-arising-from-the-normal",
    "href": "chapter_5/5.html#distributions-arising-from-the-normal",
    "title": "5  Special random variables",
    "section": "5.8 Distributions arising from the normal",
    "text": "5.8 Distributions arising from the normal",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#the-logistics-distribution",
    "href": "chapter_5/5.html#the-logistics-distribution",
    "title": "5  Special random variables",
    "section": "5.9 The logistics distribution",
    "text": "5.9 The logistics distribution",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#distributions-in-r",
    "href": "chapter_5/5.html#distributions-in-r",
    "title": "5  Special random variables",
    "section": "5.10 Distributions in R",
    "text": "5.10 Distributions in R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_5/5.html#problems",
    "href": "chapter_5/5.html#problems",
    "title": "5  Special random variables",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Special random variables</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html",
    "href": "chapter_6/6.html",
    "title": "6  Distributions of sampling statistics",
    "section": "",
    "text": "6.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-sample-mean",
    "href": "chapter_6/6.html#the-sample-mean",
    "title": "6  Distributions of sampling statistics",
    "section": "6.2 The sample mean",
    "text": "6.2 The sample mean",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-central-limit-theorem",
    "href": "chapter_6/6.html#the-central-limit-theorem",
    "title": "6  Distributions of sampling statistics",
    "section": "6.3 The central limit theorem",
    "text": "6.3 The central limit theorem",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#the-sample-variance",
    "href": "chapter_6/6.html#the-sample-variance",
    "title": "6  Distributions of sampling statistics",
    "section": "6.4 The sample variance",
    "text": "6.4 The sample variance",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#sampling-distributions-from-a-normal-population",
    "href": "chapter_6/6.html#sampling-distributions-from-a-normal-population",
    "title": "6  Distributions of sampling statistics",
    "section": "6.5 Sampling distributions from a normal population",
    "text": "6.5 Sampling distributions from a normal population",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#sampling-from-a-finite-population",
    "href": "chapter_6/6.html#sampling-from-a-finite-population",
    "title": "6  Distributions of sampling statistics",
    "section": "6.6 Sampling from a finite population",
    "text": "6.6 Sampling from a finite population",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_6/6.html#problems",
    "href": "chapter_6/6.html#problems",
    "title": "6  Distributions of sampling statistics",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Distributions of sampling statistics</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html",
    "href": "chapter_7/7.html",
    "title": "7  Parameter estimation",
    "section": "",
    "text": "7.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#maximum-likelihood-estimators",
    "href": "chapter_7/7.html#maximum-likelihood-estimators",
    "title": "7  Parameter estimation",
    "section": "7.2 Maximum likelihood estimators",
    "text": "7.2 Maximum likelihood estimators",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#interval-estimates",
    "href": "chapter_7/7.html#interval-estimates",
    "title": "7  Parameter estimation",
    "section": "7.3 Interval estimates",
    "text": "7.3 Interval estimates",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#estimating-the-difference-in-means-of-two-normal-populations",
    "href": "chapter_7/7.html#estimating-the-difference-in-means-of-two-normal-populations",
    "title": "7  Parameter estimation",
    "section": "7.4 Estimating the difference in means of two normal populations",
    "text": "7.4 Estimating the difference in means of two normal populations",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#approximate-confidence-interval-for-the-mean-of-a-bernoulli-random-variable",
    "href": "chapter_7/7.html#approximate-confidence-interval-for-the-mean-of-a-bernoulli-random-variable",
    "title": "7  Parameter estimation",
    "section": "7.5 Approximate confidence interval for the mean of a Bernoulli random variable",
    "text": "7.5 Approximate confidence interval for the mean of a Bernoulli random variable",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#confidence-interval-of-the-mean-of-the-exponential-distribution",
    "href": "chapter_7/7.html#confidence-interval-of-the-mean-of-the-exponential-distribution",
    "title": "7  Parameter estimation",
    "section": "7.6 Confidence interval of the mean of the exponential distribution",
    "text": "7.6 Confidence interval of the mean of the exponential distribution",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#evaluating-a-point-estimator",
    "href": "chapter_7/7.html#evaluating-a-point-estimator",
    "title": "7  Parameter estimation",
    "section": "7.7 Evaluating a point estimator",
    "text": "7.7 Evaluating a point estimator",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#the-bayes-estimator",
    "href": "chapter_7/7.html#the-bayes-estimator",
    "title": "7  Parameter estimation",
    "section": "7.8 The Bayes estimator",
    "text": "7.8 The Bayes estimator",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_7/7.html#problems",
    "href": "chapter_7/7.html#problems",
    "title": "7  Parameter estimation",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Parameter estimation</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html",
    "href": "chapter_8/8.html",
    "title": "8  Hypothesis testing",
    "section": "",
    "text": "8.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#significance-levels",
    "href": "chapter_8/8.html#significance-levels",
    "title": "8  Hypothesis testing",
    "section": "8.2 Significance levels",
    "text": "8.2 Significance levels",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#tests-concerning-the-mean-of-a-normal-population",
    "href": "chapter_8/8.html#tests-concerning-the-mean-of-a-normal-population",
    "title": "8  Hypothesis testing",
    "section": "8.3 Tests concerning the mean of a normal population",
    "text": "8.3 Tests concerning the mean of a normal population",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#testing-the-equality-of-means-of-two-normal-populations",
    "href": "chapter_8/8.html#testing-the-equality-of-means-of-two-normal-populations",
    "title": "8  Hypothesis testing",
    "section": "8.4 Testing the equality of means of two normal populations",
    "text": "8.4 Testing the equality of means of two normal populations",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#hypothesis-tests-concerning-the-variance-of-a-normal-population",
    "href": "chapter_8/8.html#hypothesis-tests-concerning-the-variance-of-a-normal-population",
    "title": "8  Hypothesis testing",
    "section": "8.5 Hypothesis tests concerning the variance of a normal population",
    "text": "8.5 Hypothesis tests concerning the variance of a normal population",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#hypothesis-tests-in-bernoulli-populations",
    "href": "chapter_8/8.html#hypothesis-tests-in-bernoulli-populations",
    "title": "8  Hypothesis testing",
    "section": "8.6 Hypothesis tests in Bernoulli populations",
    "text": "8.6 Hypothesis tests in Bernoulli populations",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#tests-concerning-the-mean-of-a-poisson-distribution",
    "href": "chapter_8/8.html#tests-concerning-the-mean-of-a-poisson-distribution",
    "title": "8  Hypothesis testing",
    "section": "8.7 Tests concerning the mean of a Poisson distribution",
    "text": "8.7 Tests concerning the mean of a Poisson distribution",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_8/8.html#problems",
    "href": "chapter_8/8.html#problems",
    "title": "8  Hypothesis testing",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hypothesis testing</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html",
    "href": "chapter_9/9.html",
    "title": "9  Regression",
    "section": "",
    "text": "9.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#least-squares-estimators-of-the-regression-parameters",
    "href": "chapter_9/9.html#least-squares-estimators-of-the-regression-parameters",
    "title": "9  Regression",
    "section": "9.2 Least squares estimators of the regression parameters",
    "text": "9.2 Least squares estimators of the regression parameters",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#distribution-of-the-estimators",
    "href": "chapter_9/9.html#distribution-of-the-estimators",
    "title": "9  Regression",
    "section": "9.3 Distribution of the estimators",
    "text": "9.3 Distribution of the estimators",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#statistical-inferences-about-the-regression-parameters",
    "href": "chapter_9/9.html#statistical-inferences-about-the-regression-parameters",
    "title": "9  Regression",
    "section": "9.4 Statistical inferences about the regression parameters",
    "text": "9.4 Statistical inferences about the regression parameters",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#the-coefficient-of-determination-and-the-sample-correlation-coefficient",
    "href": "chapter_9/9.html#the-coefficient-of-determination-and-the-sample-correlation-coefficient",
    "title": "9  Regression",
    "section": "9.5 The coefficient of determination and the sample correlation coefficient",
    "text": "9.5 The coefficient of determination and the sample correlation coefficient",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#analysis-of-residuals-assessing-the-model",
    "href": "chapter_9/9.html#analysis-of-residuals-assessing-the-model",
    "title": "9  Regression",
    "section": "9.6 Analysis of residuals: assessing the model",
    "text": "9.6 Analysis of residuals: assessing the model",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#transforming-to-linearity",
    "href": "chapter_9/9.html#transforming-to-linearity",
    "title": "9  Regression",
    "section": "9.7 Transforming to linearity",
    "text": "9.7 Transforming to linearity",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#weighted-least-squares",
    "href": "chapter_9/9.html#weighted-least-squares",
    "title": "9  Regression",
    "section": "9.8 Weighted least squares",
    "text": "9.8 Weighted least squares",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#polynomial-regression",
    "href": "chapter_9/9.html#polynomial-regression",
    "title": "9  Regression",
    "section": "9.9 Polynomial regression",
    "text": "9.9 Polynomial regression",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#multiple-linear-regression",
    "href": "chapter_9/9.html#multiple-linear-regression",
    "title": "9  Regression",
    "section": "9.10 Multiple linear regression",
    "text": "9.10 Multiple linear regression",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#logistic-regression-models-for-binary-output-data",
    "href": "chapter_9/9.html#logistic-regression-models-for-binary-output-data",
    "title": "9  Regression",
    "section": "9.11 Logistic regression models for binary output data",
    "text": "9.11 Logistic regression models for binary output data",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_9/9.html#problems",
    "href": "chapter_9/9.html#problems",
    "title": "9  Regression",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Regression</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html",
    "href": "chapter_10/10.html",
    "title": "10  Analysis of variance",
    "section": "",
    "text": "10.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#an-overview",
    "href": "chapter_10/10.html#an-overview",
    "title": "10  Analysis of variance",
    "section": "10.2 An overview",
    "text": "10.2 An overview",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#one-way-analysis-of-variance",
    "href": "chapter_10/10.html#one-way-analysis-of-variance",
    "title": "10  Analysis of variance",
    "section": "10.3 One-way analysis of variance",
    "text": "10.3 One-way analysis of variance",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-factor-analysis-of-variance-introduction-and-parameter-estimation",
    "href": "chapter_10/10.html#two-factor-analysis-of-variance-introduction-and-parameter-estimation",
    "title": "10  Analysis of variance",
    "section": "10.4 Two-factor analysis of variance: introduction and parameter estimation",
    "text": "10.4 Two-factor analysis of variance: introduction and parameter estimation",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-factor-analysis-of-variance-testing-hypotheses",
    "href": "chapter_10/10.html#two-factor-analysis-of-variance-testing-hypotheses",
    "title": "10  Analysis of variance",
    "section": "10.5 Two-factor analysis of variance: testing hypotheses",
    "text": "10.5 Two-factor analysis of variance: testing hypotheses",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#two-way-analysis-of-variance-with-interaction",
    "href": "chapter_10/10.html#two-way-analysis-of-variance-with-interaction",
    "title": "10  Analysis of variance",
    "section": "10.6 Two-way analysis of variance with interaction",
    "text": "10.6 Two-way analysis of variance with interaction",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_10/10.html#problems",
    "href": "chapter_10/10.html#problems",
    "title": "10  Analysis of variance",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analysis of variance</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html",
    "href": "chapter_11/11.html",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "",
    "text": "11.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#goodness-of-fit-tests-when-all-parameters-are-specified",
    "href": "chapter_11/11.html#goodness-of-fit-tests-when-all-parameters-are-specified",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.2 Goodness of fit tests when all parameters are specified",
    "text": "11.2 Goodness of fit tests when all parameters are specified",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#goodness-of-fit-tests-when-some-parameters-are-unspecified",
    "href": "chapter_11/11.html#goodness-of-fit-tests-when-some-parameters-are-unspecified",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.3 Goodness of fit tests when some parameters are unspecified",
    "text": "11.3 Goodness of fit tests when some parameters are unspecified",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#tests-of-independence-in-contingency-tables",
    "href": "chapter_11/11.html#tests-of-independence-in-contingency-tables",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.4 Tests of independence in contingency tables",
    "text": "11.4 Tests of independence in contingency tables",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#tests-of-independence-in-contingency-tables-having-fixed-marginal-totals",
    "href": "chapter_11/11.html#tests-of-independence-in-contingency-tables-having-fixed-marginal-totals",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.5 Tests of independence in contingency tables having fixed marginal totals",
    "text": "11.5 Tests of independence in contingency tables having fixed marginal totals",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#the-kolmogorovsmirnov-goodness-of-fit-test-for-continuous-data",
    "href": "chapter_11/11.html#the-kolmogorovsmirnov-goodness-of-fit-test-for-continuous-data",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "11.6 The Kolmogorov–Smirnov goodness of fit test for continuous data",
    "text": "11.6 The Kolmogorov–Smirnov goodness of fit test for continuous data",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_11/11.html#problems",
    "href": "chapter_11/11.html#problems",
    "title": "11  Goodness of fit tests and categorical data analysis",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Goodness of fit tests and categorical data analysis</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html",
    "href": "chapter_12/12.html",
    "title": "12  Nonparametric hypothesis tests",
    "section": "",
    "text": "12.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-sign-test",
    "href": "chapter_12/12.html#the-sign-test",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.2 The sign test",
    "text": "12.2 The sign test",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-signed-rank-test",
    "href": "chapter_12/12.html#the-signed-rank-test",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.3 The signed rank test",
    "text": "12.3 The signed rank test",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-two-sample-problem",
    "href": "chapter_12/12.html#the-two-sample-problem",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.4 The two-sample problem",
    "text": "12.4 The two-sample problem",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#the-runs-test-for-randomness",
    "href": "chapter_12/12.html#the-runs-test-for-randomness",
    "title": "12  Nonparametric hypothesis tests",
    "section": "12.5 The runs test for randomness",
    "text": "12.5 The runs test for randomness",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_12/12.html#problems",
    "href": "chapter_12/12.html#problems",
    "title": "12  Nonparametric hypothesis tests",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Nonparametric hypothesis tests</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html",
    "href": "chapter_13/13.html",
    "title": "13  Quality control",
    "section": "",
    "text": "13.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-average-valuesthe-overlinex-control-chart",
    "href": "chapter_13/13.html#control-charts-for-average-valuesthe-overlinex-control-chart",
    "title": "13  Quality control",
    "section": "13.2 Control charts for average values:the \\(\\overline{x}\\) control chart",
    "text": "13.2 Control charts for average values:the \\(\\overline{x}\\) control chart",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#mathbfs-control-charts",
    "href": "chapter_13/13.html#mathbfs-control-charts",
    "title": "13  Quality control",
    "section": "13.3 \\(\\mathbf{S}\\)-control charts",
    "text": "13.3 \\(\\mathbf{S}\\)-control charts",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-the-fraction-defective",
    "href": "chapter_13/13.html#control-charts-for-the-fraction-defective",
    "title": "13  Quality control",
    "section": "13.4 Control charts for the fraction defective",
    "text": "13.4 Control charts for the fraction defective",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#control-charts-for-number-of-defects",
    "href": "chapter_13/13.html#control-charts-for-number-of-defects",
    "title": "13  Quality control",
    "section": "13.5 Control charts for number of defects",
    "text": "13.5 Control charts for number of defects",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#other-control-charts-for-detecting-changes-in-the-population-mean",
    "href": "chapter_13/13.html#other-control-charts-for-detecting-changes-in-the-population-mean",
    "title": "13  Quality control",
    "section": "13.6 Other control charts for detecting changes in the population mean",
    "text": "13.6 Other control charts for detecting changes in the population mean",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_13/13.html#problems",
    "href": "chapter_13/13.html#problems",
    "title": "13  Quality control",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Quality control</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html",
    "href": "chapter_14/14.html",
    "title": "14  Life testing",
    "section": "",
    "text": "14.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#hazardrate-functions",
    "href": "chapter_14/14.html#hazardrate-functions",
    "title": "14  Life testing",
    "section": "14.2 Hazardrate functions",
    "text": "14.2 Hazardrate functions",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#the-exponential-distribution-in-life-testing.",
    "href": "chapter_14/14.html#the-exponential-distribution-in-life-testing.",
    "title": "14  Life testing",
    "section": "14.3 The exponential distribution in life testing.",
    "text": "14.3 The exponential distribution in life testing.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#a-two-sample-problem",
    "href": "chapter_14/14.html#a-two-sample-problem",
    "title": "14  Life testing",
    "section": "14.4 A two-sample problem",
    "text": "14.4 A two-sample problem",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#the-weibull-distribution-in-life-testing",
    "href": "chapter_14/14.html#the-weibull-distribution-in-life-testing",
    "title": "14  Life testing",
    "section": "14.5 The Weibull distribution in life testing",
    "text": "14.5 The Weibull distribution in life testing",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_14/14.html#problems",
    "href": "chapter_14/14.html#problems",
    "title": "14  Life testing",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Life testing</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html",
    "href": "chapter_15/15.html",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "",
    "text": "15.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#random-numbers",
    "href": "chapter_15/15.html#random-numbers",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.2 Random numbers",
    "text": "15.2 Random numbers",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#the-bootstrap-method",
    "href": "chapter_15/15.html#the-bootstrap-method",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.3 The bootstrap method",
    "text": "15.3 The bootstrap method",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#permutation-tests",
    "href": "chapter_15/15.html#permutation-tests",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.4 Permutation tests",
    "text": "15.4 Permutation tests",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#generating-discrete-random-variables",
    "href": "chapter_15/15.html#generating-discrete-random-variables",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.5 Generating discrete random variables",
    "text": "15.5 Generating discrete random variables",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#generating-continuous-random-variables",
    "href": "chapter_15/15.html#generating-continuous-random-variables",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.6 Generating continuous random variables",
    "text": "15.6 Generating continuous random variables",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#determining-the-number-of-simulation-runs-in-a-monte-carlo-study",
    "href": "chapter_15/15.html#determining-the-number-of-simulation-runs-in-a-monte-carlo-study",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "15.7 Determining the number of simulation runs in a Monte Carlo study",
    "text": "15.7 Determining the number of simulation runs in a Monte Carlo study",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_15/15.html#problems",
    "href": "chapter_15/15.html#problems",
    "title": "15  Simulation, bootstrap statistical methods, and permutation tests",
    "section": "Problems",
    "text": "Problems",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Simulation, bootstrap statistical methods, and permutation tests</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html",
    "href": "chapter_16/16.html",
    "title": "16  Machine learning and big data",
    "section": "",
    "text": "16.1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#late-flight-probabilities",
    "href": "chapter_16/16.html#late-flight-probabilities",
    "title": "16  Machine learning and big data",
    "section": "16.2 Late flight probabilities",
    "text": "16.2 Late flight probabilities",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#the-naive-bayes-approach",
    "href": "chapter_16/16.html#the-naive-bayes-approach",
    "title": "16  Machine learning and big data",
    "section": "16.3 The naive Bayes approach",
    "text": "16.3 The naive Bayes approach",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#distance-based-estimators.the-k-nearest-neighbors-rule",
    "href": "chapter_16/16.html#distance-based-estimators.the-k-nearest-neighbors-rule",
    "title": "16  Machine learning and big data",
    "section": "16.4 Distance-based estimators.The \\(k\\)-nearest neighbors rule",
    "text": "16.4 Distance-based estimators.The \\(k\\)-nearest neighbors rule",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#assessing-the-approaches",
    "href": "chapter_16/16.html#assessing-the-approaches",
    "title": "16  Machine learning and big data",
    "section": "16.5 Assessing the approaches",
    "text": "16.5 Assessing the approaches",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#when-characterizing-vectors-are-quantitative",
    "href": "chapter_16/16.html#when-characterizing-vectors-are-quantitative",
    "title": "16  Machine learning and big data",
    "section": "16.6 When characterizing vectors are quantitative",
    "text": "16.6 When characterizing vectors are quantitative",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#choosing-the-best-probability-a-bandit-problem",
    "href": "chapter_16/16.html#choosing-the-best-probability-a-bandit-problem",
    "title": "16  Machine learning and big data",
    "section": "16.7 Choosing the best probability: a bandit problem",
    "text": "16.7 Choosing the best probability: a bandit problem",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "chapter_16/16.html#problems",
    "href": "chapter_16/16.html#problems",
    "title": "16  Machine learning and big data",
    "section": "16.8 Problems",
    "text": "16.8 Problems",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Machine learning and big data</span>"
    ]
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "17  测试脚本",
    "section": "",
    "text": "图 17.1 展示了对温度和臭氧水平之间的进一步研究.\n\n\n代码\nlibrary(ggplot2)\n\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n\n\n\n\n\n\n\n\n图 17.1: 温度和臭氧水平\n\n\n\n\n\n\n\n代码\nlibrary(knitr)\ndf &lt;- data.frame(Name = c(\"Alice\", \"Bob\", \"Charlie\"), Age = c(25, 30, 35))  \nkable(df)\n\n\n\n\n表格 17.1: 年龄分布\n\n\n\n\n\n\nName\nAge\n\n\n\n\nAlice\n25\n\n\nBob\n30\n\n\nCharlie\n35",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>测试脚本</span>"
    ]
  }
]